{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## Pima Diabetes Dataset\n",
    "\n",
    "* Kaggle Dataset (https://www.kaggle.com/datasets/kumargh/pimaindiansdiabetescsv)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminaries\n",
    "\n",
    "from __future__ import absolute_import, division, print_function  # Python 2/3 compatibility\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "\n",
    "from tensorflow.keras.models  import Sequential \n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization \n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "0                 6                     148              72              35   \n",
       "1                 1                      85              66              29   \n",
       "2                 8                     183              64               0   \n",
       "3                 1                      89              66              23   \n",
       "4                 0                     137              40              35   \n",
       "..              ...                     ...             ...             ...   \n",
       "763              10                     101              76              48   \n",
       "764               2                     122              70              27   \n",
       "765               5                     121              72              23   \n",
       "766               1                     126              60               0   \n",
       "767               1                      93              70              31   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "0          0  33.6              0.627   50             1  \n",
       "1          0  26.6              0.351   31             0  \n",
       "2          0  23.3              0.672   32             1  \n",
       "3         94  28.1              0.167   21             0  \n",
       "4        168  43.1              2.288   33             1  \n",
       "..       ...   ...                ...  ...           ...  \n",
       "763      180  32.9              0.171   63             0  \n",
       "764        0  36.8              0.340   27             0  \n",
       "765      112  26.2              0.245   30             0  \n",
       "766        0  30.1              0.349   47             1  \n",
       "767        0  30.4              0.315   23             0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load in the data set (Internet Access needed)\n",
    "# Download pima-indians-diabetes.csv from https://www.kaggle.com/datasets/kumargh/pimaindiansdiabetescsv\n",
    "\n",
    "seed_value = 11111\n",
    "url = \"pima-indians-diabetes.csv\"\n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv(url, names=names) # names = column names\n",
    "diabetes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>4</td>\n",
       "      <td>154</td>\n",
       "      <td>62</td>\n",
       "      <td>31</td>\n",
       "      <td>284</td>\n",
       "      <td>32.8</td>\n",
       "      <td>0.237</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>13</td>\n",
       "      <td>105</td>\n",
       "      <td>25.9</td>\n",
       "      <td>0.472</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>10</td>\n",
       "      <td>162</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.7</td>\n",
       "      <td>0.182</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>66</td>\n",
       "      <td>20</td>\n",
       "      <td>90</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.867</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "760               2                      88              58              26   \n",
       "144               4                     154              62              31   \n",
       "340               1                     130              70              13   \n",
       "660              10                     162              84               0   \n",
       "70                2                     100              66              20   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "760       16  28.4              0.766   22             0  \n",
       "144      284  32.8              0.237   23             0  \n",
       "340      105  25.9              0.472   22             0  \n",
       "660        0  27.7              0.182   54             0  \n",
       "70        90  32.9              0.867   28             1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
       "        [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
       "        [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
       "        ...,\n",
       "        [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
       "        [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
       "        [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]]),\n",
       " array([1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "        0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "        1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "        0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "        1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "        1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "        1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "        0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "        1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "        0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "        0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "        1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "        0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "        0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "        0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "        0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "        1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values \n",
    "y = diabetes_df[\"has_diabetes\"].values\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=seed_value, stratify=y)\n",
    "# stratetify refer to the proportion of the data in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200, random_state=11111)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200, random_state=11111)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=200, random_state=11111)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200, random_state=seed_value)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.771\n",
      "roc-auc is 0.795\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test, y_pred_class_rf)))\n",
    "# Accuracy is 0.771 (77.1%) means, from 100 peoples 77 peoples are correctly predicted\n",
    "# Medical related field is really sensitive to be using in real life, if we fail once it can be fatal for the patient\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test, y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 8 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train) # fit_transform learns the mean and std dev, and then applies them to the data\n",
    "X_test_norm = normalizer.transform(X_test) # transform applies the mean and std dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 8 hidden nodes, ReLU activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "import os, random, numpy as np\n",
    "import tensorflow as tf \n",
    "\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "model_1 = Sequential([\n",
    "    Dense(8, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81 (324.00 Byte)\n",
      "Trainable params: 81 (324.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 81 parameters?  Does that make sense?\n",
    "\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7662 - accuracy: 0.4688 - val_loss: 0.7449 - val_accuracy: 0.5104\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 950us/step - loss: 0.7588 - accuracy: 0.4774 - val_loss: 0.7373 - val_accuracy: 0.5156\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.7518 - accuracy: 0.4861 - val_loss: 0.7302 - val_accuracy: 0.5312\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 881us/step - loss: 0.7452 - accuracy: 0.5035 - val_loss: 0.7234 - val_accuracy: 0.5625\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 915us/step - loss: 0.7391 - accuracy: 0.5191 - val_loss: 0.7171 - val_accuracy: 0.5677\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 852us/step - loss: 0.7332 - accuracy: 0.5295 - val_loss: 0.7113 - val_accuracy: 0.5781\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 862us/step - loss: 0.7278 - accuracy: 0.5434 - val_loss: 0.7057 - val_accuracy: 0.6042\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 853us/step - loss: 0.7226 - accuracy: 0.5538 - val_loss: 0.7004 - val_accuracy: 0.6146\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 848us/step - loss: 0.7176 - accuracy: 0.5642 - val_loss: 0.6955 - val_accuracy: 0.6146\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 828us/step - loss: 0.7130 - accuracy: 0.5712 - val_loss: 0.6909 - val_accuracy: 0.6302\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 839us/step - loss: 0.7086 - accuracy: 0.5764 - val_loss: 0.6864 - val_accuracy: 0.6406\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 838us/step - loss: 0.7043 - accuracy: 0.5938 - val_loss: 0.6822 - val_accuracy: 0.6354\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 849us/step - loss: 0.7003 - accuracy: 0.5972 - val_loss: 0.6782 - val_accuracy: 0.6458\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 852us/step - loss: 0.6964 - accuracy: 0.6094 - val_loss: 0.6744 - val_accuracy: 0.6615\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 862us/step - loss: 0.6927 - accuracy: 0.6146 - val_loss: 0.6707 - val_accuracy: 0.6562\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 859us/step - loss: 0.6891 - accuracy: 0.6198 - val_loss: 0.6672 - val_accuracy: 0.6406\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 844us/step - loss: 0.6856 - accuracy: 0.6267 - val_loss: 0.6638 - val_accuracy: 0.6458\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 829us/step - loss: 0.6823 - accuracy: 0.6302 - val_loss: 0.6606 - val_accuracy: 0.6510\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 820us/step - loss: 0.6791 - accuracy: 0.6302 - val_loss: 0.6575 - val_accuracy: 0.6510\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 822us/step - loss: 0.6759 - accuracy: 0.6354 - val_loss: 0.6544 - val_accuracy: 0.6510\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 809us/step - loss: 0.6729 - accuracy: 0.6441 - val_loss: 0.6515 - val_accuracy: 0.6458\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 821us/step - loss: 0.6699 - accuracy: 0.6510 - val_loss: 0.6487 - val_accuracy: 0.6562\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 858us/step - loss: 0.6670 - accuracy: 0.6528 - val_loss: 0.6459 - val_accuracy: 0.6615\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 867us/step - loss: 0.6642 - accuracy: 0.6562 - val_loss: 0.6432 - val_accuracy: 0.6667\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6614 - accuracy: 0.6597 - val_loss: 0.6407 - val_accuracy: 0.6667\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6588 - accuracy: 0.6615 - val_loss: 0.6382 - val_accuracy: 0.6667\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 844us/step - loss: 0.6562 - accuracy: 0.6615 - val_loss: 0.6358 - val_accuracy: 0.6667\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 846us/step - loss: 0.6537 - accuracy: 0.6649 - val_loss: 0.6335 - val_accuracy: 0.6667\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 822us/step - loss: 0.6512 - accuracy: 0.6649 - val_loss: 0.6312 - val_accuracy: 0.6615\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 825us/step - loss: 0.6488 - accuracy: 0.6701 - val_loss: 0.6290 - val_accuracy: 0.6562\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 884us/step - loss: 0.6464 - accuracy: 0.6719 - val_loss: 0.6269 - val_accuracy: 0.6562\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 987us/step - loss: 0.6441 - accuracy: 0.6701 - val_loss: 0.6248 - val_accuracy: 0.6510\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 948us/step - loss: 0.6418 - accuracy: 0.6701 - val_loss: 0.6228 - val_accuracy: 0.6510\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 918us/step - loss: 0.6396 - accuracy: 0.6736 - val_loss: 0.6208 - val_accuracy: 0.6510\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 982us/step - loss: 0.6374 - accuracy: 0.6753 - val_loss: 0.6189 - val_accuracy: 0.6510\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 916us/step - loss: 0.6352 - accuracy: 0.6788 - val_loss: 0.6171 - val_accuracy: 0.6510\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6331 - accuracy: 0.6806 - val_loss: 0.6153 - val_accuracy: 0.6458\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 968us/step - loss: 0.6310 - accuracy: 0.6823 - val_loss: 0.6135 - val_accuracy: 0.6458\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 963us/step - loss: 0.6289 - accuracy: 0.6840 - val_loss: 0.6117 - val_accuracy: 0.6510\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 957us/step - loss: 0.6269 - accuracy: 0.6840 - val_loss: 0.6100 - val_accuracy: 0.6510\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6250 - accuracy: 0.6840 - val_loss: 0.6083 - val_accuracy: 0.6510\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6231 - accuracy: 0.6858 - val_loss: 0.6067 - val_accuracy: 0.6510\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6212 - accuracy: 0.6858 - val_loss: 0.6050 - val_accuracy: 0.6510\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6194 - accuracy: 0.6858 - val_loss: 0.6035 - val_accuracy: 0.6562\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6176 - accuracy: 0.6858 - val_loss: 0.6019 - val_accuracy: 0.6615\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 973us/step - loss: 0.6159 - accuracy: 0.6875 - val_loss: 0.6004 - val_accuracy: 0.6615\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 919us/step - loss: 0.6141 - accuracy: 0.6875 - val_loss: 0.5989 - val_accuracy: 0.6615\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 946us/step - loss: 0.6124 - accuracy: 0.6910 - val_loss: 0.5974 - val_accuracy: 0.6667\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6107 - accuracy: 0.6927 - val_loss: 0.5960 - val_accuracy: 0.6667\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 963us/step - loss: 0.6090 - accuracy: 0.6944 - val_loss: 0.5945 - val_accuracy: 0.6667\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 958us/step - loss: 0.6074 - accuracy: 0.6944 - val_loss: 0.5931 - val_accuracy: 0.6615\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 934us/step - loss: 0.6057 - accuracy: 0.6944 - val_loss: 0.5917 - val_accuracy: 0.6615\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 958us/step - loss: 0.6041 - accuracy: 0.6944 - val_loss: 0.5903 - val_accuracy: 0.6615\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 932us/step - loss: 0.6026 - accuracy: 0.6979 - val_loss: 0.5889 - val_accuracy: 0.6771\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 942us/step - loss: 0.6010 - accuracy: 0.7014 - val_loss: 0.5875 - val_accuracy: 0.6771\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.5994 - accuracy: 0.7066 - val_loss: 0.5862 - val_accuracy: 0.6771\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5979 - accuracy: 0.7049 - val_loss: 0.5848 - val_accuracy: 0.6823\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5963 - accuracy: 0.7083 - val_loss: 0.5835 - val_accuracy: 0.6823\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 977us/step - loss: 0.5948 - accuracy: 0.7083 - val_loss: 0.5822 - val_accuracy: 0.6823\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5934 - accuracy: 0.7101 - val_loss: 0.5810 - val_accuracy: 0.6875\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5918 - accuracy: 0.7101 - val_loss: 0.5797 - val_accuracy: 0.6875\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.5904 - accuracy: 0.7083 - val_loss: 0.5785 - val_accuracy: 0.6875\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 855us/step - loss: 0.5889 - accuracy: 0.7083 - val_loss: 0.5772 - val_accuracy: 0.6927\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 822us/step - loss: 0.5874 - accuracy: 0.7118 - val_loss: 0.5760 - val_accuracy: 0.6927\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 834us/step - loss: 0.5860 - accuracy: 0.7118 - val_loss: 0.5748 - val_accuracy: 0.6979\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.5846 - accuracy: 0.7101 - val_loss: 0.5737 - val_accuracy: 0.6979\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.5832 - accuracy: 0.7118 - val_loss: 0.5725 - val_accuracy: 0.6979\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.5818 - accuracy: 0.7118 - val_loss: 0.5714 - val_accuracy: 0.6927\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 930us/step - loss: 0.5805 - accuracy: 0.7135 - val_loss: 0.5703 - val_accuracy: 0.6927\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 945us/step - loss: 0.5791 - accuracy: 0.7135 - val_loss: 0.5692 - val_accuracy: 0.6979\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 912us/step - loss: 0.5778 - accuracy: 0.7135 - val_loss: 0.5682 - val_accuracy: 0.6979\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.5765 - accuracy: 0.7135 - val_loss: 0.5671 - val_accuracy: 0.6979\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.5751 - accuracy: 0.7153 - val_loss: 0.5661 - val_accuracy: 0.6979\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 867us/step - loss: 0.5738 - accuracy: 0.7170 - val_loss: 0.5650 - val_accuracy: 0.6979\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.5724 - accuracy: 0.7170 - val_loss: 0.5640 - val_accuracy: 0.6979\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 848us/step - loss: 0.5711 - accuracy: 0.7188 - val_loss: 0.5629 - val_accuracy: 0.6979\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 842us/step - loss: 0.5698 - accuracy: 0.7205 - val_loss: 0.5619 - val_accuracy: 0.6979\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 835us/step - loss: 0.5685 - accuracy: 0.7205 - val_loss: 0.5609 - val_accuracy: 0.6979\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 815us/step - loss: 0.5672 - accuracy: 0.7205 - val_loss: 0.5599 - val_accuracy: 0.6979\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 826us/step - loss: 0.5660 - accuracy: 0.7205 - val_loss: 0.5589 - val_accuracy: 0.6979\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 832us/step - loss: 0.5647 - accuracy: 0.7257 - val_loss: 0.5579 - val_accuracy: 0.7031\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 814us/step - loss: 0.5635 - accuracy: 0.7274 - val_loss: 0.5569 - val_accuracy: 0.7031\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 816us/step - loss: 0.5622 - accuracy: 0.7309 - val_loss: 0.5560 - val_accuracy: 0.7031\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 815us/step - loss: 0.5610 - accuracy: 0.7326 - val_loss: 0.5550 - val_accuracy: 0.7031\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 815us/step - loss: 0.5597 - accuracy: 0.7326 - val_loss: 0.5541 - val_accuracy: 0.7031\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 821us/step - loss: 0.5585 - accuracy: 0.7344 - val_loss: 0.5531 - val_accuracy: 0.6979\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 822us/step - loss: 0.5573 - accuracy: 0.7344 - val_loss: 0.5522 - val_accuracy: 0.6979\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 857us/step - loss: 0.5561 - accuracy: 0.7361 - val_loss: 0.5513 - val_accuracy: 0.6927\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 881us/step - loss: 0.5550 - accuracy: 0.7361 - val_loss: 0.5504 - val_accuracy: 0.6927\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.5539 - accuracy: 0.7378 - val_loss: 0.5495 - val_accuracy: 0.6927\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 943us/step - loss: 0.5527 - accuracy: 0.7378 - val_loss: 0.5487 - val_accuracy: 0.6927\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 934us/step - loss: 0.5516 - accuracy: 0.7396 - val_loss: 0.5478 - val_accuracy: 0.6927\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 877us/step - loss: 0.5505 - accuracy: 0.7396 - val_loss: 0.5470 - val_accuracy: 0.6979\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 918us/step - loss: 0.5494 - accuracy: 0.7396 - val_loss: 0.5461 - val_accuracy: 0.6979\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.5483 - accuracy: 0.7413 - val_loss: 0.5453 - val_accuracy: 0.6979\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 874us/step - loss: 0.5472 - accuracy: 0.7431 - val_loss: 0.5445 - val_accuracy: 0.6927\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 887us/step - loss: 0.5461 - accuracy: 0.7431 - val_loss: 0.5437 - val_accuracy: 0.6927\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 860us/step - loss: 0.5450 - accuracy: 0.7431 - val_loss: 0.5429 - val_accuracy: 0.6875\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 863us/step - loss: 0.5440 - accuracy: 0.7448 - val_loss: 0.5422 - val_accuracy: 0.6927\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 853us/step - loss: 0.5429 - accuracy: 0.7483 - val_loss: 0.5414 - val_accuracy: 0.6927\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 819us/step - loss: 0.5419 - accuracy: 0.7500 - val_loss: 0.5406 - val_accuracy: 0.6979\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 818us/step - loss: 0.5408 - accuracy: 0.7517 - val_loss: 0.5399 - val_accuracy: 0.6979\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 855us/step - loss: 0.5398 - accuracy: 0.7517 - val_loss: 0.5392 - val_accuracy: 0.7031\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 846us/step - loss: 0.5388 - accuracy: 0.7500 - val_loss: 0.5385 - val_accuracy: 0.7031\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 814us/step - loss: 0.5378 - accuracy: 0.7500 - val_loss: 0.5378 - val_accuracy: 0.7031\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 830us/step - loss: 0.5368 - accuracy: 0.7517 - val_loss: 0.5371 - val_accuracy: 0.7031\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 830us/step - loss: 0.5358 - accuracy: 0.7517 - val_loss: 0.5364 - val_accuracy: 0.7031\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 819us/step - loss: 0.5348 - accuracy: 0.7517 - val_loss: 0.5357 - val_accuracy: 0.7031\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.5339 - accuracy: 0.7552 - val_loss: 0.5350 - val_accuracy: 0.7031\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 815us/step - loss: 0.5329 - accuracy: 0.7552 - val_loss: 0.5344 - val_accuracy: 0.7031\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 838us/step - loss: 0.5320 - accuracy: 0.7569 - val_loss: 0.5337 - val_accuracy: 0.7031\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 835us/step - loss: 0.5311 - accuracy: 0.7569 - val_loss: 0.5331 - val_accuracy: 0.7031\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 869us/step - loss: 0.5301 - accuracy: 0.7587 - val_loss: 0.5324 - val_accuracy: 0.7031\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7587 - val_loss: 0.5318 - val_accuracy: 0.7031\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5284 - accuracy: 0.7587 - val_loss: 0.5311 - val_accuracy: 0.7031\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 963us/step - loss: 0.5275 - accuracy: 0.7604 - val_loss: 0.5305 - val_accuracy: 0.7031\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 922us/step - loss: 0.5266 - accuracy: 0.7622 - val_loss: 0.5299 - val_accuracy: 0.6979\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 962us/step - loss: 0.5257 - accuracy: 0.7622 - val_loss: 0.5293 - val_accuracy: 0.7031\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5248 - accuracy: 0.7639 - val_loss: 0.5287 - val_accuracy: 0.7031\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 985us/step - loss: 0.5240 - accuracy: 0.7639 - val_loss: 0.5281 - val_accuracy: 0.7031\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 943us/step - loss: 0.5231 - accuracy: 0.7639 - val_loss: 0.5275 - val_accuracy: 0.7031\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 876us/step - loss: 0.5223 - accuracy: 0.7639 - val_loss: 0.5269 - val_accuracy: 0.7031\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 845us/step - loss: 0.5215 - accuracy: 0.7639 - val_loss: 0.5264 - val_accuracy: 0.7031\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5207 - accuracy: 0.7656 - val_loss: 0.5258 - val_accuracy: 0.7031\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5199 - accuracy: 0.7656 - val_loss: 0.5253 - val_accuracy: 0.7135\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 985us/step - loss: 0.5191 - accuracy: 0.7656 - val_loss: 0.5247 - val_accuracy: 0.7188\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 988us/step - loss: 0.5183 - accuracy: 0.7656 - val_loss: 0.5242 - val_accuracy: 0.7188\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 960us/step - loss: 0.5175 - accuracy: 0.7674 - val_loss: 0.5237 - val_accuracy: 0.7188\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5167 - accuracy: 0.7691 - val_loss: 0.5232 - val_accuracy: 0.7188\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5160 - accuracy: 0.7656 - val_loss: 0.5227 - val_accuracy: 0.7188\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.5152 - accuracy: 0.7639 - val_loss: 0.5222 - val_accuracy: 0.7135\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 887us/step - loss: 0.5145 - accuracy: 0.7639 - val_loss: 0.5218 - val_accuracy: 0.7135\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 969us/step - loss: 0.5138 - accuracy: 0.7639 - val_loss: 0.5213 - val_accuracy: 0.7135\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 967us/step - loss: 0.5131 - accuracy: 0.7639 - val_loss: 0.5208 - val_accuracy: 0.7135\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.5124 - accuracy: 0.7639 - val_loss: 0.5204 - val_accuracy: 0.7135\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 851us/step - loss: 0.5117 - accuracy: 0.7639 - val_loss: 0.5199 - val_accuracy: 0.7188\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.5110 - accuracy: 0.7656 - val_loss: 0.5195 - val_accuracy: 0.7240\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 885us/step - loss: 0.5104 - accuracy: 0.7656 - val_loss: 0.5191 - val_accuracy: 0.7240\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 868us/step - loss: 0.5097 - accuracy: 0.7639 - val_loss: 0.5187 - val_accuracy: 0.7240\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 867us/step - loss: 0.5090 - accuracy: 0.7604 - val_loss: 0.5182 - val_accuracy: 0.7240\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 866us/step - loss: 0.5083 - accuracy: 0.7604 - val_loss: 0.5178 - val_accuracy: 0.7240\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 879us/step - loss: 0.5077 - accuracy: 0.7604 - val_loss: 0.5175 - val_accuracy: 0.7240\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.5071 - accuracy: 0.7622 - val_loss: 0.5171 - val_accuracy: 0.7240\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.5064 - accuracy: 0.7622 - val_loss: 0.5167 - val_accuracy: 0.7240\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7622 - val_loss: 0.5163 - val_accuracy: 0.7292\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5052 - accuracy: 0.7622 - val_loss: 0.5160 - val_accuracy: 0.7292\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 914us/step - loss: 0.5046 - accuracy: 0.7639 - val_loss: 0.5156 - val_accuracy: 0.7292\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 878us/step - loss: 0.5040 - accuracy: 0.7639 - val_loss: 0.5153 - val_accuracy: 0.7292\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.5035 - accuracy: 0.7656 - val_loss: 0.5149 - val_accuracy: 0.7292\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 862us/step - loss: 0.5029 - accuracy: 0.7656 - val_loss: 0.5146 - val_accuracy: 0.7292\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 847us/step - loss: 0.5023 - accuracy: 0.7639 - val_loss: 0.5143 - val_accuracy: 0.7292\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.5018 - accuracy: 0.7639 - val_loss: 0.5140 - val_accuracy: 0.7344\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 931us/step - loss: 0.5012 - accuracy: 0.7639 - val_loss: 0.5137 - val_accuracy: 0.7344\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 904us/step - loss: 0.5007 - accuracy: 0.7639 - val_loss: 0.5134 - val_accuracy: 0.7344\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 927us/step - loss: 0.5002 - accuracy: 0.7639 - val_loss: 0.5131 - val_accuracy: 0.7344\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 922us/step - loss: 0.4997 - accuracy: 0.7639 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 931us/step - loss: 0.4991 - accuracy: 0.7656 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 950us/step - loss: 0.4986 - accuracy: 0.7656 - val_loss: 0.5122 - val_accuracy: 0.7344\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 965us/step - loss: 0.4981 - accuracy: 0.7674 - val_loss: 0.5120 - val_accuracy: 0.7344\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 995us/step - loss: 0.4976 - accuracy: 0.7674 - val_loss: 0.5117 - val_accuracy: 0.7344\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 913us/step - loss: 0.4971 - accuracy: 0.7674 - val_loss: 0.5114 - val_accuracy: 0.7344\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 977us/step - loss: 0.4966 - accuracy: 0.7674 - val_loss: 0.5112 - val_accuracy: 0.7292\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4961 - accuracy: 0.7691 - val_loss: 0.5109 - val_accuracy: 0.7292\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 943us/step - loss: 0.4956 - accuracy: 0.7691 - val_loss: 0.5107 - val_accuracy: 0.7292\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 959us/step - loss: 0.4951 - accuracy: 0.7674 - val_loss: 0.5104 - val_accuracy: 0.7292\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4947 - accuracy: 0.7674 - val_loss: 0.5102 - val_accuracy: 0.7292\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4942 - accuracy: 0.7674 - val_loss: 0.5099 - val_accuracy: 0.7292\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 916us/step - loss: 0.4937 - accuracy: 0.7674 - val_loss: 0.5097 - val_accuracy: 0.7292\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 909us/step - loss: 0.4932 - accuracy: 0.7674 - val_loss: 0.5094 - val_accuracy: 0.7292\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.4928 - accuracy: 0.7674 - val_loss: 0.5092 - val_accuracy: 0.7292\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 917us/step - loss: 0.4923 - accuracy: 0.7674 - val_loss: 0.5089 - val_accuracy: 0.7292\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 921us/step - loss: 0.4919 - accuracy: 0.7691 - val_loss: 0.5087 - val_accuracy: 0.7292\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 923us/step - loss: 0.4915 - accuracy: 0.7708 - val_loss: 0.5084 - val_accuracy: 0.7292\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 918us/step - loss: 0.4910 - accuracy: 0.7708 - val_loss: 0.5082 - val_accuracy: 0.7292\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 930us/step - loss: 0.4906 - accuracy: 0.7708 - val_loss: 0.5080 - val_accuracy: 0.7292\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 929us/step - loss: 0.4902 - accuracy: 0.7708 - val_loss: 0.5077 - val_accuracy: 0.7292\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 945us/step - loss: 0.4897 - accuracy: 0.7708 - val_loss: 0.5075 - val_accuracy: 0.7344\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.4893 - accuracy: 0.7708 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7708 - val_loss: 0.5071 - val_accuracy: 0.7344\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 994us/step - loss: 0.4885 - accuracy: 0.7708 - val_loss: 0.5068 - val_accuracy: 0.7344\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 991us/step - loss: 0.4881 - accuracy: 0.7708 - val_loss: 0.5066 - val_accuracy: 0.7344\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4877 - accuracy: 0.7708 - val_loss: 0.5064 - val_accuracy: 0.7344\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 878us/step - loss: 0.4873 - accuracy: 0.7708 - val_loss: 0.5062 - val_accuracy: 0.7344\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4869 - accuracy: 0.7726 - val_loss: 0.5060 - val_accuracy: 0.7344\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 873us/step - loss: 0.4866 - accuracy: 0.7726 - val_loss: 0.5058 - val_accuracy: 0.7344\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 870us/step - loss: 0.4862 - accuracy: 0.7726 - val_loss: 0.5057 - val_accuracy: 0.7344\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 926us/step - loss: 0.4858 - accuracy: 0.7726 - val_loss: 0.5055 - val_accuracy: 0.7344\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 895us/step - loss: 0.4854 - accuracy: 0.7726 - val_loss: 0.5053 - val_accuracy: 0.7344\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4851 - accuracy: 0.7743 - val_loss: 0.5051 - val_accuracy: 0.7292\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 918us/step - loss: 0.4848 - accuracy: 0.7743 - val_loss: 0.5050 - val_accuracy: 0.7292\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4844 - accuracy: 0.7743 - val_loss: 0.5048 - val_accuracy: 0.7292\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 966us/step - loss: 0.4840 - accuracy: 0.7743 - val_loss: 0.5046 - val_accuracy: 0.7292\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 992us/step - loss: 0.4837 - accuracy: 0.7743 - val_loss: 0.5045 - val_accuracy: 0.7292\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4833 - accuracy: 0.7743 - val_loss: 0.5043 - val_accuracy: 0.7292\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 928us/step - loss: 0.4830 - accuracy: 0.7743 - val_loss: 0.5042 - val_accuracy: 0.7292\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 949us/step - loss: 0.4826 - accuracy: 0.7743 - val_loss: 0.5041 - val_accuracy: 0.7292\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.7778 - val_loss: 0.5039 - val_accuracy: 0.7292\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.7795 - val_loss: 0.5038 - val_accuracy: 0.7292\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 947us/step - loss: 0.4816 - accuracy: 0.7795 - val_loss: 0.5036 - val_accuracy: 0.7292\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 921us/step - loss: 0.4813 - accuracy: 0.7795 - val_loss: 0.5035 - val_accuracy: 0.7292\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(optimizer=SGD(learning_rate=0.003), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200, batch_size=32)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 430us/step\n"
     ]
    }
   ],
   "source": [
    "#  Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilistic score.\n",
    "#  hard decision : prediction of the model\n",
    "#  probabilistic score : probability of the prediction\n",
    "\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)\n",
    "y_pred_class_nn_1 = (y_pred_prob_nn_1 >= 0.5).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58112663],\n",
       "       [0.32257375],\n",
       "       [0.6120373 ],\n",
       "       [0.1330455 ],\n",
       "       [0.49373558],\n",
       "       [0.709026  ],\n",
       "       [0.5599952 ],\n",
       "       [0.15182671],\n",
       "       [0.17918727],\n",
       "       [0.9180581 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.729\n",
      "roc-auc is 0.815\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test, y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test, y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2941840a0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4257 - accuracy: 0.7969 - val_loss: 0.5136 - val_accuracy: 0.7396\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4257 - accuracy: 0.7969 - val_loss: 0.5137 - val_accuracy: 0.7396\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 943us/step - loss: 0.4256 - accuracy: 0.7969 - val_loss: 0.5137 - val_accuracy: 0.7396\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4256 - accuracy: 0.7969 - val_loss: 0.5137 - val_accuracy: 0.7396\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 860us/step - loss: 0.4256 - accuracy: 0.7969 - val_loss: 0.5137 - val_accuracy: 0.7396\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 877us/step - loss: 0.4256 - accuracy: 0.7969 - val_loss: 0.5137 - val_accuracy: 0.7396\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 857us/step - loss: 0.4256 - accuracy: 0.7969 - val_loss: 0.5137 - val_accuracy: 0.7396\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 971us/step - loss: 0.4256 - accuracy: 0.7969 - val_loss: 0.5137 - val_accuracy: 0.7396\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 984us/step - loss: 0.4256 - accuracy: 0.7969 - val_loss: 0.5137 - val_accuracy: 0.7396\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4255 - accuracy: 0.7969 - val_loss: 0.5137 - val_accuracy: 0.7396\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 869us/step - loss: 0.4255 - accuracy: 0.7969 - val_loss: 0.5137 - val_accuracy: 0.7396\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 867us/step - loss: 0.4255 - accuracy: 0.7969 - val_loss: 0.5137 - val_accuracy: 0.7396\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 947us/step - loss: 0.4255 - accuracy: 0.7969 - val_loss: 0.5137 - val_accuracy: 0.7396\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 919us/step - loss: 0.4255 - accuracy: 0.7969 - val_loss: 0.5137 - val_accuracy: 0.7396\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 876us/step - loss: 0.4255 - accuracy: 0.7969 - val_loss: 0.5137 - val_accuracy: 0.7396\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 843us/step - loss: 0.4254 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4254 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 936us/step - loss: 0.4254 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 851us/step - loss: 0.4254 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.4254 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4253 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 856us/step - loss: 0.4253 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.4253 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 874us/step - loss: 0.4253 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 871us/step - loss: 0.4253 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.4252 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4253 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.4252 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 875us/step - loss: 0.4252 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4252 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 867us/step - loss: 0.4252 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 861us/step - loss: 0.4251 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4252 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4251 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4251 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4251 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 915us/step - loss: 0.4251 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 881us/step - loss: 0.4250 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 851us/step - loss: 0.4251 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 885us/step - loss: 0.4250 - accuracy: 0.7969 - val_loss: 0.5138 - val_accuracy: 0.7396\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4250 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 862us/step - loss: 0.4250 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 863us/step - loss: 0.4250 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4250 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 868us/step - loss: 0.4249 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 927us/step - loss: 0.4249 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4249 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4249 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.4249 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 874us/step - loss: 0.4249 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 861us/step - loss: 0.4248 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4248 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 865us/step - loss: 0.4248 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 856us/step - loss: 0.4248 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.4248 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 887us/step - loss: 0.4247 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.4247 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 914us/step - loss: 0.4247 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4247 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 872us/step - loss: 0.4247 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 848us/step - loss: 0.4247 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 866us/step - loss: 0.4247 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.4247 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4246 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 887us/step - loss: 0.4246 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 858us/step - loss: 0.4246 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.4246 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 872us/step - loss: 0.4246 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4245 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 878us/step - loss: 0.4245 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 850us/step - loss: 0.4245 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 884us/step - loss: 0.4245 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 856us/step - loss: 0.4245 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 863us/step - loss: 0.4245 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4245 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 855us/step - loss: 0.4244 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 884us/step - loss: 0.4244 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 826us/step - loss: 0.4243 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 863us/step - loss: 0.4244 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 873us/step - loss: 0.4243 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 887us/step - loss: 0.4243 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4243 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 872us/step - loss: 0.4243 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 873us/step - loss: 0.4243 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 860us/step - loss: 0.4242 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 875us/step - loss: 0.4242 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4242 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 854us/step - loss: 0.4242 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.4242 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 857us/step - loss: 0.4242 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 874us/step - loss: 0.4242 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 867us/step - loss: 0.4241 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4241 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 854us/step - loss: 0.4241 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 869us/step - loss: 0.4241 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 866us/step - loss: 0.4240 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 837us/step - loss: 0.4241 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 872us/step - loss: 0.4240 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 836us/step - loss: 0.4240 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4240 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7396\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 852us/step - loss: 0.4240 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 812us/step - loss: 0.4240 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 865us/step - loss: 0.4239 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 904us/step - loss: 0.4239 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4239 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 838us/step - loss: 0.4239 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 873us/step - loss: 0.4239 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 865us/step - loss: 0.4238 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4238 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 870us/step - loss: 0.4238 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 974us/step - loss: 0.4238 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4238 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 0s 852us/step - loss: 0.4237 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 853us/step - loss: 0.4237 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 865us/step - loss: 0.4237 - accuracy: 0.7969 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 872us/step - loss: 0.4237 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 868us/step - loss: 0.4236 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4236 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 872us/step - loss: 0.4236 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 879us/step - loss: 0.4236 - accuracy: 0.7951 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 873us/step - loss: 0.4236 - accuracy: 0.7951 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.4236 - accuracy: 0.7969 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4236 - accuracy: 0.7969 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 862us/step - loss: 0.4235 - accuracy: 0.7951 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.4235 - accuracy: 0.7951 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 878us/step - loss: 0.4235 - accuracy: 0.7934 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4235 - accuracy: 0.7934 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4234 - accuracy: 0.7951 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 885us/step - loss: 0.4234 - accuracy: 0.7986 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 885us/step - loss: 0.4234 - accuracy: 0.7934 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4234 - accuracy: 0.7969 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 872us/step - loss: 0.4234 - accuracy: 0.7934 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4234 - accuracy: 0.7969 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 921us/step - loss: 0.4234 - accuracy: 0.7969 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 873us/step - loss: 0.4233 - accuracy: 0.7969 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 863us/step - loss: 0.4234 - accuracy: 0.7969 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 877us/step - loss: 0.4233 - accuracy: 0.7951 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 874us/step - loss: 0.4233 - accuracy: 0.7951 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 865us/step - loss: 0.4233 - accuracy: 0.7951 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 870us/step - loss: 0.4233 - accuracy: 0.7951 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4233 - accuracy: 0.7951 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 844us/step - loss: 0.4232 - accuracy: 0.7969 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 834us/step - loss: 0.4232 - accuracy: 0.7951 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 916us/step - loss: 0.4232 - accuracy: 0.7986 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 861us/step - loss: 0.4232 - accuracy: 0.7951 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 930us/step - loss: 0.4232 - accuracy: 0.7951 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4231 - accuracy: 0.7951 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 863us/step - loss: 0.4231 - accuracy: 0.7951 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 862us/step - loss: 0.4231 - accuracy: 0.7951 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 860us/step - loss: 0.4231 - accuracy: 0.7969 - val_loss: 0.5140 - val_accuracy: 0.7500\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.4230 - accuracy: 0.7969 - val_loss: 0.5140 - val_accuracy: 0.7500\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 860us/step - loss: 0.4230 - accuracy: 0.7969 - val_loss: 0.5140 - val_accuracy: 0.7500\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.4231 - accuracy: 0.7951 - val_loss: 0.5140 - val_accuracy: 0.7500\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 966us/step - loss: 0.4230 - accuracy: 0.7969 - val_loss: 0.5140 - val_accuracy: 0.7500\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7969 - val_loss: 0.5140 - val_accuracy: 0.7500\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7969 - val_loss: 0.5140 - val_accuracy: 0.7500\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 914us/step - loss: 0.4230 - accuracy: 0.7969 - val_loss: 0.5140 - val_accuracy: 0.7500\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 858us/step - loss: 0.4229 - accuracy: 0.7969 - val_loss: 0.5140 - val_accuracy: 0.7500\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 843us/step - loss: 0.4229 - accuracy: 0.7969 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 895us/step - loss: 0.4229 - accuracy: 0.7969 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 839us/step - loss: 0.4229 - accuracy: 0.7969 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 856us/step - loss: 0.4229 - accuracy: 0.7969 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 956us/step - loss: 0.4228 - accuracy: 0.7969 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 950us/step - loss: 0.4229 - accuracy: 0.7969 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 881us/step - loss: 0.4228 - accuracy: 0.7969 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4228 - accuracy: 0.7986 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 864us/step - loss: 0.4228 - accuracy: 0.7969 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 854us/step - loss: 0.4228 - accuracy: 0.7969 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4228 - accuracy: 0.7986 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 857us/step - loss: 0.4228 - accuracy: 0.7969 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 878us/step - loss: 0.4228 - accuracy: 0.7986 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 833us/step - loss: 0.4227 - accuracy: 0.7969 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 859us/step - loss: 0.4227 - accuracy: 0.7969 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 925us/step - loss: 0.4227 - accuracy: 0.7969 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 895us/step - loss: 0.4227 - accuracy: 0.7969 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 851us/step - loss: 0.4226 - accuracy: 0.7986 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 836us/step - loss: 0.4226 - accuracy: 0.7986 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 855us/step - loss: 0.4226 - accuracy: 0.7986 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 877us/step - loss: 0.4226 - accuracy: 0.7969 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 850us/step - loss: 0.4226 - accuracy: 0.7969 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 867us/step - loss: 0.4226 - accuracy: 0.7986 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4225 - accuracy: 0.7986 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 873us/step - loss: 0.4226 - accuracy: 0.7986 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 856us/step - loss: 0.4225 - accuracy: 0.7986 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4225 - accuracy: 0.7986 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4225 - accuracy: 0.7986 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4225 - accuracy: 0.7969 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4225 - accuracy: 0.7986 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4224 - accuracy: 0.7986 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4224 - accuracy: 0.7986 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 877us/step - loss: 0.4224 - accuracy: 0.7986 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 904us/step - loss: 0.4224 - accuracy: 0.7969 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 874us/step - loss: 0.4224 - accuracy: 0.7986 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4224 - accuracy: 0.7986 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 871us/step - loss: 0.4224 - accuracy: 0.7986 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4223 - accuracy: 0.7986 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4223 - accuracy: 0.7986 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4223 - accuracy: 0.7986 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 884us/step - loss: 0.4223 - accuracy: 0.7986 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4222 - accuracy: 0.7986 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 885us/step - loss: 0.4222 - accuracy: 0.7986 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.4222 - accuracy: 0.7986 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4222 - accuracy: 0.7986 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7986 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4222 - accuracy: 0.7969 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.4222 - accuracy: 0.7986 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4222 - accuracy: 0.7986 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 866us/step - loss: 0.4222 - accuracy: 0.7986 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 874us/step - loss: 0.4221 - accuracy: 0.7986 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 866us/step - loss: 0.4221 - accuracy: 0.7986 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 859us/step - loss: 0.4221 - accuracy: 0.7986 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4221 - accuracy: 0.7986 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.4221 - accuracy: 0.7986 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 863us/step - loss: 0.4220 - accuracy: 0.7986 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 912us/step - loss: 0.4221 - accuracy: 0.7986 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 853us/step - loss: 0.4220 - accuracy: 0.7986 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.4220 - accuracy: 0.7986 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4220 - accuracy: 0.7986 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 853us/step - loss: 0.4219 - accuracy: 0.7986 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 906us/step - loss: 0.4219 - accuracy: 0.7986 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 951us/step - loss: 0.4219 - accuracy: 0.7986 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4219 - accuracy: 0.7986 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 863us/step - loss: 0.4219 - accuracy: 0.7986 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 908us/step - loss: 0.4219 - accuracy: 0.7986 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 895us/step - loss: 0.4219 - accuracy: 0.7986 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 875us/step - loss: 0.4218 - accuracy: 0.7986 - val_loss: 0.5145 - val_accuracy: 0.7500\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 846us/step - loss: 0.4218 - accuracy: 0.7986 - val_loss: 0.5145 - val_accuracy: 0.7500\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 870us/step - loss: 0.4218 - accuracy: 0.7986 - val_loss: 0.5145 - val_accuracy: 0.7500\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4218 - accuracy: 0.7986 - val_loss: 0.5145 - val_accuracy: 0.7500\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 945us/step - loss: 0.4217 - accuracy: 0.7986 - val_loss: 0.5145 - val_accuracy: 0.7500\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4218 - accuracy: 0.7986 - val_loss: 0.5145 - val_accuracy: 0.7500\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 866us/step - loss: 0.4217 - accuracy: 0.7986 - val_loss: 0.5145 - val_accuracy: 0.7500\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 916us/step - loss: 0.4217 - accuracy: 0.8003 - val_loss: 0.5145 - val_accuracy: 0.7500\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4217 - accuracy: 0.7986 - val_loss: 0.5145 - val_accuracy: 0.7500\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 859us/step - loss: 0.4217 - accuracy: 0.8003 - val_loss: 0.5145 - val_accuracy: 0.7500\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 867us/step - loss: 0.4217 - accuracy: 0.7986 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 843us/step - loss: 0.4217 - accuracy: 0.7986 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 875us/step - loss: 0.4216 - accuracy: 0.7986 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 841us/step - loss: 0.4216 - accuracy: 0.7986 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4216 - accuracy: 0.7986 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 863us/step - loss: 0.4216 - accuracy: 0.7986 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4215 - accuracy: 0.7986 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 881us/step - loss: 0.4216 - accuracy: 0.8003 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4215 - accuracy: 0.7986 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4215 - accuracy: 0.7986 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4215 - accuracy: 0.7986 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 848us/step - loss: 0.4215 - accuracy: 0.7986 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 862us/step - loss: 0.4215 - accuracy: 0.7986 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4214 - accuracy: 0.8003 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8003 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 841us/step - loss: 0.4214 - accuracy: 0.7986 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 863us/step - loss: 0.4214 - accuracy: 0.7986 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 871us/step - loss: 0.4214 - accuracy: 0.8003 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 869us/step - loss: 0.4213 - accuracy: 0.7986 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 867us/step - loss: 0.4214 - accuracy: 0.7986 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 876us/step - loss: 0.4213 - accuracy: 0.7986 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 863us/step - loss: 0.4213 - accuracy: 0.8003 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4213 - accuracy: 0.7986 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4213 - accuracy: 0.7986 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4213 - accuracy: 0.8003 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4213 - accuracy: 0.7986 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4212 - accuracy: 0.7986 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 877us/step - loss: 0.4212 - accuracy: 0.8003 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 873us/step - loss: 0.4212 - accuracy: 0.7986 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4212 - accuracy: 0.8003 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 916us/step - loss: 0.4212 - accuracy: 0.7986 - val_loss: 0.5148 - val_accuracy: 0.7500\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 969us/step - loss: 0.4212 - accuracy: 0.8021 - val_loss: 0.5148 - val_accuracy: 0.7500\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4211 - accuracy: 0.8021 - val_loss: 0.5148 - val_accuracy: 0.7500\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4211 - accuracy: 0.8003 - val_loss: 0.5148 - val_accuracy: 0.7500\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4211 - accuracy: 0.7986 - val_loss: 0.5148 - val_accuracy: 0.7500\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 968us/step - loss: 0.4211 - accuracy: 0.8003 - val_loss: 0.5148 - val_accuracy: 0.7448\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 980us/step - loss: 0.4211 - accuracy: 0.8021 - val_loss: 0.5148 - val_accuracy: 0.7448\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 957us/step - loss: 0.4211 - accuracy: 0.8003 - val_loss: 0.5148 - val_accuracy: 0.7448\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 945us/step - loss: 0.4210 - accuracy: 0.8021 - val_loss: 0.5149 - val_accuracy: 0.7448\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.8003 - val_loss: 0.5149 - val_accuracy: 0.7448\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4210 - accuracy: 0.8021 - val_loss: 0.5149 - val_accuracy: 0.7448\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 912us/step - loss: 0.4210 - accuracy: 0.8003 - val_loss: 0.5149 - val_accuracy: 0.7448\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 874us/step - loss: 0.4210 - accuracy: 0.8003 - val_loss: 0.5149 - val_accuracy: 0.7448\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 851us/step - loss: 0.4209 - accuracy: 0.8021 - val_loss: 0.5149 - val_accuracy: 0.7448\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 867us/step - loss: 0.4209 - accuracy: 0.8003 - val_loss: 0.5149 - val_accuracy: 0.7448\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.4210 - accuracy: 0.8021 - val_loss: 0.5149 - val_accuracy: 0.7448\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4209 - accuracy: 0.8003 - val_loss: 0.5149 - val_accuracy: 0.7448\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4209 - accuracy: 0.8003 - val_loss: 0.5149 - val_accuracy: 0.7448\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4209 - accuracy: 0.8021 - val_loss: 0.5149 - val_accuracy: 0.7448\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4209 - accuracy: 0.8003 - val_loss: 0.5150 - val_accuracy: 0.7448\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4209 - accuracy: 0.8038 - val_loss: 0.5150 - val_accuracy: 0.7448\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4208 - accuracy: 0.8003 - val_loss: 0.5150 - val_accuracy: 0.7448\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.4208 - accuracy: 0.8021 - val_loss: 0.5150 - val_accuracy: 0.7448\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4208 - accuracy: 0.7986 - val_loss: 0.5150 - val_accuracy: 0.7448\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4208 - accuracy: 0.8003 - val_loss: 0.5150 - val_accuracy: 0.7448\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 909us/step - loss: 0.4208 - accuracy: 0.8021 - val_loss: 0.5150 - val_accuracy: 0.7448\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 944us/step - loss: 0.4208 - accuracy: 0.8003 - val_loss: 0.5150 - val_accuracy: 0.7448\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 912us/step - loss: 0.4208 - accuracy: 0.8003 - val_loss: 0.5151 - val_accuracy: 0.7448\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 938us/step - loss: 0.4208 - accuracy: 0.8003 - val_loss: 0.5151 - val_accuracy: 0.7448\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4207 - accuracy: 0.8021 - val_loss: 0.5151 - val_accuracy: 0.7448\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 908us/step - loss: 0.4207 - accuracy: 0.8003 - val_loss: 0.5151 - val_accuracy: 0.7448\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4207 - accuracy: 0.8021 - val_loss: 0.5151 - val_accuracy: 0.7448\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4207 - accuracy: 0.8021 - val_loss: 0.5151 - val_accuracy: 0.7448\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4207 - accuracy: 0.8021 - val_loss: 0.5151 - val_accuracy: 0.7448\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 952us/step - loss: 0.4207 - accuracy: 0.8021 - val_loss: 0.5151 - val_accuracy: 0.7448\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 964us/step - loss: 0.4206 - accuracy: 0.8021 - val_loss: 0.5151 - val_accuracy: 0.7448\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4206 - accuracy: 0.8021 - val_loss: 0.5151 - val_accuracy: 0.7448\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 879us/step - loss: 0.4206 - accuracy: 0.8003 - val_loss: 0.5152 - val_accuracy: 0.7448\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 877us/step - loss: 0.4206 - accuracy: 0.8021 - val_loss: 0.5152 - val_accuracy: 0.7448\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 887us/step - loss: 0.4206 - accuracy: 0.8021 - val_loss: 0.5152 - val_accuracy: 0.7448\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 921us/step - loss: 0.4206 - accuracy: 0.8003 - val_loss: 0.5152 - val_accuracy: 0.7448\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 921us/step - loss: 0.4205 - accuracy: 0.8003 - val_loss: 0.5152 - val_accuracy: 0.7448\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4205 - accuracy: 0.8021 - val_loss: 0.5152 - val_accuracy: 0.7448\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 923us/step - loss: 0.4205 - accuracy: 0.8021 - val_loss: 0.5152 - val_accuracy: 0.7448\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 895us/step - loss: 0.4205 - accuracy: 0.8021 - val_loss: 0.5152 - val_accuracy: 0.7448\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 961us/step - loss: 0.4205 - accuracy: 0.7986 - val_loss: 0.5152 - val_accuracy: 0.7448\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.8021 - val_loss: 0.5152 - val_accuracy: 0.7448\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.8021 - val_loss: 0.5153 - val_accuracy: 0.7448\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 966us/step - loss: 0.4204 - accuracy: 0.8003 - val_loss: 0.5153 - val_accuracy: 0.7448\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 939us/step - loss: 0.4204 - accuracy: 0.8003 - val_loss: 0.5153 - val_accuracy: 0.7448\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 914us/step - loss: 0.4204 - accuracy: 0.8021 - val_loss: 0.5153 - val_accuracy: 0.7448\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4204 - accuracy: 0.8021 - val_loss: 0.5153 - val_accuracy: 0.7448\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4204 - accuracy: 0.8038 - val_loss: 0.5153 - val_accuracy: 0.7448\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 852us/step - loss: 0.4204 - accuracy: 0.8038 - val_loss: 0.5153 - val_accuracy: 0.7448\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 895us/step - loss: 0.4204 - accuracy: 0.8003 - val_loss: 0.5153 - val_accuracy: 0.7448\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4203 - accuracy: 0.8021 - val_loss: 0.5153 - val_accuracy: 0.7448\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 858us/step - loss: 0.4204 - accuracy: 0.8021 - val_loss: 0.5153 - val_accuracy: 0.7448\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4203 - accuracy: 0.8021 - val_loss: 0.5153 - val_accuracy: 0.7448\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4203 - accuracy: 0.8021 - val_loss: 0.5153 - val_accuracy: 0.7448\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 867us/step - loss: 0.4203 - accuracy: 0.8021 - val_loss: 0.5153 - val_accuracy: 0.7448\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4203 - accuracy: 0.8021 - val_loss: 0.5153 - val_accuracy: 0.7448\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 942us/step - loss: 0.4202 - accuracy: 0.8021 - val_loss: 0.5154 - val_accuracy: 0.7448\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 936us/step - loss: 0.4202 - accuracy: 0.8003 - val_loss: 0.5154 - val_accuracy: 0.7448\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 918us/step - loss: 0.4203 - accuracy: 0.8021 - val_loss: 0.5154 - val_accuracy: 0.7448\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 940us/step - loss: 0.4202 - accuracy: 0.8021 - val_loss: 0.5154 - val_accuracy: 0.7448\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 920us/step - loss: 0.4202 - accuracy: 0.8038 - val_loss: 0.5154 - val_accuracy: 0.7448\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 934us/step - loss: 0.4202 - accuracy: 0.8021 - val_loss: 0.5154 - val_accuracy: 0.7448\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4202 - accuracy: 0.8021 - val_loss: 0.5154 - val_accuracy: 0.7448\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.4201 - accuracy: 0.8021 - val_loss: 0.5154 - val_accuracy: 0.7448\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 960us/step - loss: 0.4201 - accuracy: 0.8021 - val_loss: 0.5154 - val_accuracy: 0.7448\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 895us/step - loss: 0.4201 - accuracy: 0.8021 - val_loss: 0.5154 - val_accuracy: 0.7448\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 875us/step - loss: 0.4201 - accuracy: 0.8021 - val_loss: 0.5154 - val_accuracy: 0.7448\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 875us/step - loss: 0.4201 - accuracy: 0.8021 - val_loss: 0.5154 - val_accuracy: 0.7448\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 866us/step - loss: 0.4201 - accuracy: 0.8021 - val_loss: 0.5155 - val_accuracy: 0.7448\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 873us/step - loss: 0.4200 - accuracy: 0.8021 - val_loss: 0.5155 - val_accuracy: 0.7448\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 875us/step - loss: 0.4201 - accuracy: 0.8021 - val_loss: 0.5155 - val_accuracy: 0.7448\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 857us/step - loss: 0.4201 - accuracy: 0.8021 - val_loss: 0.5155 - val_accuracy: 0.7448\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 862us/step - loss: 0.4200 - accuracy: 0.8021 - val_loss: 0.5155 - val_accuracy: 0.7448\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8003 - val_loss: 0.5155 - val_accuracy: 0.7448\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4200 - accuracy: 0.8021 - val_loss: 0.5155 - val_accuracy: 0.7448\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4200 - accuracy: 0.8021 - val_loss: 0.5155 - val_accuracy: 0.7448\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 879us/step - loss: 0.4200 - accuracy: 0.8038 - val_loss: 0.5155 - val_accuracy: 0.7448\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 869us/step - loss: 0.4200 - accuracy: 0.8003 - val_loss: 0.5155 - val_accuracy: 0.7448\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 863us/step - loss: 0.4200 - accuracy: 0.8021 - val_loss: 0.5156 - val_accuracy: 0.7448\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4199 - accuracy: 0.8021 - val_loss: 0.5156 - val_accuracy: 0.7448\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 884us/step - loss: 0.4199 - accuracy: 0.8021 - val_loss: 0.5156 - val_accuracy: 0.7448\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4199 - accuracy: 0.8021 - val_loss: 0.5156 - val_accuracy: 0.7448\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4199 - accuracy: 0.8003 - val_loss: 0.5156 - val_accuracy: 0.7448\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 869us/step - loss: 0.4198 - accuracy: 0.8003 - val_loss: 0.5156 - val_accuracy: 0.7448\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 875us/step - loss: 0.4199 - accuracy: 0.8021 - val_loss: 0.5156 - val_accuracy: 0.7448\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 885us/step - loss: 0.4198 - accuracy: 0.8021 - val_loss: 0.5156 - val_accuracy: 0.7448\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 962us/step - loss: 0.4198 - accuracy: 0.8003 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4199 - accuracy: 0.8003 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 850us/step - loss: 0.4198 - accuracy: 0.8003 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 871us/step - loss: 0.4198 - accuracy: 0.8003 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 909us/step - loss: 0.4197 - accuracy: 0.8003 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 864us/step - loss: 0.4198 - accuracy: 0.8003 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 874us/step - loss: 0.4197 - accuracy: 0.8021 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 865us/step - loss: 0.4197 - accuracy: 0.8003 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 867us/step - loss: 0.4197 - accuracy: 0.8003 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4197 - accuracy: 0.8003 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4197 - accuracy: 0.8021 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 868us/step - loss: 0.4197 - accuracy: 0.8003 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 874us/step - loss: 0.4197 - accuracy: 0.8003 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 864us/step - loss: 0.4197 - accuracy: 0.8003 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 868us/step - loss: 0.4196 - accuracy: 0.8003 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 867us/step - loss: 0.4196 - accuracy: 0.8003 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4196 - accuracy: 0.8003 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8003 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 868us/step - loss: 0.4196 - accuracy: 0.8003 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.4196 - accuracy: 0.8003 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 872us/step - loss: 0.4195 - accuracy: 0.8003 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4195 - accuracy: 0.8003 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 870us/step - loss: 0.4195 - accuracy: 0.8003 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 854us/step - loss: 0.4195 - accuracy: 0.8003 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 848us/step - loss: 0.4195 - accuracy: 0.8003 - val_loss: 0.5159 - val_accuracy: 0.7448\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 895us/step - loss: 0.4195 - accuracy: 0.8003 - val_loss: 0.5160 - val_accuracy: 0.7448\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 846us/step - loss: 0.4195 - accuracy: 0.8003 - val_loss: 0.5160 - val_accuracy: 0.7448\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 857us/step - loss: 0.4195 - accuracy: 0.8003 - val_loss: 0.5160 - val_accuracy: 0.7448\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 865us/step - loss: 0.4194 - accuracy: 0.8003 - val_loss: 0.5160 - val_accuracy: 0.7448\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 853us/step - loss: 0.4194 - accuracy: 0.8003 - val_loss: 0.5160 - val_accuracy: 0.7448\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 916us/step - loss: 0.4194 - accuracy: 0.8003 - val_loss: 0.5160 - val_accuracy: 0.7448\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 854us/step - loss: 0.4194 - accuracy: 0.8003 - val_loss: 0.5160 - val_accuracy: 0.7448\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4194 - accuracy: 0.8003 - val_loss: 0.5160 - val_accuracy: 0.7448\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 877us/step - loss: 0.4194 - accuracy: 0.8003 - val_loss: 0.5160 - val_accuracy: 0.7448\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 927us/step - loss: 0.4193 - accuracy: 0.8003 - val_loss: 0.5161 - val_accuracy: 0.7448\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.4194 - accuracy: 0.8003 - val_loss: 0.5161 - val_accuracy: 0.7448\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 860us/step - loss: 0.4194 - accuracy: 0.8003 - val_loss: 0.5161 - val_accuracy: 0.7448\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 877us/step - loss: 0.4193 - accuracy: 0.8003 - val_loss: 0.5161 - val_accuracy: 0.7448\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4193 - accuracy: 0.8003 - val_loss: 0.5161 - val_accuracy: 0.7448\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 909us/step - loss: 0.4193 - accuracy: 0.8003 - val_loss: 0.5161 - val_accuracy: 0.7448\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 887us/step - loss: 0.4193 - accuracy: 0.8003 - val_loss: 0.5161 - val_accuracy: 0.7448\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.4193 - accuracy: 0.8003 - val_loss: 0.5161 - val_accuracy: 0.7448\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 884us/step - loss: 0.4193 - accuracy: 0.8003 - val_loss: 0.5161 - val_accuracy: 0.7448\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 872us/step - loss: 0.4192 - accuracy: 0.8003 - val_loss: 0.5162 - val_accuracy: 0.7448\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 872us/step - loss: 0.4192 - accuracy: 0.8021 - val_loss: 0.5162 - val_accuracy: 0.7448\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4192 - accuracy: 0.8003 - val_loss: 0.5162 - val_accuracy: 0.7448\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 876us/step - loss: 0.4192 - accuracy: 0.8003 - val_loss: 0.5162 - val_accuracy: 0.7448\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.4192 - accuracy: 0.8003 - val_loss: 0.5162 - val_accuracy: 0.7448\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8003 - val_loss: 0.5162 - val_accuracy: 0.7448\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4192 - accuracy: 0.8003 - val_loss: 0.5162 - val_accuracy: 0.7448\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 846us/step - loss: 0.4192 - accuracy: 0.8003 - val_loss: 0.5162 - val_accuracy: 0.7448\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 848us/step - loss: 0.4191 - accuracy: 0.8003 - val_loss: 0.5162 - val_accuracy: 0.7448\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 879us/step - loss: 0.4192 - accuracy: 0.8003 - val_loss: 0.5162 - val_accuracy: 0.7448\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 856us/step - loss: 0.4191 - accuracy: 0.8003 - val_loss: 0.5163 - val_accuracy: 0.7448\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 861us/step - loss: 0.4191 - accuracy: 0.8003 - val_loss: 0.5163 - val_accuracy: 0.7448\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.4191 - accuracy: 0.8003 - val_loss: 0.5163 - val_accuracy: 0.7448\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 881us/step - loss: 0.4191 - accuracy: 0.8003 - val_loss: 0.5163 - val_accuracy: 0.7448\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 845us/step - loss: 0.4191 - accuracy: 0.8003 - val_loss: 0.5163 - val_accuracy: 0.7448\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 848us/step - loss: 0.4190 - accuracy: 0.8003 - val_loss: 0.5163 - val_accuracy: 0.7448\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 840us/step - loss: 0.4190 - accuracy: 0.8003 - val_loss: 0.5163 - val_accuracy: 0.7448\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 861us/step - loss: 0.4190 - accuracy: 0.8003 - val_loss: 0.5163 - val_accuracy: 0.7448\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 825us/step - loss: 0.4190 - accuracy: 0.8003 - val_loss: 0.5163 - val_accuracy: 0.7448\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 876us/step - loss: 0.4190 - accuracy: 0.8003 - val_loss: 0.5163 - val_accuracy: 0.7448\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4190 - accuracy: 0.8003 - val_loss: 0.5164 - val_accuracy: 0.7448\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 904us/step - loss: 0.4190 - accuracy: 0.8021 - val_loss: 0.5164 - val_accuracy: 0.7448\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4190 - accuracy: 0.8003 - val_loss: 0.5164 - val_accuracy: 0.7448\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.4189 - accuracy: 0.8003 - val_loss: 0.5164 - val_accuracy: 0.7448\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 895us/step - loss: 0.4189 - accuracy: 0.8003 - val_loss: 0.5164 - val_accuracy: 0.7448\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 901us/step - loss: 0.4189 - accuracy: 0.8003 - val_loss: 0.5164 - val_accuracy: 0.7448\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4189 - accuracy: 0.8003 - val_loss: 0.5164 - val_accuracy: 0.7448\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.4189 - accuracy: 0.8003 - val_loss: 0.5164 - val_accuracy: 0.7448\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 875us/step - loss: 0.4189 - accuracy: 0.8003 - val_loss: 0.5164 - val_accuracy: 0.7448\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 879us/step - loss: 0.4189 - accuracy: 0.8003 - val_loss: 0.5164 - val_accuracy: 0.7448\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 914us/step - loss: 0.4188 - accuracy: 0.8003 - val_loss: 0.5165 - val_accuracy: 0.7448\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8003 - val_loss: 0.5165 - val_accuracy: 0.7448\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4188 - accuracy: 0.8003 - val_loss: 0.5165 - val_accuracy: 0.7448\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 901us/step - loss: 0.4188 - accuracy: 0.8003 - val_loss: 0.5165 - val_accuracy: 0.7448\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4188 - accuracy: 0.8003 - val_loss: 0.5165 - val_accuracy: 0.7448\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4188 - accuracy: 0.8021 - val_loss: 0.5165 - val_accuracy: 0.7448\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 863us/step - loss: 0.4187 - accuracy: 0.8003 - val_loss: 0.5165 - val_accuracy: 0.7448\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 862us/step - loss: 0.4188 - accuracy: 0.8003 - val_loss: 0.5165 - val_accuracy: 0.7448\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 905us/step - loss: 0.4187 - accuracy: 0.8003 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 895us/step - loss: 0.4188 - accuracy: 0.8003 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 856us/step - loss: 0.4187 - accuracy: 0.8003 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 878us/step - loss: 0.4187 - accuracy: 0.8003 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 855us/step - loss: 0.4187 - accuracy: 0.8021 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 862us/step - loss: 0.4186 - accuracy: 0.8003 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 854us/step - loss: 0.4186 - accuracy: 0.8003 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 851us/step - loss: 0.4186 - accuracy: 0.8003 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4186 - accuracy: 0.8003 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4186 - accuracy: 0.8021 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 865us/step - loss: 0.4186 - accuracy: 0.8003 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4186 - accuracy: 0.8003 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 878us/step - loss: 0.4185 - accuracy: 0.8003 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 912us/step - loss: 0.4185 - accuracy: 0.8003 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 857us/step - loss: 0.4185 - accuracy: 0.8003 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 881us/step - loss: 0.4185 - accuracy: 0.8003 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 872us/step - loss: 0.4185 - accuracy: 0.8003 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 901us/step - loss: 0.4185 - accuracy: 0.8003 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4185 - accuracy: 0.8003 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8021 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 855us/step - loss: 0.4185 - accuracy: 0.8003 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 855us/step - loss: 0.4185 - accuracy: 0.8003 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 852us/step - loss: 0.4184 - accuracy: 0.8003 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 875us/step - loss: 0.4185 - accuracy: 0.8003 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 869us/step - loss: 0.4184 - accuracy: 0.8003 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 850us/step - loss: 0.4184 - accuracy: 0.8021 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 928us/step - loss: 0.4184 - accuracy: 0.8003 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 861us/step - loss: 0.4183 - accuracy: 0.8003 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 848us/step - loss: 0.4183 - accuracy: 0.8003 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 832us/step - loss: 0.4183 - accuracy: 0.8003 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 853us/step - loss: 0.4183 - accuracy: 0.8003 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 841us/step - loss: 0.4183 - accuracy: 0.8003 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 914us/step - loss: 0.4183 - accuracy: 0.8021 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 868us/step - loss: 0.4182 - accuracy: 0.8003 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 958us/step - loss: 0.4183 - accuracy: 0.8003 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4182 - accuracy: 0.8003 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 840us/step - loss: 0.4182 - accuracy: 0.8021 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 901us/step - loss: 0.4182 - accuracy: 0.8003 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 873us/step - loss: 0.4182 - accuracy: 0.8003 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 868us/step - loss: 0.4182 - accuracy: 0.8003 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 895us/step - loss: 0.4182 - accuracy: 0.8003 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 908us/step - loss: 0.4182 - accuracy: 0.8003 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 887us/step - loss: 0.4182 - accuracy: 0.8021 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8003 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 852us/step - loss: 0.4181 - accuracy: 0.8021 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 865us/step - loss: 0.4181 - accuracy: 0.8021 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4181 - accuracy: 0.8003 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4181 - accuracy: 0.8003 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4181 - accuracy: 0.8021 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 949us/step - loss: 0.4180 - accuracy: 0.8003 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4180 - accuracy: 0.7986 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4180 - accuracy: 0.7986 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4180 - accuracy: 0.7986 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4180 - accuracy: 0.8003 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4180 - accuracy: 0.8021 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 855us/step - loss: 0.4179 - accuracy: 0.7986 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 852us/step - loss: 0.4180 - accuracy: 0.8003 - val_loss: 0.5170 - val_accuracy: 0.7500\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4180 - accuracy: 0.8003 - val_loss: 0.5170 - val_accuracy: 0.7500\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 913us/step - loss: 0.4180 - accuracy: 0.7986 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4179 - accuracy: 0.7969 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 850us/step - loss: 0.4179 - accuracy: 0.7986 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 843us/step - loss: 0.4179 - accuracy: 0.7986 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 927us/step - loss: 0.4178 - accuracy: 0.7969 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 861us/step - loss: 0.4179 - accuracy: 0.7969 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 840us/step - loss: 0.4179 - accuracy: 0.7986 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 974us/step - loss: 0.4178 - accuracy: 0.7969 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 870us/step - loss: 0.4178 - accuracy: 0.8003 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4178 - accuracy: 0.7986 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7986 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 895us/step - loss: 0.4178 - accuracy: 0.7969 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 906us/step - loss: 0.4177 - accuracy: 0.7986 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.4177 - accuracy: 0.7986 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 879us/step - loss: 0.4178 - accuracy: 0.7986 - val_loss: 0.5172 - val_accuracy: 0.7500\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 905us/step - loss: 0.4177 - accuracy: 0.7986 - val_loss: 0.5172 - val_accuracy: 0.7500\n",
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4177 - accuracy: 0.7969 - val_loss: 0.5172 - val_accuracy: 0.7500\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4177 - accuracy: 0.7986 - val_loss: 0.5172 - val_accuracy: 0.7500\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 924us/step - loss: 0.4177 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7500\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 864us/step - loss: 0.4177 - accuracy: 0.7986 - val_loss: 0.5172 - val_accuracy: 0.7500\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4177 - accuracy: 0.8003 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 842us/step - loss: 0.4176 - accuracy: 0.7986 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 887us/step - loss: 0.4176 - accuracy: 0.7986 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4176 - accuracy: 0.7986 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 867us/step - loss: 0.4176 - accuracy: 0.7986 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 878us/step - loss: 0.4176 - accuracy: 0.7969 - val_loss: 0.5172 - val_accuracy: 0.7500\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 908us/step - loss: 0.4176 - accuracy: 0.7986 - val_loss: 0.5172 - val_accuracy: 0.7500\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4175 - accuracy: 0.7986 - val_loss: 0.5172 - val_accuracy: 0.7500\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 881us/step - loss: 0.4175 - accuracy: 0.7986 - val_loss: 0.5172 - val_accuracy: 0.7500\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 877us/step - loss: 0.4175 - accuracy: 0.7986 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 901us/step - loss: 0.4175 - accuracy: 0.7986 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 863us/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 866us/step - loss: 0.4174 - accuracy: 0.7986 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 884us/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 864us/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 884us/step - loss: 0.4174 - accuracy: 0.7986 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 922us/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 931us/step - loss: 0.4173 - accuracy: 0.8003 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 869us/step - loss: 0.4173 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 942us/step - loss: 0.4173 - accuracy: 0.8003 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 864us/step - loss: 0.4173 - accuracy: 0.8003 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 925us/step - loss: 0.4173 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 866us/step - loss: 0.4173 - accuracy: 0.8003 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 859us/step - loss: 0.4172 - accuracy: 0.8038 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8003 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4173 - accuracy: 0.8003 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4172 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4172 - accuracy: 0.8003 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4172 - accuracy: 0.8003 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 952us/step - loss: 0.4172 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 982us/step - loss: 0.4171 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 989us/step - loss: 0.4171 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 973us/step - loss: 0.4171 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4171 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4171 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4171 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4170 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 915us/step - loss: 0.4170 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 928us/step - loss: 0.4170 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 958us/step - loss: 0.4170 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 968us/step - loss: 0.4170 - accuracy: 0.8003 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 992us/step - loss: 0.4170 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 920us/step - loss: 0.4169 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4169 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4169 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 833us/step - loss: 0.4169 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 853us/step - loss: 0.4168 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 834us/step - loss: 0.4169 - accuracy: 0.8003 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 845us/step - loss: 0.4168 - accuracy: 0.8003 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 844us/step - loss: 0.4168 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 863us/step - loss: 0.4168 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 830us/step - loss: 0.4168 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 850us/step - loss: 0.4167 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 884us/step - loss: 0.4167 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4167 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 944us/step - loss: 0.4167 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 908us/step - loss: 0.4167 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 905us/step - loss: 0.4166 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4166 - accuracy: 0.8021 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4166 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 877us/step - loss: 0.4166 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 917us/step - loss: 0.4166 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4165 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 868us/step - loss: 0.4165 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4165 - accuracy: 0.8021 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4165 - accuracy: 0.8021 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4165 - accuracy: 0.8021 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 860us/step - loss: 0.4165 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4164 - accuracy: 0.8003 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 866us/step - loss: 0.4165 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 950us/step - loss: 0.4165 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4164 - accuracy: 0.8021 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 875us/step - loss: 0.4164 - accuracy: 0.8021 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 868us/step - loss: 0.4164 - accuracy: 0.8021 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 828us/step - loss: 0.4164 - accuracy: 0.8021 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 829us/step - loss: 0.4164 - accuracy: 0.8021 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 863us/step - loss: 0.4163 - accuracy: 0.8021 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 825us/step - loss: 0.4164 - accuracy: 0.8021 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 818us/step - loss: 0.4163 - accuracy: 0.8003 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 867us/step - loss: 0.4163 - accuracy: 0.8021 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 808us/step - loss: 0.4163 - accuracy: 0.8021 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 822us/step - loss: 0.4163 - accuracy: 0.8021 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 814us/step - loss: 0.4163 - accuracy: 0.8021 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8021 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8021 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4162 - accuracy: 0.8021 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4162 - accuracy: 0.8021 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4161 - accuracy: 0.8021 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 930us/step - loss: 0.4161 - accuracy: 0.8021 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 951us/step - loss: 0.4162 - accuracy: 0.8021 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 939us/step - loss: 0.4161 - accuracy: 0.8021 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.8021 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.4161 - accuracy: 0.8021 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 915us/step - loss: 0.4161 - accuracy: 0.8021 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.4161 - accuracy: 0.8021 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 909us/step - loss: 0.4160 - accuracy: 0.8021 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4161 - accuracy: 0.8021 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 952us/step - loss: 0.4160 - accuracy: 0.8021 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 928us/step - loss: 0.4160 - accuracy: 0.8021 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 937us/step - loss: 0.4160 - accuracy: 0.8021 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.4160 - accuracy: 0.8021 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 935us/step - loss: 0.4159 - accuracy: 0.8021 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4160 - accuracy: 0.8021 - val_loss: 0.5174 - val_accuracy: 0.7500\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4160 - accuracy: 0.8021 - val_loss: 0.5174 - val_accuracy: 0.7500\n",
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.8021 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4159 - accuracy: 0.8021 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4159 - accuracy: 0.8021 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 991us/step - loss: 0.4159 - accuracy: 0.8003 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 974us/step - loss: 0.4159 - accuracy: 0.8021 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4158 - accuracy: 0.8003 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 915us/step - loss: 0.4158 - accuracy: 0.8021 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 949us/step - loss: 0.4158 - accuracy: 0.8003 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4158 - accuracy: 0.8021 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 873us/step - loss: 0.4158 - accuracy: 0.8021 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 865us/step - loss: 0.4158 - accuracy: 0.8021 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 945us/step - loss: 0.4157 - accuracy: 0.8003 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 878us/step - loss: 0.4157 - accuracy: 0.8021 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 864us/step - loss: 0.4157 - accuracy: 0.8021 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 887us/step - loss: 0.4157 - accuracy: 0.8021 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 927us/step - loss: 0.4157 - accuracy: 0.8021 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 940us/step - loss: 0.4157 - accuracy: 0.8003 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 873us/step - loss: 0.4157 - accuracy: 0.8003 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4156 - accuracy: 0.8021 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.8021 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 844us/step - loss: 0.4156 - accuracy: 0.8021 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 840us/step - loss: 0.4156 - accuracy: 0.8021 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 857us/step - loss: 0.4156 - accuracy: 0.8021 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 806us/step - loss: 0.4156 - accuracy: 0.8021 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 834us/step - loss: 0.4156 - accuracy: 0.8003 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 810us/step - loss: 0.4155 - accuracy: 0.8021 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8021 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 887us/step - loss: 0.4155 - accuracy: 0.8021 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 853us/step - loss: 0.4155 - accuracy: 0.8038 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 861us/step - loss: 0.4155 - accuracy: 0.8021 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 862us/step - loss: 0.4155 - accuracy: 0.8003 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 805us/step - loss: 0.4155 - accuracy: 0.8021 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 862us/step - loss: 0.4154 - accuracy: 0.8021 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 820us/step - loss: 0.4155 - accuracy: 0.8038 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 836us/step - loss: 0.4154 - accuracy: 0.8021 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 794us/step - loss: 0.4154 - accuracy: 0.8038 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4154 - accuracy: 0.8003 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.8021 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 843us/step - loss: 0.4154 - accuracy: 0.8038 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 835us/step - loss: 0.4154 - accuracy: 0.8021 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 857us/step - loss: 0.4154 - accuracy: 0.8021 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 835us/step - loss: 0.4153 - accuracy: 0.8021 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 845us/step - loss: 0.4153 - accuracy: 0.8003 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 812us/step - loss: 0.4153 - accuracy: 0.8021 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 806us/step - loss: 0.4153 - accuracy: 0.8038 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4153 - accuracy: 0.8038 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 844us/step - loss: 0.4153 - accuracy: 0.8038 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.4153 - accuracy: 0.8038 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 850us/step - loss: 0.4152 - accuracy: 0.8038 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 856us/step - loss: 0.4152 - accuracy: 0.8021 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 825us/step - loss: 0.4152 - accuracy: 0.8021 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 826us/step - loss: 0.4152 - accuracy: 0.8038 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 844us/step - loss: 0.4152 - accuracy: 0.8021 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 813us/step - loss: 0.4152 - accuracy: 0.8021 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4151 - accuracy: 0.8038 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8038 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 850us/step - loss: 0.4151 - accuracy: 0.8038 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 839us/step - loss: 0.4151 - accuracy: 0.8038 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4151 - accuracy: 0.8038 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 990us/step - loss: 0.4151 - accuracy: 0.8038 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 931us/step - loss: 0.4150 - accuracy: 0.8038 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4151 - accuracy: 0.8038 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 948us/step - loss: 0.4150 - accuracy: 0.8021 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 998us/step - loss: 0.4150 - accuracy: 0.8038 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4150 - accuracy: 0.8038 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 838us/step - loss: 0.4150 - accuracy: 0.8021 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 834us/step - loss: 0.4149 - accuracy: 0.8038 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 832us/step - loss: 0.4150 - accuracy: 0.8038 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 839us/step - loss: 0.4149 - accuracy: 0.8038 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 854us/step - loss: 0.4149 - accuracy: 0.8038 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 833us/step - loss: 0.4149 - accuracy: 0.8038 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 851us/step - loss: 0.4149 - accuracy: 0.8038 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.8038 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4149 - accuracy: 0.8038 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 819us/step - loss: 0.4149 - accuracy: 0.8038 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 843us/step - loss: 0.4148 - accuracy: 0.8038 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 813us/step - loss: 0.4148 - accuracy: 0.8038 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 859us/step - loss: 0.4148 - accuracy: 0.8038 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.4148 - accuracy: 0.8038 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 828us/step - loss: 0.4148 - accuracy: 0.8038 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 834us/step - loss: 0.4148 - accuracy: 0.8038 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4147 - accuracy: 0.8038 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 841us/step - loss: 0.4147 - accuracy: 0.8038 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 805us/step - loss: 0.4147 - accuracy: 0.8038 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 820us/step - loss: 0.4147 - accuracy: 0.8038 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 821us/step - loss: 0.4147 - accuracy: 0.8038 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 853us/step - loss: 0.4147 - accuracy: 0.8038 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 816us/step - loss: 0.4147 - accuracy: 0.8038 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4146 - accuracy: 0.8038 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8038 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8038 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 834us/step - loss: 0.4146 - accuracy: 0.8038 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 826us/step - loss: 0.4146 - accuracy: 0.8038 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 856us/step - loss: 0.4146 - accuracy: 0.8038 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 827us/step - loss: 0.4146 - accuracy: 0.8038 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 819us/step - loss: 0.4145 - accuracy: 0.8038 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.4146 - accuracy: 0.8021 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 857us/step - loss: 0.4145 - accuracy: 0.8038 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 841us/step - loss: 0.4145 - accuracy: 0.8038 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4145 - accuracy: 0.8038 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 818us/step - loss: 0.4145 - accuracy: 0.8038 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 827us/step - loss: 0.4145 - accuracy: 0.8038 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 822us/step - loss: 0.4145 - accuracy: 0.8038 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 857us/step - loss: 0.4144 - accuracy: 0.8038 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 826us/step - loss: 0.4144 - accuracy: 0.8038 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.8038 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8038 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 852us/step - loss: 0.4143 - accuracy: 0.8038 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 920us/step - loss: 0.4143 - accuracy: 0.8038 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 925us/step - loss: 0.4143 - accuracy: 0.8038 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 870us/step - loss: 0.4144 - accuracy: 0.8038 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 943us/step - loss: 0.4143 - accuracy: 0.8038 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4143 - accuracy: 0.8038 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 862us/step - loss: 0.4143 - accuracy: 0.8038 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4142 - accuracy: 0.8038 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4143 - accuracy: 0.8038 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4143 - accuracy: 0.8038 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 832us/step - loss: 0.4142 - accuracy: 0.8038 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 919us/step - loss: 0.4142 - accuracy: 0.8038 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 931us/step - loss: 0.4142 - accuracy: 0.8038 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4142 - accuracy: 0.8056 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.8056 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4141 - accuracy: 0.8038 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.4141 - accuracy: 0.8038 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 914us/step - loss: 0.4141 - accuracy: 0.8038 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4141 - accuracy: 0.8056 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 863us/step - loss: 0.4141 - accuracy: 0.8038 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 923us/step - loss: 0.4141 - accuracy: 0.8038 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 885us/step - loss: 0.4141 - accuracy: 0.8038 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 914us/step - loss: 0.4141 - accuracy: 0.8056 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8038 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4140 - accuracy: 0.8056 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 992us/step - loss: 0.4140 - accuracy: 0.8056 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 973us/step - loss: 0.4140 - accuracy: 0.8056 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 979us/step - loss: 0.4140 - accuracy: 0.8038 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 922us/step - loss: 0.4140 - accuracy: 0.8038 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8056 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8056 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4139 - accuracy: 0.8056 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 980us/step - loss: 0.4139 - accuracy: 0.8073 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4139 - accuracy: 0.8056 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4139 - accuracy: 0.8090 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 999us/step - loss: 0.4139 - accuracy: 0.8038 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4139 - accuracy: 0.8038 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4138 - accuracy: 0.8056 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 950us/step - loss: 0.4138 - accuracy: 0.8073 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 877us/step - loss: 0.4138 - accuracy: 0.8073 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4138 - accuracy: 0.8073 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 935us/step - loss: 0.4138 - accuracy: 0.8073 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 885us/step - loss: 0.4138 - accuracy: 0.8056 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 868us/step - loss: 0.4138 - accuracy: 0.8073 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.4138 - accuracy: 0.8056 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 860us/step - loss: 0.4137 - accuracy: 0.8090 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.8073 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 869us/step - loss: 0.4136 - accuracy: 0.8056 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 851us/step - loss: 0.4137 - accuracy: 0.8073 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4136 - accuracy: 0.8073 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4137 - accuracy: 0.8090 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4136 - accuracy: 0.8056 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4136 - accuracy: 0.8056 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 949us/step - loss: 0.4136 - accuracy: 0.8073 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 964us/step - loss: 0.4136 - accuracy: 0.8056 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4136 - accuracy: 0.8073 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.8090 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 960us/step - loss: 0.4135 - accuracy: 0.8056 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 961us/step - loss: 0.4136 - accuracy: 0.8056 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 967us/step - loss: 0.4135 - accuracy: 0.8090 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4135 - accuracy: 0.8056 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4135 - accuracy: 0.8056 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 952us/step - loss: 0.4135 - accuracy: 0.8073 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4135 - accuracy: 0.8056 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8073 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 944us/step - loss: 0.4134 - accuracy: 0.8056 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 935us/step - loss: 0.4134 - accuracy: 0.8073 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 947us/step - loss: 0.4134 - accuracy: 0.8056 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 982us/step - loss: 0.4134 - accuracy: 0.8073 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 990us/step - loss: 0.4134 - accuracy: 0.8056 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 909us/step - loss: 0.4134 - accuracy: 0.8090 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 925us/step - loss: 0.4134 - accuracy: 0.8056 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4134 - accuracy: 0.8056 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.4133 - accuracy: 0.8073 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4133 - accuracy: 0.8073 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4133 - accuracy: 0.8056 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4133 - accuracy: 0.8073 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 925us/step - loss: 0.4133 - accuracy: 0.8073 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 940us/step - loss: 0.4133 - accuracy: 0.8073 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4132 - accuracy: 0.8056 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 944us/step - loss: 0.4133 - accuracy: 0.8073 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4132 - accuracy: 0.8090 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.8056 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 829us/step - loss: 0.4132 - accuracy: 0.8073 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 923us/step - loss: 0.4132 - accuracy: 0.8056 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 904us/step - loss: 0.4132 - accuracy: 0.8056 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4132 - accuracy: 0.8073 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4131 - accuracy: 0.8073 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4131 - accuracy: 0.8073 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 944us/step - loss: 0.4131 - accuracy: 0.8073 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 862us/step - loss: 0.4131 - accuracy: 0.8090 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 861us/step - loss: 0.4130 - accuracy: 0.8090 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4131 - accuracy: 0.8056 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 846us/step - loss: 0.4130 - accuracy: 0.8073 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4130 - accuracy: 0.8073 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4130 - accuracy: 0.8073 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 878us/step - loss: 0.4130 - accuracy: 0.8073 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 933us/step - loss: 0.4130 - accuracy: 0.8090 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 862us/step - loss: 0.4129 - accuracy: 0.8073 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 872us/step - loss: 0.4130 - accuracy: 0.8090 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8073 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4130 - accuracy: 0.8073 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 929us/step - loss: 0.4129 - accuracy: 0.8090 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4128 - accuracy: 0.8073 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 847us/step - loss: 0.4129 - accuracy: 0.8090 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 835us/step - loss: 0.4129 - accuracy: 0.8090 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 916us/step - loss: 0.4128 - accuracy: 0.8073 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 863us/step - loss: 0.4128 - accuracy: 0.8090 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 885us/step - loss: 0.4128 - accuracy: 0.8090 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 982us/step - loss: 0.4128 - accuracy: 0.8090 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 871us/step - loss: 0.4128 - accuracy: 0.8073 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 877us/step - loss: 0.4128 - accuracy: 0.8090 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4128 - accuracy: 0.8073 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4128 - accuracy: 0.8090 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 925us/step - loss: 0.4127 - accuracy: 0.8073 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.8073 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.8090 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4126 - accuracy: 0.8090 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 928us/step - loss: 0.4126 - accuracy: 0.8090 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 868us/step - loss: 0.4127 - accuracy: 0.8073 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4127 - accuracy: 0.8090 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 874us/step - loss: 0.4126 - accuracy: 0.8090 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4127 - accuracy: 0.8073 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 864us/step - loss: 0.4126 - accuracy: 0.8073 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 943us/step - loss: 0.4126 - accuracy: 0.8090 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 879us/step - loss: 0.4126 - accuracy: 0.8090 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4125 - accuracy: 0.8090 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4125 - accuracy: 0.8090 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 856us/step - loss: 0.4125 - accuracy: 0.8090 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 871us/step - loss: 0.4125 - accuracy: 0.8090 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4125 - accuracy: 0.8090 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4125 - accuracy: 0.8090 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 872us/step - loss: 0.4124 - accuracy: 0.8090 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.4125 - accuracy: 0.8073 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 912us/step - loss: 0.4124 - accuracy: 0.8090 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 860us/step - loss: 0.4124 - accuracy: 0.8073 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4124 - accuracy: 0.8090 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4124 - accuracy: 0.8090 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4124 - accuracy: 0.8090 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 874us/step - loss: 0.4124 - accuracy: 0.8073 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 915us/step - loss: 0.4123 - accuracy: 0.8090 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 904us/step - loss: 0.4123 - accuracy: 0.8090 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 940us/step - loss: 0.4123 - accuracy: 0.8090 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 901us/step - loss: 0.4123 - accuracy: 0.8090 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 926us/step - loss: 0.4123 - accuracy: 0.8090 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4123 - accuracy: 0.8090 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8090 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4122 - accuracy: 0.8090 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 914us/step - loss: 0.4122 - accuracy: 0.8073 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4122 - accuracy: 0.8073 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4122 - accuracy: 0.8090 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4122 - accuracy: 0.8090 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 928us/step - loss: 0.4122 - accuracy: 0.8073 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 881us/step - loss: 0.4121 - accuracy: 0.8090 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4121 - accuracy: 0.8090 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 930us/step - loss: 0.4122 - accuracy: 0.8090 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 865us/step - loss: 0.4121 - accuracy: 0.8090 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 942us/step - loss: 0.4121 - accuracy: 0.8090 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4121 - accuracy: 0.8090 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 875us/step - loss: 0.4121 - accuracy: 0.8090 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4121 - accuracy: 0.8073 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8073 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4120 - accuracy: 0.8090 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 863us/step - loss: 0.4120 - accuracy: 0.8090 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4120 - accuracy: 0.8090 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 938us/step - loss: 0.4120 - accuracy: 0.8090 - val_loss: 0.5197 - val_accuracy: 0.7500\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 867us/step - loss: 0.4120 - accuracy: 0.8090 - val_loss: 0.5197 - val_accuracy: 0.7500\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4120 - accuracy: 0.8090 - val_loss: 0.5197 - val_accuracy: 0.7500\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4119 - accuracy: 0.8090 - val_loss: 0.5197 - val_accuracy: 0.7500\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4120 - accuracy: 0.8073 - val_loss: 0.5197 - val_accuracy: 0.7500\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 879us/step - loss: 0.4119 - accuracy: 0.8090 - val_loss: 0.5197 - val_accuracy: 0.7500\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4119 - accuracy: 0.8090 - val_loss: 0.5197 - val_accuracy: 0.7500\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 863us/step - loss: 0.4119 - accuracy: 0.8090 - val_loss: 0.5197 - val_accuracy: 0.7500\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 972us/step - loss: 0.4119 - accuracy: 0.8073 - val_loss: 0.5197 - val_accuracy: 0.7500\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.4119 - accuracy: 0.8090 - val_loss: 0.5197 - val_accuracy: 0.7500\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8090 - val_loss: 0.5197 - val_accuracy: 0.7500\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 836us/step - loss: 0.4118 - accuracy: 0.8073 - val_loss: 0.5197 - val_accuracy: 0.7500\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4118 - accuracy: 0.8073 - val_loss: 0.5198 - val_accuracy: 0.7500\n",
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 939us/step - loss: 0.4118 - accuracy: 0.8090 - val_loss: 0.5198 - val_accuracy: 0.7500\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 956us/step - loss: 0.4118 - accuracy: 0.8073 - val_loss: 0.5198 - val_accuracy: 0.7500\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 972us/step - loss: 0.4118 - accuracy: 0.8090 - val_loss: 0.5198 - val_accuracy: 0.7500\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 966us/step - loss: 0.4118 - accuracy: 0.8073 - val_loss: 0.5198 - val_accuracy: 0.7500\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 862us/step - loss: 0.4117 - accuracy: 0.8073 - val_loss: 0.5198 - val_accuracy: 0.7500\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4118 - accuracy: 0.8073 - val_loss: 0.5198 - val_accuracy: 0.7500\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 833us/step - loss: 0.4118 - accuracy: 0.8090 - val_loss: 0.5198 - val_accuracy: 0.7500\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 963us/step - loss: 0.4117 - accuracy: 0.8090 - val_loss: 0.5198 - val_accuracy: 0.7500\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 863us/step - loss: 0.4117 - accuracy: 0.8073 - val_loss: 0.5198 - val_accuracy: 0.7500\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 955us/step - loss: 0.4117 - accuracy: 0.8073 - val_loss: 0.5198 - val_accuracy: 0.7500\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 850us/step - loss: 0.4117 - accuracy: 0.8073 - val_loss: 0.5198 - val_accuracy: 0.7500\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4116 - accuracy: 0.8090 - val_loss: 0.5198 - val_accuracy: 0.7500\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8073 - val_loss: 0.5199 - val_accuracy: 0.7500\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4117 - accuracy: 0.8108 - val_loss: 0.5199 - val_accuracy: 0.7500\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 866us/step - loss: 0.4117 - accuracy: 0.8073 - val_loss: 0.5199 - val_accuracy: 0.7500\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.4116 - accuracy: 0.8073 - val_loss: 0.5199 - val_accuracy: 0.7500\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 916us/step - loss: 0.4116 - accuracy: 0.8073 - val_loss: 0.5199 - val_accuracy: 0.7500\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 878us/step - loss: 0.4116 - accuracy: 0.8090 - val_loss: 0.5199 - val_accuracy: 0.7500\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4116 - accuracy: 0.8073 - val_loss: 0.5199 - val_accuracy: 0.7500\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4116 - accuracy: 0.8090 - val_loss: 0.5199 - val_accuracy: 0.7500\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4115 - accuracy: 0.8108 - val_loss: 0.5199 - val_accuracy: 0.7500\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 929us/step - loss: 0.4116 - accuracy: 0.8073 - val_loss: 0.5199 - val_accuracy: 0.7500\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4115 - accuracy: 0.8090 - val_loss: 0.5200 - val_accuracy: 0.7500\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 866us/step - loss: 0.4115 - accuracy: 0.8090 - val_loss: 0.5200 - val_accuracy: 0.7500\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 926us/step - loss: 0.4115 - accuracy: 0.8125 - val_loss: 0.5200 - val_accuracy: 0.7500\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 871us/step - loss: 0.4115 - accuracy: 0.8073 - val_loss: 0.5200 - val_accuracy: 0.7500\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4115 - accuracy: 0.8090 - val_loss: 0.5200 - val_accuracy: 0.7500\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8125 - val_loss: 0.5200 - val_accuracy: 0.7500\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4114 - accuracy: 0.8125 - val_loss: 0.5200 - val_accuracy: 0.7500\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 870us/step - loss: 0.4115 - accuracy: 0.8090 - val_loss: 0.5200 - val_accuracy: 0.7500\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 862us/step - loss: 0.4114 - accuracy: 0.8108 - val_loss: 0.5200 - val_accuracy: 0.7500\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4114 - accuracy: 0.8125 - val_loss: 0.5200 - val_accuracy: 0.7500\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4114 - accuracy: 0.8073 - val_loss: 0.5200 - val_accuracy: 0.7500\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4114 - accuracy: 0.8108 - val_loss: 0.5200 - val_accuracy: 0.7500\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 901us/step - loss: 0.4114 - accuracy: 0.8090 - val_loss: 0.5200 - val_accuracy: 0.7500\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 945us/step - loss: 0.4114 - accuracy: 0.8108 - val_loss: 0.5200 - val_accuracy: 0.7500\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 867us/step - loss: 0.4114 - accuracy: 0.8073 - val_loss: 0.5201 - val_accuracy: 0.7500\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4113 - accuracy: 0.8090 - val_loss: 0.5201 - val_accuracy: 0.7500\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 860us/step - loss: 0.4113 - accuracy: 0.8090 - val_loss: 0.5201 - val_accuracy: 0.7500\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4113 - accuracy: 0.8108 - val_loss: 0.5201 - val_accuracy: 0.7500\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 930us/step - loss: 0.4113 - accuracy: 0.8090 - val_loss: 0.5201 - val_accuracy: 0.7500\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.4113 - accuracy: 0.8090 - val_loss: 0.5201 - val_accuracy: 0.7500\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8090 - val_loss: 0.5201 - val_accuracy: 0.7500\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.4113 - accuracy: 0.8090 - val_loss: 0.5201 - val_accuracy: 0.7500\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4113 - accuracy: 0.8090 - val_loss: 0.5201 - val_accuracy: 0.7500\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 878us/step - loss: 0.4113 - accuracy: 0.8108 - val_loss: 0.5201 - val_accuracy: 0.7500\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 870us/step - loss: 0.4113 - accuracy: 0.8108 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 934us/step - loss: 0.4112 - accuracy: 0.8090 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 867us/step - loss: 0.4112 - accuracy: 0.8108 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 876us/step - loss: 0.4112 - accuracy: 0.8108 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 918us/step - loss: 0.4112 - accuracy: 0.8108 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 870us/step - loss: 0.4112 - accuracy: 0.8108 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 874us/step - loss: 0.4111 - accuracy: 0.8108 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4112 - accuracy: 0.8108 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4111 - accuracy: 0.8108 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4111 - accuracy: 0.8108 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.8125 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.4111 - accuracy: 0.8090 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 921us/step - loss: 0.4112 - accuracy: 0.8108 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 904us/step - loss: 0.4111 - accuracy: 0.8090 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 857us/step - loss: 0.4111 - accuracy: 0.8108 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4111 - accuracy: 0.8090 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 868us/step - loss: 0.4111 - accuracy: 0.8073 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 914us/step - loss: 0.4111 - accuracy: 0.8125 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 851us/step - loss: 0.4111 - accuracy: 0.8108 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 876us/step - loss: 0.4110 - accuracy: 0.8125 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4111 - accuracy: 0.8108 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4110 - accuracy: 0.8108 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4110 - accuracy: 0.8108 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 943us/step - loss: 0.4110 - accuracy: 0.8108 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 878us/step - loss: 0.4110 - accuracy: 0.8108 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 885us/step - loss: 0.4110 - accuracy: 0.8108 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 939us/step - loss: 0.4110 - accuracy: 0.8108 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 871us/step - loss: 0.4109 - accuracy: 0.8108 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8108 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 857us/step - loss: 0.4109 - accuracy: 0.8108 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 914us/step - loss: 0.4109 - accuracy: 0.8125 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 861us/step - loss: 0.4109 - accuracy: 0.8108 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4109 - accuracy: 0.8125 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 855us/step - loss: 0.4109 - accuracy: 0.8090 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 869us/step - loss: 0.4109 - accuracy: 0.8125 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 931us/step - loss: 0.4108 - accuracy: 0.8108 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 864us/step - loss: 0.4108 - accuracy: 0.8108 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 914us/step - loss: 0.4108 - accuracy: 0.8108 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 861us/step - loss: 0.4108 - accuracy: 0.8125 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 975us/step - loss: 0.4108 - accuracy: 0.8108 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 856us/step - loss: 0.4108 - accuracy: 0.8108 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4108 - accuracy: 0.8125 - val_loss: 0.5204 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(\n",
    "    X_train_norm, \n",
    "    y_train, \n",
    "    validation_data=(X_test_norm, y_test), \n",
    "    epochs=1000, \n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Loss: 0.4108\n",
      "Final Validation Loss: 0.5204\n",
      "Final Training accuracy: 0.8125\n",
      "Final Validation accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "final_train_loss = run_hist_1b.history[\"loss\"][-1]\n",
    "final_val_loss = run_hist_1b.history[\"val_loss\"][-1]\n",
    "final_train_accuracy = run_hist_1b.history[\"accuracy\"][-1]\n",
    "final_val_accuracy = run_hist_1b.history[\"val_accuracy\"][-1]\n",
    "\n",
    "print(\"Final Training Loss: {:.4f}\".format(final_train_loss))\n",
    "print(\"Final Validation Loss: {:.4f}\".format(final_val_loss))\n",
    "print(\"Final Training accuracy: {:.4f}\".format(final_train_accuracy))\n",
    "print(\"Final Validation accuracy: {:.4f}\".format(final_val_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x293ad3700>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">แบบฝึกปฏิบัติ</span>\n",
    "\n",
    "(รวม 100 คะแนน) ให้นิสิตใช้พื้นที่ต่อไปนี้ ในการเพิ่มโค้ดให้เป็นไปตามข้อกำหนดต่อไปนี้\n",
    "1. (50 คะแนน) เพิ่มเซลโค้ด เพื่อ\n",
    "   * สร้างโมเดลที่มีเลเยอร์ hidden 2 ชั้น แต่ละชั้นมี 6 โหนด\n",
    "   * ปรับโค้ดให้สามารถรับอินพุตที่มีจำนวน feature ตามข้อมูลเทรนที่จะถูกส่งเข้ามา (ปราศจากการใช้ค่าคงที่ 8 ที่ถูกระบุอยู่ในโค้ด ณ ตอนนี้)\n",
    "   * สำหรับเลเยอร์ hidden ให้ใช้ activation function เป็น \"relu\" และเลเยอร์ output เป็น \"sigmoid\"\n",
    "   * ใช้ learning rate เท่ากับ 0.003 และเทรนด้วยจำนวน 1500 epochs ส่วนสำหรับ Hyperparameter ที่เหลือให้ใช้ค่าคงเดิม\n",
    "   * วาดกราฟของค่า loss และ accuracy ด้วยทั้งชุดข้อมูล train และ test (ดังตัวอย่างในรูปนี้)\n",
    "  <img src=\"https://drive.google.com/uc?id=1GuN0KQf64rGMa4oCY2upnbOTMzWaXmbT\" style=\"height:360px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set (Internet Access needed)\n",
    "# Download pima-indians-diabetes.csv from https://www.kaggle.com/datasets/kumargh/pimaindiansdiabetescsv\n",
    "\n",
    "seed_value = 11111\n",
    "url = \"pima-indians-diabetes.csv\"\n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv(url, names=names) # names = column names\n",
    "\n",
    "X = diabetes_df.iloc[:, :-1].values \n",
    "y = diabetes_df[\"has_diabetes\"].values\n",
    "\n",
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=seed_value, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = StandardScaler() # scaling the input data\n",
    "\n",
    "''' Applying the transformation learned from the training data to the test data,\n",
    "    ensuring that the preprocessing steps are consistent between the two sets '''\n",
    "X_train_norm = normalizer.fit_transform(X_train) # fit_transform learns the mean and std dev, and then applies them to the data\n",
    "X_test_norm = normalizer.transform(X_test) # transform applies the mean and std dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nModel: \"sequential\"\\n_________________________________________________________________\\nLayer (type)                 Output Shape              Param #   \\n=================================================================\\ndense (Dense)                (None, 6)                 54 (( 8 + 1 ) * 6 )\\n_________________________________________________________________\\ndense_1 (Dense)              (None, 6)                 42 (( 6 + 1 ) * 6 )\\n_________________________________________________________________\\ndense_2 (Dense)              (None, 1)                 7  (( 6 + 1 ) * 1 )\\n=================================================================\\nTotal params: 103\\nTrainable params: 103\\nNon-trainable params: 0\\n_________________________________________________________________\\n\\nNote : param = ( input units + 1 ) * output units\\n'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Model \n",
    "\n",
    "import os, random, numpy as np\n",
    "import tensorflow as tf \n",
    "\n",
    "# Ensuring that the results are reproducible\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "# make the input of the model dynamic to the number of features of the dataset\n",
    "num_features = len(diabetes_df.columns) - 1\n",
    "\n",
    "# model with 2 hidden layers with 6 nodes each\n",
    "# relu for hidden layers and sigmoid for output layer\n",
    "model_2 = Sequential([\n",
    "    Dense(6, input_shape=(num_features,), activation=\"relu\"),\n",
    "    Dense(6, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "'''\n",
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense (Dense)                (None, 6)                 54 (( 8 + 1 ) * 6 )\n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 6)                 42 (( 6 + 1 ) * 6 )\n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 1)                 7  (( 6 + 1 ) * 1 )\n",
    "=================================================================\n",
    "Total params: 103\n",
    "Trainable params: 103\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "\n",
    "Note : param = ( input units + 1 ) * output units\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7849 - accuracy: 0.3490 - val_loss: 0.7797 - val_accuracy: 0.3385\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 944us/step - loss: 0.7710 - accuracy: 0.3368 - val_loss: 0.7659 - val_accuracy: 0.3281\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.7586 - accuracy: 0.3403 - val_loss: 0.7536 - val_accuracy: 0.3333\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 912us/step - loss: 0.7475 - accuracy: 0.3351 - val_loss: 0.7424 - val_accuracy: 0.3385\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.7374 - accuracy: 0.3385 - val_loss: 0.7321 - val_accuracy: 0.3646\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 870us/step - loss: 0.7282 - accuracy: 0.3438 - val_loss: 0.7228 - val_accuracy: 0.4062\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 848us/step - loss: 0.7199 - accuracy: 0.4028 - val_loss: 0.7143 - val_accuracy: 0.4635\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 845us/step - loss: 0.7123 - accuracy: 0.5052 - val_loss: 0.7065 - val_accuracy: 0.5260\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 841us/step - loss: 0.7052 - accuracy: 0.5503 - val_loss: 0.6993 - val_accuracy: 0.5677\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 873us/step - loss: 0.6987 - accuracy: 0.5660 - val_loss: 0.6927 - val_accuracy: 0.5833\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 856us/step - loss: 0.6927 - accuracy: 0.5868 - val_loss: 0.6865 - val_accuracy: 0.5938\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 873us/step - loss: 0.6871 - accuracy: 0.5955 - val_loss: 0.6808 - val_accuracy: 0.6094\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 864us/step - loss: 0.6819 - accuracy: 0.6059 - val_loss: 0.6755 - val_accuracy: 0.6094\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 838us/step - loss: 0.6771 - accuracy: 0.6302 - val_loss: 0.6706 - val_accuracy: 0.6302\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 840us/step - loss: 0.6726 - accuracy: 0.6372 - val_loss: 0.6661 - val_accuracy: 0.6302\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 866us/step - loss: 0.6684 - accuracy: 0.6389 - val_loss: 0.6618 - val_accuracy: 0.6302\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 870us/step - loss: 0.6644 - accuracy: 0.6389 - val_loss: 0.6578 - val_accuracy: 0.6406\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 836us/step - loss: 0.6608 - accuracy: 0.6406 - val_loss: 0.6541 - val_accuracy: 0.6562\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 833us/step - loss: 0.6574 - accuracy: 0.6476 - val_loss: 0.6506 - val_accuracy: 0.6771\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 847us/step - loss: 0.6542 - accuracy: 0.6510 - val_loss: 0.6473 - val_accuracy: 0.6823\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 832us/step - loss: 0.6511 - accuracy: 0.6562 - val_loss: 0.6442 - val_accuracy: 0.6771\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 825us/step - loss: 0.6482 - accuracy: 0.6580 - val_loss: 0.6413 - val_accuracy: 0.6927\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 833us/step - loss: 0.6455 - accuracy: 0.6632 - val_loss: 0.6385 - val_accuracy: 0.6979\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 830us/step - loss: 0.6429 - accuracy: 0.6667 - val_loss: 0.6359 - val_accuracy: 0.6823\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 839us/step - loss: 0.6405 - accuracy: 0.6684 - val_loss: 0.6334 - val_accuracy: 0.6823\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 840us/step - loss: 0.6381 - accuracy: 0.6684 - val_loss: 0.6310 - val_accuracy: 0.6823\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 838us/step - loss: 0.6358 - accuracy: 0.6667 - val_loss: 0.6287 - val_accuracy: 0.6823\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 841us/step - loss: 0.6337 - accuracy: 0.6684 - val_loss: 0.6265 - val_accuracy: 0.6875\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 831us/step - loss: 0.6317 - accuracy: 0.6701 - val_loss: 0.6244 - val_accuracy: 0.6875\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 841us/step - loss: 0.6297 - accuracy: 0.6753 - val_loss: 0.6224 - val_accuracy: 0.6823\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 854us/step - loss: 0.6278 - accuracy: 0.6771 - val_loss: 0.6204 - val_accuracy: 0.6823\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 831us/step - loss: 0.6261 - accuracy: 0.6771 - val_loss: 0.6186 - val_accuracy: 0.6771\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 828us/step - loss: 0.6243 - accuracy: 0.6771 - val_loss: 0.6168 - val_accuracy: 0.6823\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 834us/step - loss: 0.6227 - accuracy: 0.6753 - val_loss: 0.6151 - val_accuracy: 0.6823\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 828us/step - loss: 0.6210 - accuracy: 0.6771 - val_loss: 0.6134 - val_accuracy: 0.6875\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 853us/step - loss: 0.6194 - accuracy: 0.6771 - val_loss: 0.6117 - val_accuracy: 0.6875\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 844us/step - loss: 0.6179 - accuracy: 0.6771 - val_loss: 0.6101 - val_accuracy: 0.6927\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 832us/step - loss: 0.6164 - accuracy: 0.6771 - val_loss: 0.6086 - val_accuracy: 0.6927\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 835us/step - loss: 0.6149 - accuracy: 0.6788 - val_loss: 0.6071 - val_accuracy: 0.6927\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 833us/step - loss: 0.6135 - accuracy: 0.6788 - val_loss: 0.6056 - val_accuracy: 0.6927\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 835us/step - loss: 0.6121 - accuracy: 0.6788 - val_loss: 0.6042 - val_accuracy: 0.6927\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 810us/step - loss: 0.6107 - accuracy: 0.6788 - val_loss: 0.6028 - val_accuracy: 0.6927\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 831us/step - loss: 0.6093 - accuracy: 0.6788 - val_loss: 0.6014 - val_accuracy: 0.6927\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 859us/step - loss: 0.6080 - accuracy: 0.6788 - val_loss: 0.6001 - val_accuracy: 0.6927\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 842us/step - loss: 0.6067 - accuracy: 0.6788 - val_loss: 0.5988 - val_accuracy: 0.6927\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 846us/step - loss: 0.6054 - accuracy: 0.6788 - val_loss: 0.5975 - val_accuracy: 0.6927\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 840us/step - loss: 0.6041 - accuracy: 0.6806 - val_loss: 0.5962 - val_accuracy: 0.6979\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 828us/step - loss: 0.6029 - accuracy: 0.6788 - val_loss: 0.5950 - val_accuracy: 0.6875\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 833us/step - loss: 0.6016 - accuracy: 0.6806 - val_loss: 0.5938 - val_accuracy: 0.6927\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 828us/step - loss: 0.6004 - accuracy: 0.6806 - val_loss: 0.5926 - val_accuracy: 0.6979\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 838us/step - loss: 0.5992 - accuracy: 0.6806 - val_loss: 0.5915 - val_accuracy: 0.6979\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 829us/step - loss: 0.5980 - accuracy: 0.6840 - val_loss: 0.5904 - val_accuracy: 0.6979\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 836us/step - loss: 0.5968 - accuracy: 0.6840 - val_loss: 0.5892 - val_accuracy: 0.6979\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 839us/step - loss: 0.5956 - accuracy: 0.6840 - val_loss: 0.5881 - val_accuracy: 0.6979\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 836us/step - loss: 0.5945 - accuracy: 0.6840 - val_loss: 0.5871 - val_accuracy: 0.6979\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 813us/step - loss: 0.5933 - accuracy: 0.6840 - val_loss: 0.5860 - val_accuracy: 0.7031\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 842us/step - loss: 0.5922 - accuracy: 0.6892 - val_loss: 0.5849 - val_accuracy: 0.7031\n",
      "Epoch 58/1500\n",
      "18/18 [==============================] - 0s 820us/step - loss: 0.5910 - accuracy: 0.6892 - val_loss: 0.5839 - val_accuracy: 0.7031\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.5899 - accuracy: 0.6892 - val_loss: 0.5828 - val_accuracy: 0.7031\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 837us/step - loss: 0.5887 - accuracy: 0.6892 - val_loss: 0.5818 - val_accuracy: 0.7031\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 829us/step - loss: 0.5876 - accuracy: 0.6927 - val_loss: 0.5807 - val_accuracy: 0.7031\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 825us/step - loss: 0.5864 - accuracy: 0.6927 - val_loss: 0.5797 - val_accuracy: 0.7031\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.5853 - accuracy: 0.6927 - val_loss: 0.5786 - val_accuracy: 0.7031\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5842 - accuracy: 0.6927 - val_loss: 0.5776 - val_accuracy: 0.7083\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 818us/step - loss: 0.5830 - accuracy: 0.6944 - val_loss: 0.5766 - val_accuracy: 0.7083\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 825us/step - loss: 0.5819 - accuracy: 0.6962 - val_loss: 0.5756 - val_accuracy: 0.7135\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 839us/step - loss: 0.5807 - accuracy: 0.6962 - val_loss: 0.5746 - val_accuracy: 0.7135\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 823us/step - loss: 0.5795 - accuracy: 0.6997 - val_loss: 0.5736 - val_accuracy: 0.7135\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 826us/step - loss: 0.5783 - accuracy: 0.7014 - val_loss: 0.5726 - val_accuracy: 0.7083\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 841us/step - loss: 0.5770 - accuracy: 0.7031 - val_loss: 0.5716 - val_accuracy: 0.7135\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 820us/step - loss: 0.5759 - accuracy: 0.7049 - val_loss: 0.5706 - val_accuracy: 0.7240\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 838us/step - loss: 0.5747 - accuracy: 0.7049 - val_loss: 0.5697 - val_accuracy: 0.7188\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 830us/step - loss: 0.5735 - accuracy: 0.7049 - val_loss: 0.5687 - val_accuracy: 0.7240\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 833us/step - loss: 0.5724 - accuracy: 0.7049 - val_loss: 0.5677 - val_accuracy: 0.7292\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 832us/step - loss: 0.5712 - accuracy: 0.7066 - val_loss: 0.5667 - val_accuracy: 0.7292\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 825us/step - loss: 0.5701 - accuracy: 0.7101 - val_loss: 0.5657 - val_accuracy: 0.7292\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5689 - accuracy: 0.7118 - val_loss: 0.5647 - val_accuracy: 0.7292\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 845us/step - loss: 0.5678 - accuracy: 0.7118 - val_loss: 0.5637 - val_accuracy: 0.7292\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 837us/step - loss: 0.5666 - accuracy: 0.7135 - val_loss: 0.5627 - val_accuracy: 0.7292\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 841us/step - loss: 0.5655 - accuracy: 0.7118 - val_loss: 0.5618 - val_accuracy: 0.7292\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 851us/step - loss: 0.5643 - accuracy: 0.7135 - val_loss: 0.5608 - val_accuracy: 0.7292\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 834us/step - loss: 0.5631 - accuracy: 0.7170 - val_loss: 0.5599 - val_accuracy: 0.7292\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 839us/step - loss: 0.5620 - accuracy: 0.7170 - val_loss: 0.5590 - val_accuracy: 0.7292\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 835us/step - loss: 0.5609 - accuracy: 0.7170 - val_loss: 0.5580 - val_accuracy: 0.7344\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 832us/step - loss: 0.5598 - accuracy: 0.7153 - val_loss: 0.5571 - val_accuracy: 0.7344\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 821us/step - loss: 0.5586 - accuracy: 0.7153 - val_loss: 0.5562 - val_accuracy: 0.7344\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 843us/step - loss: 0.5575 - accuracy: 0.7153 - val_loss: 0.5553 - val_accuracy: 0.7396\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 842us/step - loss: 0.5564 - accuracy: 0.7170 - val_loss: 0.5544 - val_accuracy: 0.7396\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 842us/step - loss: 0.5554 - accuracy: 0.7170 - val_loss: 0.5535 - val_accuracy: 0.7344\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 831us/step - loss: 0.5543 - accuracy: 0.7188 - val_loss: 0.5526 - val_accuracy: 0.7344\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 831us/step - loss: 0.5531 - accuracy: 0.7222 - val_loss: 0.5518 - val_accuracy: 0.7344\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 836us/step - loss: 0.5520 - accuracy: 0.7240 - val_loss: 0.5509 - val_accuracy: 0.7344\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 829us/step - loss: 0.5509 - accuracy: 0.7240 - val_loss: 0.5500 - val_accuracy: 0.7344\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 819us/step - loss: 0.5498 - accuracy: 0.7222 - val_loss: 0.5492 - val_accuracy: 0.7344\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 840us/step - loss: 0.5487 - accuracy: 0.7240 - val_loss: 0.5484 - val_accuracy: 0.7344\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 826us/step - loss: 0.5475 - accuracy: 0.7292 - val_loss: 0.5476 - val_accuracy: 0.7448\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 837us/step - loss: 0.5465 - accuracy: 0.7378 - val_loss: 0.5468 - val_accuracy: 0.7396\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 830us/step - loss: 0.5454 - accuracy: 0.7361 - val_loss: 0.5460 - val_accuracy: 0.7448\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 825us/step - loss: 0.5444 - accuracy: 0.7361 - val_loss: 0.5452 - val_accuracy: 0.7500\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 829us/step - loss: 0.5433 - accuracy: 0.7413 - val_loss: 0.5445 - val_accuracy: 0.7500\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 829us/step - loss: 0.5423 - accuracy: 0.7413 - val_loss: 0.5437 - val_accuracy: 0.7500\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 809us/step - loss: 0.5413 - accuracy: 0.7413 - val_loss: 0.5430 - val_accuracy: 0.7500\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 840us/step - loss: 0.5402 - accuracy: 0.7448 - val_loss: 0.5422 - val_accuracy: 0.7500\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 837us/step - loss: 0.5392 - accuracy: 0.7465 - val_loss: 0.5415 - val_accuracy: 0.7500\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 832us/step - loss: 0.5382 - accuracy: 0.7483 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 851us/step - loss: 0.5373 - accuracy: 0.7517 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 837us/step - loss: 0.5363 - accuracy: 0.7552 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 854us/step - loss: 0.5353 - accuracy: 0.7535 - val_loss: 0.5387 - val_accuracy: 0.7500\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 847us/step - loss: 0.5344 - accuracy: 0.7552 - val_loss: 0.5380 - val_accuracy: 0.7448\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 851us/step - loss: 0.5334 - accuracy: 0.7604 - val_loss: 0.5374 - val_accuracy: 0.7448\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 937us/step - loss: 0.5324 - accuracy: 0.7569 - val_loss: 0.5367 - val_accuracy: 0.7396\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.5315 - accuracy: 0.7587 - val_loss: 0.5360 - val_accuracy: 0.7396\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 874us/step - loss: 0.5305 - accuracy: 0.7587 - val_loss: 0.5354 - val_accuracy: 0.7344\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 871us/step - loss: 0.5296 - accuracy: 0.7587 - val_loss: 0.5348 - val_accuracy: 0.7344\n",
      "Epoch 115/1500\n",
      "18/18 [==============================] - 0s 866us/step - loss: 0.5287 - accuracy: 0.7587 - val_loss: 0.5341 - val_accuracy: 0.7344\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 843us/step - loss: 0.5278 - accuracy: 0.7587 - val_loss: 0.5335 - val_accuracy: 0.7344\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 855us/step - loss: 0.5269 - accuracy: 0.7604 - val_loss: 0.5329 - val_accuracy: 0.7292\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 857us/step - loss: 0.5259 - accuracy: 0.7587 - val_loss: 0.5323 - val_accuracy: 0.7292\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 874us/step - loss: 0.5251 - accuracy: 0.7587 - val_loss: 0.5317 - val_accuracy: 0.7292\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 824us/step - loss: 0.5242 - accuracy: 0.7587 - val_loss: 0.5311 - val_accuracy: 0.7292\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 860us/step - loss: 0.5233 - accuracy: 0.7587 - val_loss: 0.5305 - val_accuracy: 0.7292\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 836us/step - loss: 0.5225 - accuracy: 0.7587 - val_loss: 0.5300 - val_accuracy: 0.7344\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5216 - accuracy: 0.7587 - val_loss: 0.5294 - val_accuracy: 0.7344\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7569 - val_loss: 0.5289 - val_accuracy: 0.7396\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 856us/step - loss: 0.5199 - accuracy: 0.7569 - val_loss: 0.5283 - val_accuracy: 0.7396\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 840us/step - loss: 0.5191 - accuracy: 0.7587 - val_loss: 0.5278 - val_accuracy: 0.7396\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 862us/step - loss: 0.5182 - accuracy: 0.7569 - val_loss: 0.5273 - val_accuracy: 0.7396\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 832us/step - loss: 0.5174 - accuracy: 0.7587 - val_loss: 0.5268 - val_accuracy: 0.7396\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 862us/step - loss: 0.5166 - accuracy: 0.7587 - val_loss: 0.5263 - val_accuracy: 0.7448\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.5158 - accuracy: 0.7604 - val_loss: 0.5258 - val_accuracy: 0.7448\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.5150 - accuracy: 0.7604 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 905us/step - loss: 0.5142 - accuracy: 0.7604 - val_loss: 0.5249 - val_accuracy: 0.7448\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.5134 - accuracy: 0.7604 - val_loss: 0.5245 - val_accuracy: 0.7448\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.5126 - accuracy: 0.7604 - val_loss: 0.5240 - val_accuracy: 0.7448\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5119 - accuracy: 0.7604 - val_loss: 0.5236 - val_accuracy: 0.7448\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5112 - accuracy: 0.7622 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 987us/step - loss: 0.5105 - accuracy: 0.7604 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 996us/step - loss: 0.5098 - accuracy: 0.7656 - val_loss: 0.5223 - val_accuracy: 0.7448\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 955us/step - loss: 0.5090 - accuracy: 0.7639 - val_loss: 0.5218 - val_accuracy: 0.7448\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 915us/step - loss: 0.5083 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7448\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.5076 - accuracy: 0.7639 - val_loss: 0.5210 - val_accuracy: 0.7448\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.5069 - accuracy: 0.7622 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 932us/step - loss: 0.5063 - accuracy: 0.7622 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 977us/step - loss: 0.5056 - accuracy: 0.7622 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5050 - accuracy: 0.7622 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 884us/step - loss: 0.5044 - accuracy: 0.7622 - val_loss: 0.5189 - val_accuracy: 0.7396\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.5038 - accuracy: 0.7639 - val_loss: 0.5186 - val_accuracy: 0.7396\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 858us/step - loss: 0.5032 - accuracy: 0.7674 - val_loss: 0.5182 - val_accuracy: 0.7448\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 989us/step - loss: 0.5026 - accuracy: 0.7674 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 933us/step - loss: 0.5020 - accuracy: 0.7691 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.5014 - accuracy: 0.7691 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 955us/step - loss: 0.5008 - accuracy: 0.7691 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7708 - val_loss: 0.5164 - val_accuracy: 0.7448\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 978us/step - loss: 0.4996 - accuracy: 0.7708 - val_loss: 0.5160 - val_accuracy: 0.7448\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 926us/step - loss: 0.4990 - accuracy: 0.7708 - val_loss: 0.5157 - val_accuracy: 0.7448\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.7708 - val_loss: 0.5153 - val_accuracy: 0.7448\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4979 - accuracy: 0.7708 - val_loss: 0.5150 - val_accuracy: 0.7448\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4973 - accuracy: 0.7708 - val_loss: 0.5147 - val_accuracy: 0.7448\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4968 - accuracy: 0.7708 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.7708 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 966us/step - loss: 0.4958 - accuracy: 0.7691 - val_loss: 0.5138 - val_accuracy: 0.7448\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 930us/step - loss: 0.4952 - accuracy: 0.7691 - val_loss: 0.5135 - val_accuracy: 0.7552\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4947 - accuracy: 0.7708 - val_loss: 0.5132 - val_accuracy: 0.7500\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 901us/step - loss: 0.4942 - accuracy: 0.7691 - val_loss: 0.5129 - val_accuracy: 0.7552\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 858us/step - loss: 0.4937 - accuracy: 0.7691 - val_loss: 0.5126 - val_accuracy: 0.7552\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 845us/step - loss: 0.4933 - accuracy: 0.7674 - val_loss: 0.5124 - val_accuracy: 0.7552\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 846us/step - loss: 0.4928 - accuracy: 0.7674 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 848us/step - loss: 0.4922 - accuracy: 0.7656 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 856us/step - loss: 0.4918 - accuracy: 0.7674 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4913 - accuracy: 0.7691 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 915us/step - loss: 0.4909 - accuracy: 0.7691 - val_loss: 0.5111 - val_accuracy: 0.7552\n",
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 958us/step - loss: 0.4904 - accuracy: 0.7691 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 994us/step - loss: 0.4900 - accuracy: 0.7691 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 970us/step - loss: 0.4895 - accuracy: 0.7691 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 974us/step - loss: 0.4891 - accuracy: 0.7691 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 964us/step - loss: 0.4886 - accuracy: 0.7691 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7691 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.7691 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4874 - accuracy: 0.7691 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4870 - accuracy: 0.7691 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 852us/step - loss: 0.4866 - accuracy: 0.7726 - val_loss: 0.5090 - val_accuracy: 0.7552\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 853us/step - loss: 0.4862 - accuracy: 0.7726 - val_loss: 0.5089 - val_accuracy: 0.7552\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 857us/step - loss: 0.4858 - accuracy: 0.7726 - val_loss: 0.5087 - val_accuracy: 0.7552\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 839us/step - loss: 0.4855 - accuracy: 0.7708 - val_loss: 0.5086 - val_accuracy: 0.7552\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 842us/step - loss: 0.4851 - accuracy: 0.7708 - val_loss: 0.5084 - val_accuracy: 0.7552\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 866us/step - loss: 0.4847 - accuracy: 0.7708 - val_loss: 0.5082 - val_accuracy: 0.7552\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 858us/step - loss: 0.4844 - accuracy: 0.7708 - val_loss: 0.5081 - val_accuracy: 0.7552\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 834us/step - loss: 0.4840 - accuracy: 0.7708 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 831us/step - loss: 0.4837 - accuracy: 0.7708 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 831us/step - loss: 0.4834 - accuracy: 0.7726 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 815us/step - loss: 0.4831 - accuracy: 0.7726 - val_loss: 0.5076 - val_accuracy: 0.7552\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 840us/step - loss: 0.4828 - accuracy: 0.7726 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 819us/step - loss: 0.4825 - accuracy: 0.7726 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 838us/step - loss: 0.4821 - accuracy: 0.7708 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 833us/step - loss: 0.4819 - accuracy: 0.7691 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 845us/step - loss: 0.4816 - accuracy: 0.7708 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 855us/step - loss: 0.4813 - accuracy: 0.7708 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 841us/step - loss: 0.4810 - accuracy: 0.7691 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 839us/step - loss: 0.4807 - accuracy: 0.7691 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 843us/step - loss: 0.4805 - accuracy: 0.7708 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 847us/step - loss: 0.4802 - accuracy: 0.7708 - val_loss: 0.5066 - val_accuracy: 0.7500\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 930us/step - loss: 0.4799 - accuracy: 0.7708 - val_loss: 0.5065 - val_accuracy: 0.7500\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 928us/step - loss: 0.4796 - accuracy: 0.7726 - val_loss: 0.5064 - val_accuracy: 0.7500\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 947us/step - loss: 0.4794 - accuracy: 0.7726 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 955us/step - loss: 0.4791 - accuracy: 0.7726 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 962us/step - loss: 0.4788 - accuracy: 0.7708 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 983us/step - loss: 0.4786 - accuracy: 0.7691 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 943us/step - loss: 0.4783 - accuracy: 0.7691 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 921us/step - loss: 0.4781 - accuracy: 0.7674 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4778 - accuracy: 0.7691 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4775 - accuracy: 0.7708 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4772 - accuracy: 0.7691 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 870us/step - loss: 0.4770 - accuracy: 0.7691 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 842us/step - loss: 0.4767 - accuracy: 0.7691 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 852us/step - loss: 0.4765 - accuracy: 0.7674 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 846us/step - loss: 0.4762 - accuracy: 0.7691 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 839us/step - loss: 0.4759 - accuracy: 0.7674 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 847us/step - loss: 0.4756 - accuracy: 0.7674 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 832us/step - loss: 0.4753 - accuracy: 0.7674 - val_loss: 0.5049 - val_accuracy: 0.7448\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 848us/step - loss: 0.4751 - accuracy: 0.7691 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 839us/step - loss: 0.4748 - accuracy: 0.7674 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4746 - accuracy: 0.7674 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4743 - accuracy: 0.7656 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 940us/step - loss: 0.4741 - accuracy: 0.7674 - val_loss: 0.5045 - val_accuracy: 0.7396\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 932us/step - loss: 0.4738 - accuracy: 0.7674 - val_loss: 0.5044 - val_accuracy: 0.7396\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 909us/step - loss: 0.4736 - accuracy: 0.7674 - val_loss: 0.5043 - val_accuracy: 0.7396\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 999us/step - loss: 0.4733 - accuracy: 0.7674 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 991us/step - loss: 0.4731 - accuracy: 0.7691 - val_loss: 0.5042 - val_accuracy: 0.7396\n",
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.7674 - val_loss: 0.5041 - val_accuracy: 0.7396\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4726 - accuracy: 0.7691 - val_loss: 0.5040 - val_accuracy: 0.7396\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 993us/step - loss: 0.4723 - accuracy: 0.7691 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 964us/step - loss: 0.4721 - accuracy: 0.7708 - val_loss: 0.5038 - val_accuracy: 0.7396\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 951us/step - loss: 0.4719 - accuracy: 0.7691 - val_loss: 0.5037 - val_accuracy: 0.7396\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4716 - accuracy: 0.7708 - val_loss: 0.5036 - val_accuracy: 0.7396\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 956us/step - loss: 0.4714 - accuracy: 0.7708 - val_loss: 0.5035 - val_accuracy: 0.7396\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 946us/step - loss: 0.4712 - accuracy: 0.7708 - val_loss: 0.5034 - val_accuracy: 0.7396\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 998us/step - loss: 0.4709 - accuracy: 0.7708 - val_loss: 0.5033 - val_accuracy: 0.7396\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 978us/step - loss: 0.4707 - accuracy: 0.7726 - val_loss: 0.5033 - val_accuracy: 0.7396\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 991us/step - loss: 0.4705 - accuracy: 0.7726 - val_loss: 0.5032 - val_accuracy: 0.7396\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 973us/step - loss: 0.4703 - accuracy: 0.7726 - val_loss: 0.5031 - val_accuracy: 0.7396\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 945us/step - loss: 0.4701 - accuracy: 0.7726 - val_loss: 0.5030 - val_accuracy: 0.7396\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 934us/step - loss: 0.4699 - accuracy: 0.7726 - val_loss: 0.5029 - val_accuracy: 0.7396\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.4697 - accuracy: 0.7726 - val_loss: 0.5028 - val_accuracy: 0.7396\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 975us/step - loss: 0.4694 - accuracy: 0.7726 - val_loss: 0.5027 - val_accuracy: 0.7396\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7726 - val_loss: 0.5026 - val_accuracy: 0.7396\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 955us/step - loss: 0.4690 - accuracy: 0.7726 - val_loss: 0.5025 - val_accuracy: 0.7396\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 947us/step - loss: 0.4687 - accuracy: 0.7726 - val_loss: 0.5024 - val_accuracy: 0.7396\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 922us/step - loss: 0.4685 - accuracy: 0.7726 - val_loss: 0.5023 - val_accuracy: 0.7396\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 949us/step - loss: 0.4682 - accuracy: 0.7726 - val_loss: 0.5021 - val_accuracy: 0.7396\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 947us/step - loss: 0.4680 - accuracy: 0.7726 - val_loss: 0.5020 - val_accuracy: 0.7396\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4677 - accuracy: 0.7743 - val_loss: 0.5019 - val_accuracy: 0.7396\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.7743 - val_loss: 0.5018 - val_accuracy: 0.7396\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 934us/step - loss: 0.4673 - accuracy: 0.7743 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 878us/step - loss: 0.4671 - accuracy: 0.7743 - val_loss: 0.5017 - val_accuracy: 0.7396\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 858us/step - loss: 0.4668 - accuracy: 0.7743 - val_loss: 0.5016 - val_accuracy: 0.7396\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 926us/step - loss: 0.4666 - accuracy: 0.7726 - val_loss: 0.5015 - val_accuracy: 0.7396\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4664 - accuracy: 0.7726 - val_loss: 0.5014 - val_accuracy: 0.7344\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 918us/step - loss: 0.4662 - accuracy: 0.7726 - val_loss: 0.5012 - val_accuracy: 0.7344\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 929us/step - loss: 0.4660 - accuracy: 0.7726 - val_loss: 0.5011 - val_accuracy: 0.7344\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 948us/step - loss: 0.4658 - accuracy: 0.7743 - val_loss: 0.5011 - val_accuracy: 0.7344\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 986us/step - loss: 0.4656 - accuracy: 0.7708 - val_loss: 0.5010 - val_accuracy: 0.7344\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 996us/step - loss: 0.4653 - accuracy: 0.7726 - val_loss: 0.5009 - val_accuracy: 0.7344\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 975us/step - loss: 0.4652 - accuracy: 0.7743 - val_loss: 0.5008 - val_accuracy: 0.7344\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 982us/step - loss: 0.4649 - accuracy: 0.7726 - val_loss: 0.5007 - val_accuracy: 0.7344\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 981us/step - loss: 0.4647 - accuracy: 0.7726 - val_loss: 0.5005 - val_accuracy: 0.7344\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 946us/step - loss: 0.4645 - accuracy: 0.7726 - val_loss: 0.5004 - val_accuracy: 0.7344\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 947us/step - loss: 0.4644 - accuracy: 0.7726 - val_loss: 0.5003 - val_accuracy: 0.7396\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 950us/step - loss: 0.4642 - accuracy: 0.7726 - val_loss: 0.5002 - val_accuracy: 0.7396\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 965us/step - loss: 0.4640 - accuracy: 0.7743 - val_loss: 0.5001 - val_accuracy: 0.7396\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 969us/step - loss: 0.4638 - accuracy: 0.7743 - val_loss: 0.5000 - val_accuracy: 0.7344\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 966us/step - loss: 0.4636 - accuracy: 0.7743 - val_loss: 0.4999 - val_accuracy: 0.7344\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 943us/step - loss: 0.4634 - accuracy: 0.7743 - val_loss: 0.4998 - val_accuracy: 0.7344\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 905us/step - loss: 0.4632 - accuracy: 0.7743 - val_loss: 0.4997 - val_accuracy: 0.7344\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 885us/step - loss: 0.4631 - accuracy: 0.7743 - val_loss: 0.4996 - val_accuracy: 0.7344\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4629 - accuracy: 0.7743 - val_loss: 0.4995 - val_accuracy: 0.7344\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.4627 - accuracy: 0.7743 - val_loss: 0.4994 - val_accuracy: 0.7344\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4994 - val_accuracy: 0.7344\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 905us/step - loss: 0.4624 - accuracy: 0.7760 - val_loss: 0.4993 - val_accuracy: 0.7344\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4622 - accuracy: 0.7760 - val_loss: 0.4992 - val_accuracy: 0.7344\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4621 - accuracy: 0.7743 - val_loss: 0.4991 - val_accuracy: 0.7344\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7760 - val_loss: 0.4990 - val_accuracy: 0.7396\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7760 - val_loss: 0.4990 - val_accuracy: 0.7396\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 936us/step - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.4989 - val_accuracy: 0.7396\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4614 - accuracy: 0.7760 - val_loss: 0.4988 - val_accuracy: 0.7396\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.4613 - accuracy: 0.7743 - val_loss: 0.4987 - val_accuracy: 0.7396\n",
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 895us/step - loss: 0.4611 - accuracy: 0.7760 - val_loss: 0.4986 - val_accuracy: 0.7396\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.4610 - accuracy: 0.7760 - val_loss: 0.4985 - val_accuracy: 0.7396\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 946us/step - loss: 0.4608 - accuracy: 0.7760 - val_loss: 0.4984 - val_accuracy: 0.7396\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 979us/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4984 - val_accuracy: 0.7396\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 983us/step - loss: 0.4604 - accuracy: 0.7760 - val_loss: 0.4983 - val_accuracy: 0.7396\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 980us/step - loss: 0.4603 - accuracy: 0.7760 - val_loss: 0.4982 - val_accuracy: 0.7396\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7760 - val_loss: 0.4982 - val_accuracy: 0.7396\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.7760 - val_loss: 0.4981 - val_accuracy: 0.7396\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 924us/step - loss: 0.4598 - accuracy: 0.7760 - val_loss: 0.4980 - val_accuracy: 0.7396\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 875us/step - loss: 0.4597 - accuracy: 0.7760 - val_loss: 0.4980 - val_accuracy: 0.7396\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4596 - accuracy: 0.7760 - val_loss: 0.4979 - val_accuracy: 0.7396\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 877us/step - loss: 0.4594 - accuracy: 0.7760 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 884us/step - loss: 0.4593 - accuracy: 0.7760 - val_loss: 0.4978 - val_accuracy: 0.7448\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 879us/step - loss: 0.4591 - accuracy: 0.7760 - val_loss: 0.4977 - val_accuracy: 0.7448\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 943us/step - loss: 0.4590 - accuracy: 0.7760 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4976 - val_accuracy: 0.7448\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 878us/step - loss: 0.4587 - accuracy: 0.7778 - val_loss: 0.4975 - val_accuracy: 0.7448\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.4586 - accuracy: 0.7778 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 887us/step - loss: 0.4584 - accuracy: 0.7778 - val_loss: 0.4974 - val_accuracy: 0.7448\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4583 - accuracy: 0.7778 - val_loss: 0.4973 - val_accuracy: 0.7448\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 873us/step - loss: 0.4582 - accuracy: 0.7778 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4580 - accuracy: 0.7778 - val_loss: 0.4972 - val_accuracy: 0.7448\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 881us/step - loss: 0.4579 - accuracy: 0.7778 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4578 - accuracy: 0.7778 - val_loss: 0.4971 - val_accuracy: 0.7448\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4576 - accuracy: 0.7778 - val_loss: 0.4970 - val_accuracy: 0.7448\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 904us/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4969 - val_accuracy: 0.7448\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 884us/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 874us/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4968 - val_accuracy: 0.7448\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4570 - accuracy: 0.7778 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 876us/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 994us/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4966 - val_accuracy: 0.7396\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4965 - val_accuracy: 0.7396\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4964 - val_accuracy: 0.7396\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 909us/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4964 - val_accuracy: 0.7396\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4963 - val_accuracy: 0.7396\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 904us/step - loss: 0.4561 - accuracy: 0.7778 - val_loss: 0.4962 - val_accuracy: 0.7396\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 947us/step - loss: 0.4560 - accuracy: 0.7778 - val_loss: 0.4962 - val_accuracy: 0.7396\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 938us/step - loss: 0.4559 - accuracy: 0.7795 - val_loss: 0.4961 - val_accuracy: 0.7396\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4558 - accuracy: 0.7795 - val_loss: 0.4960 - val_accuracy: 0.7396\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4557 - accuracy: 0.7812 - val_loss: 0.4960 - val_accuracy: 0.7396\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4555 - accuracy: 0.7812 - val_loss: 0.4959 - val_accuracy: 0.7396\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 905us/step - loss: 0.4554 - accuracy: 0.7795 - val_loss: 0.4958 - val_accuracy: 0.7396\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 878us/step - loss: 0.4553 - accuracy: 0.7812 - val_loss: 0.4958 - val_accuracy: 0.7396\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 919us/step - loss: 0.4552 - accuracy: 0.7812 - val_loss: 0.4957 - val_accuracy: 0.7396\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 963us/step - loss: 0.4551 - accuracy: 0.7812 - val_loss: 0.4957 - val_accuracy: 0.7396\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.7812 - val_loss: 0.4956 - val_accuracy: 0.7396\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4549 - accuracy: 0.7812 - val_loss: 0.4956 - val_accuracy: 0.7396\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4548 - accuracy: 0.7812 - val_loss: 0.4955 - val_accuracy: 0.7396\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 940us/step - loss: 0.4547 - accuracy: 0.7812 - val_loss: 0.4954 - val_accuracy: 0.7396\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 928us/step - loss: 0.4546 - accuracy: 0.7812 - val_loss: 0.4954 - val_accuracy: 0.7396\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 955us/step - loss: 0.4545 - accuracy: 0.7812 - val_loss: 0.4953 - val_accuracy: 0.7396\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 985us/step - loss: 0.4543 - accuracy: 0.7812 - val_loss: 0.4953 - val_accuracy: 0.7396\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 939us/step - loss: 0.4543 - accuracy: 0.7830 - val_loss: 0.4952 - val_accuracy: 0.7396\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.7830 - val_loss: 0.4952 - val_accuracy: 0.7396\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 990us/step - loss: 0.4541 - accuracy: 0.7830 - val_loss: 0.4951 - val_accuracy: 0.7396\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 943us/step - loss: 0.4539 - accuracy: 0.7830 - val_loss: 0.4950 - val_accuracy: 0.7396\n",
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 985us/step - loss: 0.4539 - accuracy: 0.7847 - val_loss: 0.4950 - val_accuracy: 0.7396\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.7830 - val_loss: 0.4949 - val_accuracy: 0.7396\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7847 - val_loss: 0.4948 - val_accuracy: 0.7396\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 968us/step - loss: 0.4536 - accuracy: 0.7830 - val_loss: 0.4948 - val_accuracy: 0.7396\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 929us/step - loss: 0.4535 - accuracy: 0.7830 - val_loss: 0.4947 - val_accuracy: 0.7396\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 957us/step - loss: 0.4534 - accuracy: 0.7847 - val_loss: 0.4947 - val_accuracy: 0.7396\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 999us/step - loss: 0.4533 - accuracy: 0.7847 - val_loss: 0.4946 - val_accuracy: 0.7396\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 931us/step - loss: 0.4532 - accuracy: 0.7847 - val_loss: 0.4946 - val_accuracy: 0.7396\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 865us/step - loss: 0.4531 - accuracy: 0.7847 - val_loss: 0.4945 - val_accuracy: 0.7396\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 944us/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.4945 - val_accuracy: 0.7396\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 924us/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.4944 - val_accuracy: 0.7396\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.4528 - accuracy: 0.7847 - val_loss: 0.4944 - val_accuracy: 0.7396\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4527 - accuracy: 0.7847 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4526 - accuracy: 0.7847 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4526 - accuracy: 0.7847 - val_loss: 0.4943 - val_accuracy: 0.7448\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 967us/step - loss: 0.4525 - accuracy: 0.7865 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 947us/step - loss: 0.4524 - accuracy: 0.7865 - val_loss: 0.4942 - val_accuracy: 0.7500\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4524 - accuracy: 0.7865 - val_loss: 0.4942 - val_accuracy: 0.7500\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4523 - accuracy: 0.7865 - val_loss: 0.4941 - val_accuracy: 0.7500\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4522 - accuracy: 0.7865 - val_loss: 0.4941 - val_accuracy: 0.7500\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4521 - accuracy: 0.7865 - val_loss: 0.4941 - val_accuracy: 0.7500\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 870us/step - loss: 0.4521 - accuracy: 0.7865 - val_loss: 0.4941 - val_accuracy: 0.7500\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.7882 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.7882 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4519 - accuracy: 0.7882 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.4518 - accuracy: 0.7865 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 913us/step - loss: 0.4518 - accuracy: 0.7882 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4517 - accuracy: 0.7882 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.7865 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.7865 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4515 - accuracy: 0.7865 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 895us/step - loss: 0.4514 - accuracy: 0.7865 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4513 - accuracy: 0.7882 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.4513 - accuracy: 0.7899 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4512 - accuracy: 0.7899 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 934us/step - loss: 0.4512 - accuracy: 0.7899 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 920us/step - loss: 0.4511 - accuracy: 0.7899 - val_loss: 0.4936 - val_accuracy: 0.7552\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 946us/step - loss: 0.4510 - accuracy: 0.7899 - val_loss: 0.4936 - val_accuracy: 0.7552\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4510 - accuracy: 0.7899 - val_loss: 0.4936 - val_accuracy: 0.7552\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.7899 - val_loss: 0.4935 - val_accuracy: 0.7552\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.7882 - val_loss: 0.4935 - val_accuracy: 0.7552\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 990us/step - loss: 0.4508 - accuracy: 0.7899 - val_loss: 0.4935 - val_accuracy: 0.7552\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 945us/step - loss: 0.4507 - accuracy: 0.7882 - val_loss: 0.4934 - val_accuracy: 0.7552\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.7882 - val_loss: 0.4934 - val_accuracy: 0.7552\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.7882 - val_loss: 0.4934 - val_accuracy: 0.7552\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7882 - val_loss: 0.4933 - val_accuracy: 0.7552\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.7882 - val_loss: 0.4933 - val_accuracy: 0.7552\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 982us/step - loss: 0.4504 - accuracy: 0.7882 - val_loss: 0.4933 - val_accuracy: 0.7552\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 968us/step - loss: 0.4504 - accuracy: 0.7882 - val_loss: 0.4932 - val_accuracy: 0.7552\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 992us/step - loss: 0.4503 - accuracy: 0.7882 - val_loss: 0.4932 - val_accuracy: 0.7552\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4502 - accuracy: 0.7882 - val_loss: 0.4932 - val_accuracy: 0.7552\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4502 - accuracy: 0.7882 - val_loss: 0.4932 - val_accuracy: 0.7552\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.7882 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.7882 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4500 - accuracy: 0.7882 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 939us/step - loss: 0.4500 - accuracy: 0.7882 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4499 - accuracy: 0.7882 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 914us/step - loss: 0.4499 - accuracy: 0.7882 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 879us/step - loss: 0.4498 - accuracy: 0.7882 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 940us/step - loss: 0.4498 - accuracy: 0.7882 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 867us/step - loss: 0.4497 - accuracy: 0.7882 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.7882 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7882 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7882 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.7917 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 936us/step - loss: 0.4495 - accuracy: 0.7917 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 865us/step - loss: 0.4495 - accuracy: 0.7899 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 926us/step - loss: 0.4494 - accuracy: 0.7882 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 905us/step - loss: 0.4494 - accuracy: 0.7899 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4493 - accuracy: 0.7917 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 958us/step - loss: 0.4493 - accuracy: 0.7899 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4492 - accuracy: 0.7934 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4492 - accuracy: 0.7917 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 936us/step - loss: 0.4491 - accuracy: 0.7917 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 932us/step - loss: 0.4491 - accuracy: 0.7917 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 920us/step - loss: 0.4490 - accuracy: 0.7934 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 934us/step - loss: 0.4490 - accuracy: 0.7917 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 918us/step - loss: 0.4489 - accuracy: 0.7917 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4489 - accuracy: 0.7917 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 914us/step - loss: 0.4489 - accuracy: 0.7934 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.4488 - accuracy: 0.7917 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.4487 - accuracy: 0.7934 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.7934 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4487 - accuracy: 0.7934 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.4486 - accuracy: 0.7934 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7934 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7917 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4485 - accuracy: 0.7951 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 939us/step - loss: 0.4485 - accuracy: 0.7917 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4484 - accuracy: 0.7917 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.4483 - accuracy: 0.7917 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4483 - accuracy: 0.7934 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 904us/step - loss: 0.4483 - accuracy: 0.7934 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.4482 - accuracy: 0.7934 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 879us/step - loss: 0.4482 - accuracy: 0.7917 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4481 - accuracy: 0.7934 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4481 - accuracy: 0.7951 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 895us/step - loss: 0.4480 - accuracy: 0.7934 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 876us/step - loss: 0.4480 - accuracy: 0.7934 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4480 - accuracy: 0.7917 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4479 - accuracy: 0.7934 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 873us/step - loss: 0.4479 - accuracy: 0.7934 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 901us/step - loss: 0.4478 - accuracy: 0.7934 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4478 - accuracy: 0.7934 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 872us/step - loss: 0.4478 - accuracy: 0.7917 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 914us/step - loss: 0.4477 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 875us/step - loss: 0.4477 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 853us/step - loss: 0.4477 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 930us/step - loss: 0.4476 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4476 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 868us/step - loss: 0.4474 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 901us/step - loss: 0.4474 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.4474 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4473 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 922us/step - loss: 0.4473 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 857us/step - loss: 0.4473 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4472 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.4472 - accuracy: 0.7899 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4471 - accuracy: 0.7899 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 885us/step - loss: 0.4471 - accuracy: 0.7899 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 904us/step - loss: 0.4471 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4470 - accuracy: 0.7899 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4470 - accuracy: 0.7899 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 915us/step - loss: 0.4470 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 917us/step - loss: 0.4469 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4469 - accuracy: 0.7899 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.4469 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4468 - accuracy: 0.7917 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4468 - accuracy: 0.7899 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4468 - accuracy: 0.7917 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 925us/step - loss: 0.4467 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.4467 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4466 - accuracy: 0.7917 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4466 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 851us/step - loss: 0.4466 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 862us/step - loss: 0.4465 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 913us/step - loss: 0.4465 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4464 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 885us/step - loss: 0.4464 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 927us/step - loss: 0.4464 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 884us/step - loss: 0.4463 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 909us/step - loss: 0.4463 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4462 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.4462 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4462 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.4462 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 881us/step - loss: 0.4461 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4461 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4460 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 915us/step - loss: 0.4461 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4460 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4460 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4459 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4460 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4459 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 887us/step - loss: 0.4458 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4458 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.4457 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 865us/step - loss: 0.4457 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 924us/step - loss: 0.4457 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 958us/step - loss: 0.4456 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 872us/step - loss: 0.4456 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.4456 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 877us/step - loss: 0.4455 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 924us/step - loss: 0.4455 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 923us/step - loss: 0.4455 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.4455 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.4454 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 871us/step - loss: 0.4454 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 929us/step - loss: 0.4453 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.4453 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 887us/step - loss: 0.4453 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4452 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4453 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 876us/step - loss: 0.4452 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.4451 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 904us/step - loss: 0.4451 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4451 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 952us/step - loss: 0.4450 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4450 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4449 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.4449 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4449 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 909us/step - loss: 0.4449 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 921us/step - loss: 0.4449 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 908us/step - loss: 0.4448 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 923us/step - loss: 0.4448 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 909us/step - loss: 0.4448 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4447 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 921us/step - loss: 0.4447 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 914us/step - loss: 0.4447 - accuracy: 0.7882 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4446 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4447 - accuracy: 0.7865 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7882 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4446 - accuracy: 0.7882 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 869us/step - loss: 0.4446 - accuracy: 0.7882 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 934us/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 876us/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 924us/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 924us/step - loss: 0.4444 - accuracy: 0.7865 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4444 - accuracy: 0.7882 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4444 - accuracy: 0.7865 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 915us/step - loss: 0.4443 - accuracy: 0.7882 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4443 - accuracy: 0.7882 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4443 - accuracy: 0.7882 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4443 - accuracy: 0.7882 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4443 - accuracy: 0.7882 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4442 - accuracy: 0.7882 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 952us/step - loss: 0.4442 - accuracy: 0.7882 - val_loss: 0.4918 - val_accuracy: 0.7604\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4442 - accuracy: 0.7882 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4442 - accuracy: 0.7882 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4442 - accuracy: 0.7882 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4441 - accuracy: 0.7882 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7882 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 933us/step - loss: 0.4441 - accuracy: 0.7882 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 950us/step - loss: 0.4440 - accuracy: 0.7882 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 934us/step - loss: 0.4440 - accuracy: 0.7882 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.4440 - accuracy: 0.7882 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 918us/step - loss: 0.4439 - accuracy: 0.7882 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 885us/step - loss: 0.4439 - accuracy: 0.7882 - val_loss: 0.4917 - val_accuracy: 0.7604\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.7882 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.7882 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4439 - accuracy: 0.7882 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4438 - accuracy: 0.7882 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4438 - accuracy: 0.7882 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 916us/step - loss: 0.4438 - accuracy: 0.7882 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 909us/step - loss: 0.4437 - accuracy: 0.7882 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4437 - accuracy: 0.7882 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 992us/step - loss: 0.4437 - accuracy: 0.7882 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 922us/step - loss: 0.4437 - accuracy: 0.7882 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4437 - accuracy: 0.7882 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4436 - accuracy: 0.7882 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4436 - accuracy: 0.7882 - val_loss: 0.4916 - val_accuracy: 0.7500\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4436 - accuracy: 0.7882 - val_loss: 0.4916 - val_accuracy: 0.7500\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.7882 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.7882 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 877us/step - loss: 0.4434 - accuracy: 0.7882 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4434 - accuracy: 0.7882 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.4434 - accuracy: 0.7882 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.4434 - accuracy: 0.7882 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4434 - accuracy: 0.7882 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4433 - accuracy: 0.7882 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.4433 - accuracy: 0.7882 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4433 - accuracy: 0.7882 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4433 - accuracy: 0.7899 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4433 - accuracy: 0.7882 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 881us/step - loss: 0.4432 - accuracy: 0.7882 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4432 - accuracy: 0.7882 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 885us/step - loss: 0.4432 - accuracy: 0.7882 - val_loss: 0.4914 - val_accuracy: 0.7500\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 906us/step - loss: 0.4431 - accuracy: 0.7882 - val_loss: 0.4914 - val_accuracy: 0.7500\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4431 - accuracy: 0.7882 - val_loss: 0.4914 - val_accuracy: 0.7500\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4431 - accuracy: 0.7882 - val_loss: 0.4914 - val_accuracy: 0.7500\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 964us/step - loss: 0.4431 - accuracy: 0.7882 - val_loss: 0.4914 - val_accuracy: 0.7500\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.4430 - accuracy: 0.7899 - val_loss: 0.4914 - val_accuracy: 0.7500\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 858us/step - loss: 0.4430 - accuracy: 0.7882 - val_loss: 0.4914 - val_accuracy: 0.7500\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7882 - val_loss: 0.4914 - val_accuracy: 0.7500\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 925us/step - loss: 0.4430 - accuracy: 0.7899 - val_loss: 0.4914 - val_accuracy: 0.7500\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4429 - accuracy: 0.7882 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 916us/step - loss: 0.4429 - accuracy: 0.7899 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 925us/step - loss: 0.4429 - accuracy: 0.7882 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 915us/step - loss: 0.4429 - accuracy: 0.7882 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 895us/step - loss: 0.4428 - accuracy: 0.7882 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4428 - accuracy: 0.7899 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 966us/step - loss: 0.4428 - accuracy: 0.7899 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 982us/step - loss: 0.4428 - accuracy: 0.7899 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 938us/step - loss: 0.4427 - accuracy: 0.7882 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 915us/step - loss: 0.4427 - accuracy: 0.7899 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.4427 - accuracy: 0.7899 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4427 - accuracy: 0.7899 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4427 - accuracy: 0.7899 - val_loss: 0.4915 - val_accuracy: 0.7500\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4426 - accuracy: 0.7899 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.4426 - accuracy: 0.7899 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7899 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 877us/step - loss: 0.4425 - accuracy: 0.7899 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 885us/step - loss: 0.4425 - accuracy: 0.7899 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4425 - accuracy: 0.7899 - val_loss: 0.4915 - val_accuracy: 0.7448\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 908us/step - loss: 0.4425 - accuracy: 0.7917 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.4425 - accuracy: 0.7882 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.4424 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 923us/step - loss: 0.4424 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 916us/step - loss: 0.4423 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4423 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 867us/step - loss: 0.4423 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 878us/step - loss: 0.4422 - accuracy: 0.7917 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 920us/step - loss: 0.4422 - accuracy: 0.7917 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 901us/step - loss: 0.4421 - accuracy: 0.7917 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4421 - accuracy: 0.7917 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4421 - accuracy: 0.7917 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 874us/step - loss: 0.4421 - accuracy: 0.7917 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.4421 - accuracy: 0.7917 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4420 - accuracy: 0.7917 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 935us/step - loss: 0.4420 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 879us/step - loss: 0.4420 - accuracy: 0.7917 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4420 - accuracy: 0.7917 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.4419 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4419 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4419 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4419 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 928us/step - loss: 0.4419 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 919us/step - loss: 0.4418 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 946us/step - loss: 0.4418 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4418 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 905us/step - loss: 0.4418 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4417 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4417 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 916us/step - loss: 0.4417 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 913us/step - loss: 0.4416 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 957us/step - loss: 0.4416 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.4416 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4416 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 887us/step - loss: 0.4416 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4416 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 885us/step - loss: 0.4415 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4415 - accuracy: 0.7899 - val_loss: 0.4916 - val_accuracy: 0.7448\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 919us/step - loss: 0.4415 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4414 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4415 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 879us/step - loss: 0.4414 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 905us/step - loss: 0.4414 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4413 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4413 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4413 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 931us/step - loss: 0.4413 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4413 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 925us/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 901us/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4412 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 925us/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.4917 - val_accuracy: 0.7448\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7899 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 857us/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 862us/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 945us/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 864us/step - loss: 0.4409 - accuracy: 0.7899 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4409 - accuracy: 0.7899 - val_loss: 0.4918 - val_accuracy: 0.7448\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 989us/step - loss: 0.4409 - accuracy: 0.7899 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 858us/step - loss: 0.4409 - accuracy: 0.7899 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 963us/step - loss: 0.4409 - accuracy: 0.7899 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 876us/step - loss: 0.4409 - accuracy: 0.7899 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.4408 - accuracy: 0.7899 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.7899 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4408 - accuracy: 0.7899 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 912us/step - loss: 0.4408 - accuracy: 0.7899 - val_loss: 0.4919 - val_accuracy: 0.7448\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 915us/step - loss: 0.4407 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 921us/step - loss: 0.4407 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 901us/step - loss: 0.4407 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 946us/step - loss: 0.4407 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 875us/step - loss: 0.4407 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 885us/step - loss: 0.4406 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.4406 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 875us/step - loss: 0.4406 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 927us/step - loss: 0.4406 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.4406 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 917us/step - loss: 0.4405 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4404 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 860us/step - loss: 0.4404 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4404 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 905us/step - loss: 0.4403 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 867us/step - loss: 0.4403 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 917us/step - loss: 0.4403 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 919us/step - loss: 0.4403 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 916us/step - loss: 0.4402 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4403 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 929us/step - loss: 0.4402 - accuracy: 0.7899 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4402 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4401 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 904us/step - loss: 0.4402 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 914us/step - loss: 0.4402 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4401 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4401 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4401 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 895us/step - loss: 0.4400 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4400 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4400 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 905us/step - loss: 0.4400 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 983us/step - loss: 0.4400 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4399 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 855us/step - loss: 0.4399 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 864us/step - loss: 0.4399 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 959us/step - loss: 0.4399 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4398 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 916us/step - loss: 0.4398 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 957us/step - loss: 0.4398 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 881us/step - loss: 0.4398 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 934us/step - loss: 0.4398 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4397 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 901us/step - loss: 0.4397 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4396 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 869us/step - loss: 0.4397 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 884us/step - loss: 0.4397 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 936us/step - loss: 0.4396 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 947us/step - loss: 0.4396 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 927us/step - loss: 0.4396 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4395 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 906us/step - loss: 0.4395 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4395 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 921us/step - loss: 0.4395 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 926us/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7448\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 881us/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 918us/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 967us/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4393 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4392 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4392 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4391 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4391 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 905us/step - loss: 0.4391 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 967us/step - loss: 0.4391 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 975us/step - loss: 0.4391 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4391 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4390 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4391 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4390 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 901us/step - loss: 0.4390 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4390 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4389 - accuracy: 0.7899 - val_loss: 0.4921 - val_accuracy: 0.7448\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 924us/step - loss: 0.4389 - accuracy: 0.7899 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 870us/step - loss: 0.4389 - accuracy: 0.7899 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 876us/step - loss: 0.4389 - accuracy: 0.7899 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7899 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4388 - accuracy: 0.7917 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 909us/step - loss: 0.4388 - accuracy: 0.7899 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 921us/step - loss: 0.4388 - accuracy: 0.7899 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 935us/step - loss: 0.4388 - accuracy: 0.7917 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4387 - accuracy: 0.7917 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4387 - accuracy: 0.7917 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4387 - accuracy: 0.7917 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 927us/step - loss: 0.4387 - accuracy: 0.7899 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 864us/step - loss: 0.4387 - accuracy: 0.7917 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 873us/step - loss: 0.4387 - accuracy: 0.7917 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 936us/step - loss: 0.4387 - accuracy: 0.7917 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 926us/step - loss: 0.4386 - accuracy: 0.7899 - val_loss: 0.4922 - val_accuracy: 0.7448\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 946us/step - loss: 0.4386 - accuracy: 0.7917 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4386 - accuracy: 0.7917 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 904us/step - loss: 0.4386 - accuracy: 0.7917 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4386 - accuracy: 0.7917 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7917 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.7917 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 884us/step - loss: 0.4385 - accuracy: 0.7899 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.7917 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 912us/step - loss: 0.4385 - accuracy: 0.7917 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4384 - accuracy: 0.7917 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4384 - accuracy: 0.7917 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 905us/step - loss: 0.4384 - accuracy: 0.7917 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 864us/step - loss: 0.4383 - accuracy: 0.7917 - val_loss: 0.4923 - val_accuracy: 0.7448\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 872us/step - loss: 0.4383 - accuracy: 0.7917 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 912us/step - loss: 0.4383 - accuracy: 0.7917 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 901us/step - loss: 0.4383 - accuracy: 0.7917 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.4382 - accuracy: 0.7917 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 949us/step - loss: 0.4383 - accuracy: 0.7917 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7917 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.7917 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 872us/step - loss: 0.4381 - accuracy: 0.7917 - val_loss: 0.4924 - val_accuracy: 0.7448\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 874us/step - loss: 0.4382 - accuracy: 0.7917 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.7917 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4381 - accuracy: 0.7917 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 901us/step - loss: 0.4381 - accuracy: 0.7917 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4381 - accuracy: 0.7917 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 914us/step - loss: 0.4381 - accuracy: 0.7917 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 875us/step - loss: 0.4380 - accuracy: 0.7917 - val_loss: 0.4925 - val_accuracy: 0.7448\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 878us/step - loss: 0.4380 - accuracy: 0.7917 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 943us/step - loss: 0.4380 - accuracy: 0.7917 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4380 - accuracy: 0.7917 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 929us/step - loss: 0.4379 - accuracy: 0.7917 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4379 - accuracy: 0.7917 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7917 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 866us/step - loss: 0.4379 - accuracy: 0.7917 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 917us/step - loss: 0.4379 - accuracy: 0.7917 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 913us/step - loss: 0.4378 - accuracy: 0.7917 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 904us/step - loss: 0.4378 - accuracy: 0.7917 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.4378 - accuracy: 0.7917 - val_loss: 0.4926 - val_accuracy: 0.7448\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4378 - accuracy: 0.7917 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 954us/step - loss: 0.4378 - accuracy: 0.7917 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 869us/step - loss: 0.4378 - accuracy: 0.7917 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.7917 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4377 - accuracy: 0.7917 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 912us/step - loss: 0.4377 - accuracy: 0.7917 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 943us/step - loss: 0.4377 - accuracy: 0.7917 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 879us/step - loss: 0.4377 - accuracy: 0.7917 - val_loss: 0.4927 - val_accuracy: 0.7448\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7917 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 993us/step - loss: 0.4376 - accuracy: 0.7917 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 924us/step - loss: 0.4375 - accuracy: 0.7917 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4376 - accuracy: 0.7917 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 921us/step - loss: 0.4375 - accuracy: 0.7917 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4375 - accuracy: 0.7917 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.4375 - accuracy: 0.7917 - val_loss: 0.4928 - val_accuracy: 0.7448\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4375 - accuracy: 0.7917 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.4374 - accuracy: 0.7917 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4374 - accuracy: 0.7917 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 938us/step - loss: 0.4374 - accuracy: 0.7917 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 913us/step - loss: 0.4374 - accuracy: 0.7917 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.4374 - accuracy: 0.7917 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 918us/step - loss: 0.4374 - accuracy: 0.7917 - val_loss: 0.4929 - val_accuracy: 0.7448\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.4374 - accuracy: 0.7917 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7917 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.7917 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 877us/step - loss: 0.4374 - accuracy: 0.7917 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4373 - accuracy: 0.7917 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 935us/step - loss: 0.4372 - accuracy: 0.7917 - val_loss: 0.4930 - val_accuracy: 0.7448\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4372 - accuracy: 0.7917 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 942us/step - loss: 0.4372 - accuracy: 0.7917 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7917 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 909us/step - loss: 0.4372 - accuracy: 0.7917 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4372 - accuracy: 0.7917 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4371 - accuracy: 0.7934 - val_loss: 0.4931 - val_accuracy: 0.7448\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 904us/step - loss: 0.4371 - accuracy: 0.7917 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 870us/step - loss: 0.4371 - accuracy: 0.7934 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 944us/step - loss: 0.4371 - accuracy: 0.7934 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.4371 - accuracy: 0.7934 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4370 - accuracy: 0.7934 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7934 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.7934 - val_loss: 0.4932 - val_accuracy: 0.7448\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 878us/step - loss: 0.4370 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4369 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.4370 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 901us/step - loss: 0.4369 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4369 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 926us/step - loss: 0.4368 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 920us/step - loss: 0.4368 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 942us/step - loss: 0.4368 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 935us/step - loss: 0.4368 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 885us/step - loss: 0.4367 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 938us/step - loss: 0.4368 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4367 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 925us/step - loss: 0.4367 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.4367 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4366 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 927us/step - loss: 0.4366 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 862us/step - loss: 0.4365 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4366 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 856us/step - loss: 0.4366 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4365 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 906us/step - loss: 0.4365 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 964us/step - loss: 0.4364 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7448\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 876us/step - loss: 0.4364 - accuracy: 0.7934 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7934 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.7934 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4364 - accuracy: 0.7934 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 931us/step - loss: 0.4364 - accuracy: 0.7934 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 962us/step - loss: 0.4363 - accuracy: 0.7934 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 866us/step - loss: 0.4364 - accuracy: 0.7934 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 935us/step - loss: 0.4363 - accuracy: 0.7934 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 924us/step - loss: 0.4363 - accuracy: 0.7934 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7934 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4362 - accuracy: 0.7934 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4362 - accuracy: 0.7934 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4362 - accuracy: 0.7934 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7934 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 865us/step - loss: 0.4362 - accuracy: 0.7934 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 867us/step - loss: 0.4361 - accuracy: 0.7934 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 904us/step - loss: 0.4361 - accuracy: 0.7934 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 917us/step - loss: 0.4361 - accuracy: 0.7934 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 908us/step - loss: 0.4360 - accuracy: 0.7934 - val_loss: 0.4934 - val_accuracy: 0.7448\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4360 - accuracy: 0.7934 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 927us/step - loss: 0.4360 - accuracy: 0.7934 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 905us/step - loss: 0.4360 - accuracy: 0.7934 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4360 - accuracy: 0.7934 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 979us/step - loss: 0.4360 - accuracy: 0.7934 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7934 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4360 - accuracy: 0.7934 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4359 - accuracy: 0.7934 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 895us/step - loss: 0.4359 - accuracy: 0.7934 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4359 - accuracy: 0.7934 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 879us/step - loss: 0.4358 - accuracy: 0.7934 - val_loss: 0.4935 - val_accuracy: 0.7448\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.4358 - accuracy: 0.7934 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4358 - accuracy: 0.7934 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 948us/step - loss: 0.4358 - accuracy: 0.7934 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4358 - accuracy: 0.7934 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4357 - accuracy: 0.7934 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7934 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7934 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4357 - accuracy: 0.7934 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4357 - accuracy: 0.7934 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.7934 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4356 - accuracy: 0.7934 - val_loss: 0.4936 - val_accuracy: 0.7448\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4356 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 973us/step - loss: 0.4355 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 904us/step - loss: 0.4355 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 901us/step - loss: 0.4355 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 947us/step - loss: 0.4355 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 939us/step - loss: 0.4355 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 906us/step - loss: 0.4354 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 935us/step - loss: 0.4354 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 964us/step - loss: 0.4353 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 916us/step - loss: 0.4354 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 948us/step - loss: 0.4353 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7448\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4353 - accuracy: 0.7934 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 856us/step - loss: 0.4353 - accuracy: 0.7934 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 956us/step - loss: 0.4353 - accuracy: 0.7934 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 901us/step - loss: 0.4353 - accuracy: 0.7934 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 887us/step - loss: 0.4352 - accuracy: 0.7934 - val_loss: 0.4938 - val_accuracy: 0.7448\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7934 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 884us/step - loss: 0.4352 - accuracy: 0.7934 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 864us/step - loss: 0.4352 - accuracy: 0.7934 - val_loss: 0.4939 - val_accuracy: 0.7448\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 959us/step - loss: 0.4351 - accuracy: 0.7934 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 881us/step - loss: 0.4351 - accuracy: 0.7934 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 952us/step - loss: 0.4351 - accuracy: 0.7934 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 916us/step - loss: 0.4351 - accuracy: 0.7934 - val_loss: 0.4940 - val_accuracy: 0.7448\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7934 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 876us/step - loss: 0.4351 - accuracy: 0.7934 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4351 - accuracy: 0.7951 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4350 - accuracy: 0.7934 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7934 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 904us/step - loss: 0.4349 - accuracy: 0.7934 - val_loss: 0.4941 - val_accuracy: 0.7448\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4349 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 924us/step - loss: 0.4349 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4348 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 943us/step - loss: 0.4348 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 925us/step - loss: 0.4348 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4348 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7448\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4348 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7500\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7500\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7500\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 864us/step - loss: 0.4347 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7500\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 946us/step - loss: 0.4346 - accuracy: 0.7969 - val_loss: 0.4942 - val_accuracy: 0.7500\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 881us/step - loss: 0.4347 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7500\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 935us/step - loss: 0.4347 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7500\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 918us/step - loss: 0.4346 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7500\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 921us/step - loss: 0.4346 - accuracy: 0.7934 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4346 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4346 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4345 - accuracy: 0.7934 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 977us/step - loss: 0.4345 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4344 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4344 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 869us/step - loss: 0.4344 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 936us/step - loss: 0.4344 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.4344 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 914us/step - loss: 0.4344 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 934us/step - loss: 0.4343 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 895us/step - loss: 0.4343 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 982us/step - loss: 0.4343 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 877us/step - loss: 0.4342 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4341 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 912us/step - loss: 0.4341 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 947us/step - loss: 0.4341 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4341 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4341 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 908us/step - loss: 0.4340 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4340 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 868us/step - loss: 0.4340 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 997us/step - loss: 0.4340 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4339 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4339 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 916us/step - loss: 0.4338 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 906us/step - loss: 0.4338 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 908us/step - loss: 0.4338 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.4338 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4338 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 921us/step - loss: 0.4338 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 930us/step - loss: 0.4337 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4337 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 918us/step - loss: 0.4336 - accuracy: 0.7986 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.4336 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4336 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4336 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4336 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4335 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7986 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4335 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 895us/step - loss: 0.4334 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 870us/step - loss: 0.4335 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 924us/step - loss: 0.4334 - accuracy: 0.7986 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 931us/step - loss: 0.4334 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.4334 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 915us/step - loss: 0.4334 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4333 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4333 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4333 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4333 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 960us/step - loss: 0.4333 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 927us/step - loss: 0.4332 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 968us/step - loss: 0.4332 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 923us/step - loss: 0.4332 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 930us/step - loss: 0.4332 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4332 - accuracy: 0.7986 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.4331 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 939us/step - loss: 0.4331 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 913us/step - loss: 0.4331 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4331 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 916us/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 935us/step - loss: 0.4330 - accuracy: 0.7986 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 863us/step - loss: 0.4330 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 885us/step - loss: 0.4330 - accuracy: 0.7986 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4329 - accuracy: 0.7986 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 887us/step - loss: 0.4329 - accuracy: 0.7986 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4329 - accuracy: 0.7986 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 919us/step - loss: 0.4329 - accuracy: 0.7986 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 923us/step - loss: 0.4328 - accuracy: 0.7986 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 944us/step - loss: 0.4329 - accuracy: 0.7986 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4328 - accuracy: 0.7986 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4327 - accuracy: 0.7986 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1083/1500\n",
      "18/18 [==============================] - 0s 917us/step - loss: 0.4327 - accuracy: 0.7986 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 916us/step - loss: 0.4327 - accuracy: 0.7986 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 885us/step - loss: 0.4327 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 988us/step - loss: 0.4327 - accuracy: 0.7986 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 879us/step - loss: 0.4326 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 932us/step - loss: 0.4327 - accuracy: 0.7986 - val_loss: 0.4944 - val_accuracy: 0.7500\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 931us/step - loss: 0.4326 - accuracy: 0.7986 - val_loss: 0.4944 - val_accuracy: 0.7500\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.4326 - accuracy: 0.7969 - val_loss: 0.4944 - val_accuracy: 0.7500\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4326 - accuracy: 0.7986 - val_loss: 0.4944 - val_accuracy: 0.7500\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4326 - accuracy: 0.7986 - val_loss: 0.4944 - val_accuracy: 0.7500\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 927us/step - loss: 0.4325 - accuracy: 0.7986 - val_loss: 0.4944 - val_accuracy: 0.7500\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 904us/step - loss: 0.4325 - accuracy: 0.7986 - val_loss: 0.4944 - val_accuracy: 0.7500\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7986 - val_loss: 0.4944 - val_accuracy: 0.7500\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7969 - val_loss: 0.4945 - val_accuracy: 0.7552\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 871us/step - loss: 0.4324 - accuracy: 0.7986 - val_loss: 0.4945 - val_accuracy: 0.7552\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 913us/step - loss: 0.4324 - accuracy: 0.7986 - val_loss: 0.4945 - val_accuracy: 0.7552\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 957us/step - loss: 0.4324 - accuracy: 0.7986 - val_loss: 0.4945 - val_accuracy: 0.7552\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 922us/step - loss: 0.4323 - accuracy: 0.7986 - val_loss: 0.4945 - val_accuracy: 0.7552\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 944us/step - loss: 0.4323 - accuracy: 0.7986 - val_loss: 0.4945 - val_accuracy: 0.7552\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 878us/step - loss: 0.4323 - accuracy: 0.7986 - val_loss: 0.4946 - val_accuracy: 0.7552\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 938us/step - loss: 0.4323 - accuracy: 0.7986 - val_loss: 0.4946 - val_accuracy: 0.7552\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4322 - accuracy: 0.7986 - val_loss: 0.4946 - val_accuracy: 0.7552\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4322 - accuracy: 0.7986 - val_loss: 0.4946 - val_accuracy: 0.7552\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 945us/step - loss: 0.4322 - accuracy: 0.7986 - val_loss: 0.4946 - val_accuracy: 0.7552\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 920us/step - loss: 0.4322 - accuracy: 0.7986 - val_loss: 0.4946 - val_accuracy: 0.7552\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7552\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4322 - accuracy: 0.7969 - val_loss: 0.4947 - val_accuracy: 0.7552\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4321 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7552\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 901us/step - loss: 0.4321 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7552\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 919us/step - loss: 0.4322 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7552\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 930us/step - loss: 0.4321 - accuracy: 0.7986 - val_loss: 0.4947 - val_accuracy: 0.7552\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4321 - accuracy: 0.7986 - val_loss: 0.4948 - val_accuracy: 0.7552\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4320 - accuracy: 0.7986 - val_loss: 0.4948 - val_accuracy: 0.7604\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4321 - accuracy: 0.7986 - val_loss: 0.4948 - val_accuracy: 0.7604\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 982us/step - loss: 0.4320 - accuracy: 0.8003 - val_loss: 0.4948 - val_accuracy: 0.7604\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7986 - val_loss: 0.4948 - val_accuracy: 0.7604\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 867us/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.4948 - val_accuracy: 0.7604\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 945us/step - loss: 0.4320 - accuracy: 0.7986 - val_loss: 0.4948 - val_accuracy: 0.7604\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.4949 - val_accuracy: 0.7604\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 901us/step - loss: 0.4319 - accuracy: 0.8003 - val_loss: 0.4949 - val_accuracy: 0.7604\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 923us/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.4949 - val_accuracy: 0.7604\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 937us/step - loss: 0.4318 - accuracy: 0.7986 - val_loss: 0.4949 - val_accuracy: 0.7604\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.4318 - accuracy: 0.8003 - val_loss: 0.4949 - val_accuracy: 0.7604\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4319 - accuracy: 0.8003 - val_loss: 0.4950 - val_accuracy: 0.7604\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4318 - accuracy: 0.7969 - val_loss: 0.4950 - val_accuracy: 0.7604\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.8003 - val_loss: 0.4950 - val_accuracy: 0.7604\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 876us/step - loss: 0.4317 - accuracy: 0.8003 - val_loss: 0.4950 - val_accuracy: 0.7604\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 967us/step - loss: 0.4317 - accuracy: 0.8003 - val_loss: 0.4950 - val_accuracy: 0.7604\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 924us/step - loss: 0.4317 - accuracy: 0.8003 - val_loss: 0.4950 - val_accuracy: 0.7604\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 901us/step - loss: 0.4317 - accuracy: 0.8003 - val_loss: 0.4950 - val_accuracy: 0.7604\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 973us/step - loss: 0.4317 - accuracy: 0.8003 - val_loss: 0.4951 - val_accuracy: 0.7604\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 918us/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.4951 - val_accuracy: 0.7604\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 953us/step - loss: 0.4317 - accuracy: 0.8003 - val_loss: 0.4951 - val_accuracy: 0.7604\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4316 - accuracy: 0.8003 - val_loss: 0.4951 - val_accuracy: 0.7604\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8003 - val_loss: 0.4951 - val_accuracy: 0.7604\n",
      "Epoch 1139/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4316 - accuracy: 0.8003 - val_loss: 0.4951 - val_accuracy: 0.7604\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 904us/step - loss: 0.4315 - accuracy: 0.8003 - val_loss: 0.4952 - val_accuracy: 0.7604\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 905us/step - loss: 0.4316 - accuracy: 0.8003 - val_loss: 0.4952 - val_accuracy: 0.7604\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4315 - accuracy: 0.8003 - val_loss: 0.4952 - val_accuracy: 0.7604\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 946us/step - loss: 0.4316 - accuracy: 0.7986 - val_loss: 0.4952 - val_accuracy: 0.7604\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4315 - accuracy: 0.8003 - val_loss: 0.4952 - val_accuracy: 0.7604\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 917us/step - loss: 0.4315 - accuracy: 0.8003 - val_loss: 0.4952 - val_accuracy: 0.7604\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.4953 - val_accuracy: 0.7604\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4314 - accuracy: 0.8003 - val_loss: 0.4953 - val_accuracy: 0.7604\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.8003 - val_loss: 0.4953 - val_accuracy: 0.7604\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 859us/step - loss: 0.4314 - accuracy: 0.8003 - val_loss: 0.4953 - val_accuracy: 0.7604\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4314 - accuracy: 0.8003 - val_loss: 0.4953 - val_accuracy: 0.7604\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4314 - accuracy: 0.8003 - val_loss: 0.4953 - val_accuracy: 0.7604\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4314 - accuracy: 0.8003 - val_loss: 0.4954 - val_accuracy: 0.7604\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4313 - accuracy: 0.7986 - val_loss: 0.4954 - val_accuracy: 0.7604\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7986 - val_loss: 0.4954 - val_accuracy: 0.7604\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 879us/step - loss: 0.4313 - accuracy: 0.7986 - val_loss: 0.4954 - val_accuracy: 0.7604\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 871us/step - loss: 0.4313 - accuracy: 0.7986 - val_loss: 0.4954 - val_accuracy: 0.7604\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.8003 - val_loss: 0.4954 - val_accuracy: 0.7604\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 874us/step - loss: 0.4312 - accuracy: 0.7986 - val_loss: 0.4955 - val_accuracy: 0.7604\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 937us/step - loss: 0.4312 - accuracy: 0.7986 - val_loss: 0.4955 - val_accuracy: 0.7604\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4312 - accuracy: 0.7986 - val_loss: 0.4955 - val_accuracy: 0.7604\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 951us/step - loss: 0.4312 - accuracy: 0.7986 - val_loss: 0.4955 - val_accuracy: 0.7604\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.4312 - accuracy: 0.8003 - val_loss: 0.4955 - val_accuracy: 0.7604\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.4312 - accuracy: 0.7986 - val_loss: 0.4955 - val_accuracy: 0.7604\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 904us/step - loss: 0.4312 - accuracy: 0.7986 - val_loss: 0.4956 - val_accuracy: 0.7604\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4311 - accuracy: 0.7986 - val_loss: 0.4956 - val_accuracy: 0.7604\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.4311 - accuracy: 0.7986 - val_loss: 0.4956 - val_accuracy: 0.7604\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7986 - val_loss: 0.4956 - val_accuracy: 0.7604\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4311 - accuracy: 0.7969 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 901us/step - loss: 0.4311 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 918us/step - loss: 0.4311 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 940us/step - loss: 0.4310 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4310 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 943us/step - loss: 0.4310 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 879us/step - loss: 0.4309 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 915us/step - loss: 0.4310 - accuracy: 0.7969 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 924us/step - loss: 0.4310 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7969 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.4309 - accuracy: 0.7969 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 875us/step - loss: 0.4309 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 904us/step - loss: 0.4309 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4308 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 929us/step - loss: 0.4308 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 818us/step - loss: 0.4308 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 973us/step - loss: 0.4307 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 828us/step - loss: 0.4307 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4307 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4307 - accuracy: 0.7969 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 870us/step - loss: 0.4307 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4306 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 929us/step - loss: 0.4306 - accuracy: 0.7969 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4306 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 922us/step - loss: 0.4305 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1195/1500\n",
      "18/18 [==============================] - 0s 908us/step - loss: 0.4305 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7969 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 912us/step - loss: 0.4305 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4304 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4304 - accuracy: 0.7969 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 933us/step - loss: 0.4304 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4304 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 959us/step - loss: 0.4304 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 908us/step - loss: 0.4303 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 908us/step - loss: 0.4304 - accuracy: 0.7986 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 929us/step - loss: 0.4303 - accuracy: 0.7986 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 919us/step - loss: 0.4303 - accuracy: 0.7986 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 942us/step - loss: 0.4302 - accuracy: 0.7986 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 878us/step - loss: 0.4303 - accuracy: 0.7986 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 943us/step - loss: 0.4302 - accuracy: 0.7986 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4302 - accuracy: 0.7986 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7986 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4302 - accuracy: 0.7986 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4302 - accuracy: 0.7986 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4302 - accuracy: 0.7986 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 968us/step - loss: 0.4301 - accuracy: 0.7986 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4301 - accuracy: 0.7986 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 995us/step - loss: 0.4301 - accuracy: 0.7986 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 881us/step - loss: 0.4301 - accuracy: 0.8003 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 955us/step - loss: 0.4300 - accuracy: 0.7986 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.8003 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 870us/step - loss: 0.4300 - accuracy: 0.8003 - val_loss: 0.4959 - val_accuracy: 0.7604\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4300 - accuracy: 0.7986 - val_loss: 0.4959 - val_accuracy: 0.7604\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 849us/step - loss: 0.4299 - accuracy: 0.8003 - val_loss: 0.4959 - val_accuracy: 0.7604\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 918us/step - loss: 0.4299 - accuracy: 0.7969 - val_loss: 0.4959 - val_accuracy: 0.7604\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4299 - accuracy: 0.8003 - val_loss: 0.4959 - val_accuracy: 0.7604\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.4299 - accuracy: 0.7986 - val_loss: 0.4959 - val_accuracy: 0.7604\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4299 - accuracy: 0.8003 - val_loss: 0.4959 - val_accuracy: 0.7656\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 918us/step - loss: 0.4298 - accuracy: 0.7986 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.8003 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 843us/step - loss: 0.4298 - accuracy: 0.7986 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 912us/step - loss: 0.4298 - accuracy: 0.7969 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 878us/step - loss: 0.4298 - accuracy: 0.7986 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 978us/step - loss: 0.4297 - accuracy: 0.7969 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4297 - accuracy: 0.7986 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4297 - accuracy: 0.7986 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 947us/step - loss: 0.4296 - accuracy: 0.8003 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4296 - accuracy: 0.7986 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 918us/step - loss: 0.4296 - accuracy: 0.7986 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 918us/step - loss: 0.4296 - accuracy: 0.7969 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7986 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 905us/step - loss: 0.4295 - accuracy: 0.8003 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 919us/step - loss: 0.4295 - accuracy: 0.7986 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.7986 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4295 - accuracy: 0.7986 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 867us/step - loss: 0.4294 - accuracy: 0.7986 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 881us/step - loss: 0.4295 - accuracy: 0.7986 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 931us/step - loss: 0.4294 - accuracy: 0.7986 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4294 - accuracy: 0.7986 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7986 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
      "Epoch 1251/1500\n",
      "18/18 [==============================] - 0s 895us/step - loss: 0.4293 - accuracy: 0.7986 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 978us/step - loss: 0.4293 - accuracy: 0.7986 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 918us/step - loss: 0.4293 - accuracy: 0.7986 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 921us/step - loss: 0.4293 - accuracy: 0.7986 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4293 - accuracy: 0.7986 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4292 - accuracy: 0.7986 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 958us/step - loss: 0.4292 - accuracy: 0.7986 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 922us/step - loss: 0.4291 - accuracy: 0.7986 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7986 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 879us/step - loss: 0.4292 - accuracy: 0.7986 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 906us/step - loss: 0.4292 - accuracy: 0.7986 - val_loss: 0.4965 - val_accuracy: 0.7656\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 937us/step - loss: 0.4291 - accuracy: 0.7986 - val_loss: 0.4965 - val_accuracy: 0.7656\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 920us/step - loss: 0.4291 - accuracy: 0.7986 - val_loss: 0.4965 - val_accuracy: 0.7656\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 925us/step - loss: 0.4290 - accuracy: 0.7986 - val_loss: 0.4965 - val_accuracy: 0.7656\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4290 - accuracy: 0.7986 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4290 - accuracy: 0.7986 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.7969 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 895us/step - loss: 0.4290 - accuracy: 0.7986 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.4290 - accuracy: 0.7986 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 909us/step - loss: 0.4289 - accuracy: 0.7986 - val_loss: 0.4967 - val_accuracy: 0.7656\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7986 - val_loss: 0.4967 - val_accuracy: 0.7656\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4289 - accuracy: 0.7986 - val_loss: 0.4967 - val_accuracy: 0.7656\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4289 - accuracy: 0.7986 - val_loss: 0.4967 - val_accuracy: 0.7656\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 982us/step - loss: 0.4289 - accuracy: 0.7986 - val_loss: 0.4968 - val_accuracy: 0.7656\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 879us/step - loss: 0.4288 - accuracy: 0.7986 - val_loss: 0.4968 - val_accuracy: 0.7656\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 954us/step - loss: 0.4288 - accuracy: 0.7986 - val_loss: 0.4968 - val_accuracy: 0.7656\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4288 - accuracy: 0.7986 - val_loss: 0.4968 - val_accuracy: 0.7656\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 870us/step - loss: 0.4288 - accuracy: 0.7986 - val_loss: 0.4969 - val_accuracy: 0.7656\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 863us/step - loss: 0.4288 - accuracy: 0.7986 - val_loss: 0.4969 - val_accuracy: 0.7656\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 918us/step - loss: 0.4287 - accuracy: 0.7986 - val_loss: 0.4969 - val_accuracy: 0.7656\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 895us/step - loss: 0.4287 - accuracy: 0.7986 - val_loss: 0.4969 - val_accuracy: 0.7656\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 954us/step - loss: 0.4287 - accuracy: 0.7986 - val_loss: 0.4969 - val_accuracy: 0.7656\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4287 - accuracy: 0.7986 - val_loss: 0.4970 - val_accuracy: 0.7656\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.7986 - val_loss: 0.4970 - val_accuracy: 0.7656\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4287 - accuracy: 0.7986 - val_loss: 0.4970 - val_accuracy: 0.7656\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7986 - val_loss: 0.4970 - val_accuracy: 0.7656\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4286 - accuracy: 0.7986 - val_loss: 0.4970 - val_accuracy: 0.7656\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 914us/step - loss: 0.4286 - accuracy: 0.7986 - val_loss: 0.4971 - val_accuracy: 0.7656\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 919us/step - loss: 0.4285 - accuracy: 0.7986 - val_loss: 0.4971 - val_accuracy: 0.7656\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 906us/step - loss: 0.4285 - accuracy: 0.7986 - val_loss: 0.4971 - val_accuracy: 0.7656\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 932us/step - loss: 0.4285 - accuracy: 0.7986 - val_loss: 0.4971 - val_accuracy: 0.7656\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 906us/step - loss: 0.4285 - accuracy: 0.7986 - val_loss: 0.4971 - val_accuracy: 0.7656\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 971us/step - loss: 0.4285 - accuracy: 0.7986 - val_loss: 0.4971 - val_accuracy: 0.7656\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 854us/step - loss: 0.4284 - accuracy: 0.7986 - val_loss: 0.4972 - val_accuracy: 0.7656\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7986 - val_loss: 0.4972 - val_accuracy: 0.7656\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4284 - accuracy: 0.7986 - val_loss: 0.4972 - val_accuracy: 0.7656\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7986 - val_loss: 0.4972 - val_accuracy: 0.7656\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 867us/step - loss: 0.4284 - accuracy: 0.7986 - val_loss: 0.4972 - val_accuracy: 0.7656\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 929us/step - loss: 0.4283 - accuracy: 0.7986 - val_loss: 0.4973 - val_accuracy: 0.7656\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4283 - accuracy: 0.7986 - val_loss: 0.4973 - val_accuracy: 0.7656\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 912us/step - loss: 0.4283 - accuracy: 0.7986 - val_loss: 0.4973 - val_accuracy: 0.7656\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 915us/step - loss: 0.4283 - accuracy: 0.7986 - val_loss: 0.4973 - val_accuracy: 0.7656\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 982us/step - loss: 0.4282 - accuracy: 0.7986 - val_loss: 0.4973 - val_accuracy: 0.7656\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 875us/step - loss: 0.4282 - accuracy: 0.7986 - val_loss: 0.4973 - val_accuracy: 0.7656\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 950us/step - loss: 0.4283 - accuracy: 0.7986 - val_loss: 0.4974 - val_accuracy: 0.7656\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4282 - accuracy: 0.7986 - val_loss: 0.4974 - val_accuracy: 0.7656\n",
      "Epoch 1307/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7969 - val_loss: 0.4974 - val_accuracy: 0.7656\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.7986 - val_loss: 0.4974 - val_accuracy: 0.7604\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4281 - accuracy: 0.7986 - val_loss: 0.4975 - val_accuracy: 0.7604\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 916us/step - loss: 0.4281 - accuracy: 0.7986 - val_loss: 0.4975 - val_accuracy: 0.7604\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 947us/step - loss: 0.4281 - accuracy: 0.7986 - val_loss: 0.4975 - val_accuracy: 0.7604\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.4281 - accuracy: 0.7986 - val_loss: 0.4975 - val_accuracy: 0.7604\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 928us/step - loss: 0.4282 - accuracy: 0.7986 - val_loss: 0.4975 - val_accuracy: 0.7604\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 895us/step - loss: 0.4280 - accuracy: 0.7986 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.7986 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 878us/step - loss: 0.4280 - accuracy: 0.7986 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7986 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 882us/step - loss: 0.4280 - accuracy: 0.7986 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4279 - accuracy: 0.7986 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 887us/step - loss: 0.4279 - accuracy: 0.7986 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 945us/step - loss: 0.4279 - accuracy: 0.7986 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 881us/step - loss: 0.4279 - accuracy: 0.7986 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 970us/step - loss: 0.4278 - accuracy: 0.7986 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4278 - accuracy: 0.7986 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.7986 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7986 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 934us/step - loss: 0.4277 - accuracy: 0.7969 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 903us/step - loss: 0.4277 - accuracy: 0.7986 - val_loss: 0.4978 - val_accuracy: 0.7604\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 955us/step - loss: 0.4277 - accuracy: 0.7986 - val_loss: 0.4978 - val_accuracy: 0.7604\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4277 - accuracy: 0.7986 - val_loss: 0.4978 - val_accuracy: 0.7604\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.4277 - accuracy: 0.7986 - val_loss: 0.4978 - val_accuracy: 0.7604\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4277 - accuracy: 0.7969 - val_loss: 0.4978 - val_accuracy: 0.7604\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 951us/step - loss: 0.4277 - accuracy: 0.7986 - val_loss: 0.4978 - val_accuracy: 0.7604\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4276 - accuracy: 0.7986 - val_loss: 0.4978 - val_accuracy: 0.7604\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7986 - val_loss: 0.4978 - val_accuracy: 0.7604\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 906us/step - loss: 0.4276 - accuracy: 0.7986 - val_loss: 0.4978 - val_accuracy: 0.7604\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 909us/step - loss: 0.4276 - accuracy: 0.7986 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 915us/step - loss: 0.4276 - accuracy: 0.7986 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 872us/step - loss: 0.4275 - accuracy: 0.7986 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 943us/step - loss: 0.4275 - accuracy: 0.7969 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4275 - accuracy: 0.7986 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.7986 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 877us/step - loss: 0.4275 - accuracy: 0.7969 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7986 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 881us/step - loss: 0.4274 - accuracy: 0.7986 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 984us/step - loss: 0.4274 - accuracy: 0.7969 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 904us/step - loss: 0.4273 - accuracy: 0.7969 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 958us/step - loss: 0.4274 - accuracy: 0.7986 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4273 - accuracy: 0.7986 - val_loss: 0.4981 - val_accuracy: 0.7604\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 924us/step - loss: 0.4274 - accuracy: 0.7951 - val_loss: 0.4981 - val_accuracy: 0.7604\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 912us/step - loss: 0.4273 - accuracy: 0.7969 - val_loss: 0.4981 - val_accuracy: 0.7604\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 938us/step - loss: 0.4273 - accuracy: 0.7969 - val_loss: 0.4981 - val_accuracy: 0.7604\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4272 - accuracy: 0.7986 - val_loss: 0.4981 - val_accuracy: 0.7604\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.7969 - val_loss: 0.4981 - val_accuracy: 0.7604\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 922us/step - loss: 0.4272 - accuracy: 0.7969 - val_loss: 0.4981 - val_accuracy: 0.7604\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 938us/step - loss: 0.4272 - accuracy: 0.7986 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4272 - accuracy: 0.7969 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7986 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.7986 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 874us/step - loss: 0.4271 - accuracy: 0.7969 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 880us/step - loss: 0.4271 - accuracy: 0.7986 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 947us/step - loss: 0.4271 - accuracy: 0.7986 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
      "Epoch 1363/1500\n",
      "18/18 [==============================] - 0s 901us/step - loss: 0.4270 - accuracy: 0.7986 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.7969 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4270 - accuracy: 0.7969 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 947us/step - loss: 0.4270 - accuracy: 0.7986 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4270 - accuracy: 0.7986 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4269 - accuracy: 0.7969 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7986 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 859us/step - loss: 0.4269 - accuracy: 0.7986 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.4269 - accuracy: 0.7969 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 916us/step - loss: 0.4269 - accuracy: 0.7986 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.7986 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 904us/step - loss: 0.4268 - accuracy: 0.7986 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 894us/step - loss: 0.4268 - accuracy: 0.7986 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.4268 - accuracy: 0.7986 - val_loss: 0.4983 - val_accuracy: 0.7604\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4268 - accuracy: 0.7986 - val_loss: 0.4983 - val_accuracy: 0.7604\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 928us/step - loss: 0.4267 - accuracy: 0.7986 - val_loss: 0.4983 - val_accuracy: 0.7604\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 923us/step - loss: 0.4267 - accuracy: 0.7986 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 890us/step - loss: 0.4267 - accuracy: 0.7986 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.4267 - accuracy: 0.7986 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 953us/step - loss: 0.4267 - accuracy: 0.7986 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 883us/step - loss: 0.4267 - accuracy: 0.7969 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7986 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4267 - accuracy: 0.7986 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 872us/step - loss: 0.4266 - accuracy: 0.7986 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 914us/step - loss: 0.4266 - accuracy: 0.7986 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 906us/step - loss: 0.4266 - accuracy: 0.7986 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 912us/step - loss: 0.4266 - accuracy: 0.7986 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 900us/step - loss: 0.4265 - accuracy: 0.7986 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 909us/step - loss: 0.4265 - accuracy: 0.7986 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4265 - accuracy: 0.7986 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7986 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4265 - accuracy: 0.7986 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4264 - accuracy: 0.7986 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 933us/step - loss: 0.4264 - accuracy: 0.7986 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 893us/step - loss: 0.4264 - accuracy: 0.7986 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 926us/step - loss: 0.4263 - accuracy: 0.7986 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7986 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 976us/step - loss: 0.4264 - accuracy: 0.7986 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 954us/step - loss: 0.4263 - accuracy: 0.7986 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4263 - accuracy: 0.7986 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 917us/step - loss: 0.4262 - accuracy: 0.7986 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 895us/step - loss: 0.4263 - accuracy: 0.7986 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 935us/step - loss: 0.4262 - accuracy: 0.7986 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 865us/step - loss: 0.4262 - accuracy: 0.7986 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7986 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4261 - accuracy: 0.7986 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 913us/step - loss: 0.4262 - accuracy: 0.8003 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 938us/step - loss: 0.4261 - accuracy: 0.8003 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 906us/step - loss: 0.4261 - accuracy: 0.7986 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4261 - accuracy: 0.7986 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 914us/step - loss: 0.4261 - accuracy: 0.7986 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 944us/step - loss: 0.4260 - accuracy: 0.7986 - val_loss: 0.4986 - val_accuracy: 0.7552\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4260 - accuracy: 0.7986 - val_loss: 0.4986 - val_accuracy: 0.7552\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8003 - val_loss: 0.4986 - val_accuracy: 0.7500\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8003 - val_loss: 0.4986 - val_accuracy: 0.7500\n",
      "Epoch 1418/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4260 - accuracy: 0.8003 - val_loss: 0.4986 - val_accuracy: 0.7552\n",
      "Epoch 1419/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4260 - accuracy: 0.7986 - val_loss: 0.4986 - val_accuracy: 0.7500\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4259 - accuracy: 0.8003 - val_loss: 0.4987 - val_accuracy: 0.7500\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 997us/step - loss: 0.4259 - accuracy: 0.8038 - val_loss: 0.4987 - val_accuracy: 0.7500\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8021 - val_loss: 0.4987 - val_accuracy: 0.7500\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 973us/step - loss: 0.4259 - accuracy: 0.8021 - val_loss: 0.4987 - val_accuracy: 0.7500\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4258 - accuracy: 0.8003 - val_loss: 0.4987 - val_accuracy: 0.7500\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 949us/step - loss: 0.4258 - accuracy: 0.8038 - val_loss: 0.4987 - val_accuracy: 0.7500\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 962us/step - loss: 0.4257 - accuracy: 0.8021 - val_loss: 0.4988 - val_accuracy: 0.7500\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 949us/step - loss: 0.4258 - accuracy: 0.8038 - val_loss: 0.4988 - val_accuracy: 0.7500\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 960us/step - loss: 0.4258 - accuracy: 0.8021 - val_loss: 0.4988 - val_accuracy: 0.7500\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4258 - accuracy: 0.8038 - val_loss: 0.4988 - val_accuracy: 0.7500\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 961us/step - loss: 0.4257 - accuracy: 0.8038 - val_loss: 0.4988 - val_accuracy: 0.7500\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.8038 - val_loss: 0.4988 - val_accuracy: 0.7500\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 872us/step - loss: 0.4256 - accuracy: 0.8038 - val_loss: 0.4989 - val_accuracy: 0.7500\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 973us/step - loss: 0.4257 - accuracy: 0.8038 - val_loss: 0.4989 - val_accuracy: 0.7500\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 899us/step - loss: 0.4256 - accuracy: 0.8038 - val_loss: 0.4989 - val_accuracy: 0.7500\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 935us/step - loss: 0.4256 - accuracy: 0.8038 - val_loss: 0.4989 - val_accuracy: 0.7500\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 873us/step - loss: 0.4256 - accuracy: 0.8021 - val_loss: 0.4989 - val_accuracy: 0.7500\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 927us/step - loss: 0.4256 - accuracy: 0.8021 - val_loss: 0.4990 - val_accuracy: 0.7500\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 918us/step - loss: 0.4255 - accuracy: 0.8038 - val_loss: 0.4990 - val_accuracy: 0.7500\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 977us/step - loss: 0.4256 - accuracy: 0.8021 - val_loss: 0.4990 - val_accuracy: 0.7500\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.4255 - accuracy: 0.8038 - val_loss: 0.4990 - val_accuracy: 0.7500\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4255 - accuracy: 0.8038 - val_loss: 0.4991 - val_accuracy: 0.7500\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 892us/step - loss: 0.4255 - accuracy: 0.8038 - val_loss: 0.4991 - val_accuracy: 0.7500\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4255 - accuracy: 0.8021 - val_loss: 0.4991 - val_accuracy: 0.7500\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4255 - accuracy: 0.8038 - val_loss: 0.4991 - val_accuracy: 0.7500\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 906us/step - loss: 0.4254 - accuracy: 0.8038 - val_loss: 0.4991 - val_accuracy: 0.7500\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 920us/step - loss: 0.4254 - accuracy: 0.8038 - val_loss: 0.4991 - val_accuracy: 0.7500\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 928us/step - loss: 0.4254 - accuracy: 0.8021 - val_loss: 0.4992 - val_accuracy: 0.7500\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 973us/step - loss: 0.4253 - accuracy: 0.8038 - val_loss: 0.4992 - val_accuracy: 0.7500\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4253 - accuracy: 0.8038 - val_loss: 0.4992 - val_accuracy: 0.7500\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 878us/step - loss: 0.4254 - accuracy: 0.8038 - val_loss: 0.4992 - val_accuracy: 0.7500\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 905us/step - loss: 0.4253 - accuracy: 0.8021 - val_loss: 0.4992 - val_accuracy: 0.7500\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 916us/step - loss: 0.4253 - accuracy: 0.8021 - val_loss: 0.4993 - val_accuracy: 0.7500\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4253 - accuracy: 0.8021 - val_loss: 0.4993 - val_accuracy: 0.7500\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8038 - val_loss: 0.4993 - val_accuracy: 0.7500\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 888us/step - loss: 0.4253 - accuracy: 0.8038 - val_loss: 0.4993 - val_accuracy: 0.7500\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4252 - accuracy: 0.8038 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4252 - accuracy: 0.8038 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4252 - accuracy: 0.8038 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 911us/step - loss: 0.4252 - accuracy: 0.8038 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 972us/step - loss: 0.4251 - accuracy: 0.8038 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 885us/step - loss: 0.4251 - accuracy: 0.8021 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 919us/step - loss: 0.4251 - accuracy: 0.8038 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 891us/step - loss: 0.4251 - accuracy: 0.8021 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 905us/step - loss: 0.4251 - accuracy: 0.8038 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 887us/step - loss: 0.4251 - accuracy: 0.8038 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 912us/step - loss: 0.4251 - accuracy: 0.8038 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8038 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4250 - accuracy: 0.8038 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8038 - val_loss: 0.4996 - val_accuracy: 0.7500\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 884us/step - loss: 0.4250 - accuracy: 0.8038 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 940us/step - loss: 0.4250 - accuracy: 0.8021 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 881us/step - loss: 0.4249 - accuracy: 0.8021 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 959us/step - loss: 0.4249 - accuracy: 0.8021 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 1474/1500\n",
      "18/18 [==============================] - 0s 919us/step - loss: 0.4249 - accuracy: 0.8038 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 1475/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8021 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4248 - accuracy: 0.8038 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 898us/step - loss: 0.4248 - accuracy: 0.8021 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 969us/step - loss: 0.4248 - accuracy: 0.8038 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 879us/step - loss: 0.4248 - accuracy: 0.8038 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 973us/step - loss: 0.4248 - accuracy: 0.8021 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 889us/step - loss: 0.4247 - accuracy: 0.8021 - val_loss: 0.4999 - val_accuracy: 0.7500\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8038 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4247 - accuracy: 0.8038 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 896us/step - loss: 0.4247 - accuracy: 0.8038 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 939us/step - loss: 0.4247 - accuracy: 0.8038 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 907us/step - loss: 0.4246 - accuracy: 0.8021 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 951us/step - loss: 0.4246 - accuracy: 0.8021 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 919us/step - loss: 0.4246 - accuracy: 0.8038 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 918us/step - loss: 0.4246 - accuracy: 0.8038 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8038 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 910us/step - loss: 0.4245 - accuracy: 0.8038 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4246 - accuracy: 0.8038 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4245 - accuracy: 0.8038 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 886us/step - loss: 0.4245 - accuracy: 0.8021 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 928us/step - loss: 0.4245 - accuracy: 0.8038 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 875us/step - loss: 0.4245 - accuracy: 0.8038 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4244 - accuracy: 0.8038 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8021 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 872us/step - loss: 0.4244 - accuracy: 0.8038 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 936us/step - loss: 0.4244 - accuracy: 0.8038 - val_loss: 0.5003 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "# learning rate fix to 0.003\n",
    "# 1500 epochs (iterations)\n",
    "\n",
    "model_2.compile(\n",
    "    optimizer=SGD(learning_rate=0.003),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "run_hist_2 = model_2.fit(\n",
    "    X_train_norm,\n",
    "    y_train,\n",
    "    validation_data=(X_test_norm, y_test),\n",
    "    epochs=1500,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 673us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "y_pred_class_nn_2 = (y_pred_prob_nn_2 >= 0.5).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Loss: 0.4244\n",
      "Final Validation Loss: 0.5003\n",
      "Final Training Accuracy: 0.8038\n",
      "Final Validation Accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "final_train_loss = run_hist_2.history[\"loss\"][-1]\n",
    "final_val_loss = run_hist_2.history[\"val_loss\"][-1]\n",
    "final_train_accuracy = run_hist_2.history[\"accuracy\"][-1]\n",
    "final_val_accuracy = run_hist_2.history[\"val_accuracy\"][-1]\n",
    "\n",
    "print(f\"Final Training Loss: {final_train_loss:.4f}\")\n",
    "print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
    "print(f\"Final Training Accuracy: {final_train_accuracy:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {final_val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss\n",
    "fig2, (bx1, bx2) = plt.subplots(nrows=2, ncols=1, figsize=(16, 12))\n",
    "bx1.plot(run_hist_2.history[\"loss\"], 'teal', linestyle='-', label=\"Train Loss\")\n",
    "bx1.plot(run_hist_2.history[\"val_loss\"], 'orange', linestyle='-', linewidth=3, label=\"Validation Loss\")\n",
    "bx1.legend()\n",
    "bx1.set_xlabel(\"Epoch\")\n",
    "bx1.set_ylabel(\"Loss\")\n",
    "bx1.set_title(\"Training and Validation Loss\")\n",
    "\n",
    "# Plot accuracy\n",
    "bx2.plot(run_hist_2.history[\"accuracy\"], 'teal', linestyle='-', label=\"Train Accuracy\")\n",
    "bx2.plot(run_hist_2.history[\"val_accuracy\"], 'orange', linestyle='-', linewidth=3, label=\"Validation Accuracy\")\n",
    "bx2.legend()\n",
    "bx2.set_xlabel(\"Epoch\")\n",
    "bx2.set_ylabel(\"Accuracy\")\n",
    "bx2.set_title(\"Training and Validation Accuracy\")\n",
    "\n",
    "# Adjust layout to prevent clipping\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (50 คะแนน) เพิ่มอีกเซลโค้ด เพื่อสร้างโมเดลที่มีการปรับโครงสร้างที่เหมาะสมขึ้น รวมถึงการปรับค่า Hyperparameter ต่าง ๆ เพื่อให้โมเดลใหม่ได้ผลลัพธ์ที่ดีขึ้น (โดยพิจารณาจากค่า accuracy) และในการเทรนโมเดลใหม่นี้ ห้ามมีการใช้ Early Stopping \n",
    "   * ให้วาดกราฟของค่า loss และ accuracy ของโมเดลใหม่นี้ด้วย\n",
    "   * อธิบายให้เห็นว่าผลลัพธ์ที่ได้จากโมเดลใหม่นั้นดีขึ้นจากโมเดลเดิม\n",
    "\n",
    "   Notes :\n",
    "   - ปรับค่า Hyperparameter ต่าง ๆ\n",
    "   - ห้ามการ Early Stopping \n",
    "   - พิจารณาจากค่า accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.7183 - accuracy: 0.3993 - val_loss: 0.7100 - val_accuracy: 0.4323\n",
      "Epoch 2/1000\n",
      "36/36 [==============================] - 0s 681us/step - loss: 0.7139 - accuracy: 0.4115 - val_loss: 0.7062 - val_accuracy: 0.4479\n",
      "Epoch 3/1000\n",
      "36/36 [==============================] - 0s 714us/step - loss: 0.7099 - accuracy: 0.4271 - val_loss: 0.7029 - val_accuracy: 0.4844\n",
      "Epoch 4/1000\n",
      "36/36 [==============================] - 0s 700us/step - loss: 0.7062 - accuracy: 0.4340 - val_loss: 0.6998 - val_accuracy: 0.4583\n",
      "Epoch 5/1000\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.7029 - accuracy: 0.4531 - val_loss: 0.6969 - val_accuracy: 0.4531\n",
      "Epoch 6/1000\n",
      "36/36 [==============================] - 0s 648us/step - loss: 0.6998 - accuracy: 0.4653 - val_loss: 0.6943 - val_accuracy: 0.4792\n",
      "Epoch 7/1000\n",
      "36/36 [==============================] - 0s 704us/step - loss: 0.6969 - accuracy: 0.4792 - val_loss: 0.6917 - val_accuracy: 0.5000\n",
      "Epoch 8/1000\n",
      "36/36 [==============================] - 0s 682us/step - loss: 0.6942 - accuracy: 0.4983 - val_loss: 0.6893 - val_accuracy: 0.5156\n",
      "Epoch 9/1000\n",
      "36/36 [==============================] - 0s 665us/step - loss: 0.6915 - accuracy: 0.5208 - val_loss: 0.6870 - val_accuracy: 0.5469\n",
      "Epoch 10/1000\n",
      "36/36 [==============================] - 0s 648us/step - loss: 0.6891 - accuracy: 0.5365 - val_loss: 0.6849 - val_accuracy: 0.5625\n",
      "Epoch 11/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.6867 - accuracy: 0.5399 - val_loss: 0.6829 - val_accuracy: 0.5781\n",
      "Epoch 12/1000\n",
      "36/36 [==============================] - 0s 630us/step - loss: 0.6845 - accuracy: 0.5677 - val_loss: 0.6810 - val_accuracy: 0.5990\n",
      "Epoch 13/1000\n",
      "36/36 [==============================] - 0s 637us/step - loss: 0.6824 - accuracy: 0.5868 - val_loss: 0.6793 - val_accuracy: 0.6146\n",
      "Epoch 14/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.6804 - accuracy: 0.6076 - val_loss: 0.6777 - val_accuracy: 0.6250\n",
      "Epoch 15/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.6785 - accuracy: 0.6215 - val_loss: 0.6760 - val_accuracy: 0.6354\n",
      "Epoch 16/1000\n",
      "36/36 [==============================] - 0s 677us/step - loss: 0.6766 - accuracy: 0.6389 - val_loss: 0.6744 - val_accuracy: 0.6510\n",
      "Epoch 17/1000\n",
      "36/36 [==============================] - 0s 683us/step - loss: 0.6748 - accuracy: 0.6372 - val_loss: 0.6730 - val_accuracy: 0.6458\n",
      "Epoch 18/1000\n",
      "36/36 [==============================] - 0s 693us/step - loss: 0.6732 - accuracy: 0.6424 - val_loss: 0.6717 - val_accuracy: 0.6458\n",
      "Epoch 19/1000\n",
      "36/36 [==============================] - 0s 656us/step - loss: 0.6716 - accuracy: 0.6493 - val_loss: 0.6705 - val_accuracy: 0.6458\n",
      "Epoch 20/1000\n",
      "36/36 [==============================] - 0s 629us/step - loss: 0.6702 - accuracy: 0.6458 - val_loss: 0.6693 - val_accuracy: 0.6458\n",
      "Epoch 21/1000\n",
      "36/36 [==============================] - 0s 628us/step - loss: 0.6688 - accuracy: 0.6458 - val_loss: 0.6682 - val_accuracy: 0.6562\n",
      "Epoch 22/1000\n",
      "36/36 [==============================] - 0s 630us/step - loss: 0.6675 - accuracy: 0.6441 - val_loss: 0.6672 - val_accuracy: 0.6562\n",
      "Epoch 23/1000\n",
      "36/36 [==============================] - 0s 616us/step - loss: 0.6662 - accuracy: 0.6424 - val_loss: 0.6662 - val_accuracy: 0.6562\n",
      "Epoch 24/1000\n",
      "36/36 [==============================] - 0s 629us/step - loss: 0.6650 - accuracy: 0.6441 - val_loss: 0.6652 - val_accuracy: 0.6562\n",
      "Epoch 25/1000\n",
      "36/36 [==============================] - 0s 626us/step - loss: 0.6638 - accuracy: 0.6458 - val_loss: 0.6643 - val_accuracy: 0.6510\n",
      "Epoch 26/1000\n",
      "36/36 [==============================] - 0s 624us/step - loss: 0.6627 - accuracy: 0.6493 - val_loss: 0.6634 - val_accuracy: 0.6458\n",
      "Epoch 27/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6617 - accuracy: 0.6476 - val_loss: 0.6626 - val_accuracy: 0.6562\n",
      "Epoch 28/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.6606 - accuracy: 0.6476 - val_loss: 0.6618 - val_accuracy: 0.6562\n",
      "Epoch 29/1000\n",
      "36/36 [==============================] - 0s 620us/step - loss: 0.6597 - accuracy: 0.6476 - val_loss: 0.6610 - val_accuracy: 0.6562\n",
      "Epoch 30/1000\n",
      "36/36 [==============================] - 0s 635us/step - loss: 0.6587 - accuracy: 0.6476 - val_loss: 0.6603 - val_accuracy: 0.6562\n",
      "Epoch 31/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.6577 - accuracy: 0.6510 - val_loss: 0.6595 - val_accuracy: 0.6562\n",
      "Epoch 32/1000\n",
      "36/36 [==============================] - 0s 684us/step - loss: 0.6568 - accuracy: 0.6510 - val_loss: 0.6588 - val_accuracy: 0.6562\n",
      "Epoch 33/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.6559 - accuracy: 0.6545 - val_loss: 0.6581 - val_accuracy: 0.6562\n",
      "Epoch 34/1000\n",
      "36/36 [==============================] - 0s 675us/step - loss: 0.6551 - accuracy: 0.6510 - val_loss: 0.6575 - val_accuracy: 0.6562\n",
      "Epoch 35/1000\n",
      "36/36 [==============================] - 0s 662us/step - loss: 0.6542 - accuracy: 0.6528 - val_loss: 0.6568 - val_accuracy: 0.6562\n",
      "Epoch 36/1000\n",
      "36/36 [==============================] - 0s 677us/step - loss: 0.6534 - accuracy: 0.6510 - val_loss: 0.6562 - val_accuracy: 0.6562\n",
      "Epoch 37/1000\n",
      "36/36 [==============================] - 0s 655us/step - loss: 0.6526 - accuracy: 0.6510 - val_loss: 0.6556 - val_accuracy: 0.6562\n",
      "Epoch 38/1000\n",
      "36/36 [==============================] - 0s 698us/step - loss: 0.6518 - accuracy: 0.6510 - val_loss: 0.6550 - val_accuracy: 0.6562\n",
      "Epoch 39/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.6511 - accuracy: 0.6545 - val_loss: 0.6545 - val_accuracy: 0.6562\n",
      "Epoch 40/1000\n",
      "36/36 [==============================] - 0s 670us/step - loss: 0.6503 - accuracy: 0.6545 - val_loss: 0.6539 - val_accuracy: 0.6562\n",
      "Epoch 41/1000\n",
      "36/36 [==============================] - 0s 628us/step - loss: 0.6496 - accuracy: 0.6545 - val_loss: 0.6534 - val_accuracy: 0.6562\n",
      "Epoch 42/1000\n",
      "36/36 [==============================] - 0s 637us/step - loss: 0.6489 - accuracy: 0.6545 - val_loss: 0.6529 - val_accuracy: 0.6562\n",
      "Epoch 43/1000\n",
      "36/36 [==============================] - 0s 622us/step - loss: 0.6483 - accuracy: 0.6528 - val_loss: 0.6525 - val_accuracy: 0.6562\n",
      "Epoch 44/1000\n",
      "36/36 [==============================] - 0s 612us/step - loss: 0.6476 - accuracy: 0.6528 - val_loss: 0.6521 - val_accuracy: 0.6562\n",
      "Epoch 45/1000\n",
      "36/36 [==============================] - 0s 609us/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6516 - val_accuracy: 0.6562\n",
      "Epoch 46/1000\n",
      "36/36 [==============================] - 0s 604us/step - loss: 0.6464 - accuracy: 0.6510 - val_loss: 0.6512 - val_accuracy: 0.6562\n",
      "Epoch 47/1000\n",
      "36/36 [==============================] - 0s 618us/step - loss: 0.6458 - accuracy: 0.6510 - val_loss: 0.6508 - val_accuracy: 0.6562\n",
      "Epoch 48/1000\n",
      "36/36 [==============================] - 0s 620us/step - loss: 0.6452 - accuracy: 0.6510 - val_loss: 0.6505 - val_accuracy: 0.6562\n",
      "Epoch 49/1000\n",
      "36/36 [==============================] - 0s 629us/step - loss: 0.6446 - accuracy: 0.6510 - val_loss: 0.6501 - val_accuracy: 0.6562\n",
      "Epoch 50/1000\n",
      "36/36 [==============================] - 0s 613us/step - loss: 0.6441 - accuracy: 0.6510 - val_loss: 0.6497 - val_accuracy: 0.6562\n",
      "Epoch 51/1000\n",
      "36/36 [==============================] - 0s 602us/step - loss: 0.6436 - accuracy: 0.6510 - val_loss: 0.6493 - val_accuracy: 0.6562\n",
      "Epoch 52/1000\n",
      "36/36 [==============================] - 0s 617us/step - loss: 0.6430 - accuracy: 0.6510 - val_loss: 0.6490 - val_accuracy: 0.6562\n",
      "Epoch 53/1000\n",
      "36/36 [==============================] - 0s 606us/step - loss: 0.6425 - accuracy: 0.6510 - val_loss: 0.6486 - val_accuracy: 0.6562\n",
      "Epoch 54/1000\n",
      "36/36 [==============================] - 0s 612us/step - loss: 0.6420 - accuracy: 0.6510 - val_loss: 0.6483 - val_accuracy: 0.6510\n",
      "Epoch 55/1000\n",
      "36/36 [==============================] - 0s 612us/step - loss: 0.6415 - accuracy: 0.6510 - val_loss: 0.6479 - val_accuracy: 0.6510\n",
      "Epoch 56/1000\n",
      "36/36 [==============================] - 0s 617us/step - loss: 0.6409 - accuracy: 0.6510 - val_loss: 0.6476 - val_accuracy: 0.6510\n",
      "Epoch 57/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.6405 - accuracy: 0.6510 - val_loss: 0.6473 - val_accuracy: 0.6510\n",
      "Epoch 58/1000\n",
      "36/36 [==============================] - 0s 779us/step - loss: 0.6400 - accuracy: 0.6510 - val_loss: 0.6469 - val_accuracy: 0.6510\n",
      "Epoch 59/1000\n",
      "36/36 [==============================] - 0s 792us/step - loss: 0.6395 - accuracy: 0.6510 - val_loss: 0.6466 - val_accuracy: 0.6510\n",
      "Epoch 60/1000\n",
      "36/36 [==============================] - 0s 689us/step - loss: 0.6390 - accuracy: 0.6510 - val_loss: 0.6463 - val_accuracy: 0.6510\n",
      "Epoch 61/1000\n",
      "36/36 [==============================] - 0s 708us/step - loss: 0.6385 - accuracy: 0.6510 - val_loss: 0.6460 - val_accuracy: 0.6510\n",
      "Epoch 62/1000\n",
      "36/36 [==============================] - 0s 721us/step - loss: 0.6381 - accuracy: 0.6510 - val_loss: 0.6457 - val_accuracy: 0.6510\n",
      "Epoch 63/1000\n",
      "36/36 [==============================] - 0s 658us/step - loss: 0.6376 - accuracy: 0.6510 - val_loss: 0.6454 - val_accuracy: 0.6510\n",
      "Epoch 64/1000\n",
      "36/36 [==============================] - 0s 692us/step - loss: 0.6372 - accuracy: 0.6510 - val_loss: 0.6451 - val_accuracy: 0.6510\n",
      "Epoch 65/1000\n",
      "36/36 [==============================] - 0s 666us/step - loss: 0.6367 - accuracy: 0.6510 - val_loss: 0.6449 - val_accuracy: 0.6510\n",
      "Epoch 66/1000\n",
      "36/36 [==============================] - 0s 709us/step - loss: 0.6363 - accuracy: 0.6510 - val_loss: 0.6446 - val_accuracy: 0.6510\n",
      "Epoch 67/1000\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.6359 - accuracy: 0.6510 - val_loss: 0.6443 - val_accuracy: 0.6510\n",
      "Epoch 68/1000\n",
      "36/36 [==============================] - 0s 662us/step - loss: 0.6355 - accuracy: 0.6510 - val_loss: 0.6440 - val_accuracy: 0.6510\n",
      "Epoch 69/1000\n",
      "36/36 [==============================] - 0s 634us/step - loss: 0.6351 - accuracy: 0.6510 - val_loss: 0.6437 - val_accuracy: 0.6510\n",
      "Epoch 70/1000\n",
      "36/36 [==============================] - 0s 664us/step - loss: 0.6347 - accuracy: 0.6510 - val_loss: 0.6435 - val_accuracy: 0.6510\n",
      "Epoch 71/1000\n",
      "36/36 [==============================] - 0s 638us/step - loss: 0.6342 - accuracy: 0.6510 - val_loss: 0.6432 - val_accuracy: 0.6510\n",
      "Epoch 72/1000\n",
      "36/36 [==============================] - 0s 649us/step - loss: 0.6338 - accuracy: 0.6510 - val_loss: 0.6429 - val_accuracy: 0.6510\n",
      "Epoch 73/1000\n",
      "36/36 [==============================] - 0s 634us/step - loss: 0.6334 - accuracy: 0.6510 - val_loss: 0.6427 - val_accuracy: 0.6510\n",
      "Epoch 74/1000\n",
      "36/36 [==============================] - 0s 646us/step - loss: 0.6330 - accuracy: 0.6510 - val_loss: 0.6424 - val_accuracy: 0.6510\n",
      "Epoch 75/1000\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.6326 - accuracy: 0.6510 - val_loss: 0.6421 - val_accuracy: 0.6510\n",
      "Epoch 76/1000\n",
      "36/36 [==============================] - 0s 633us/step - loss: 0.6323 - accuracy: 0.6510 - val_loss: 0.6419 - val_accuracy: 0.6510\n",
      "Epoch 77/1000\n",
      "36/36 [==============================] - 0s 634us/step - loss: 0.6319 - accuracy: 0.6510 - val_loss: 0.6416 - val_accuracy: 0.6510\n",
      "Epoch 78/1000\n",
      "36/36 [==============================] - 0s 632us/step - loss: 0.6315 - accuracy: 0.6510 - val_loss: 0.6413 - val_accuracy: 0.6510\n",
      "Epoch 79/1000\n",
      "36/36 [==============================] - 0s 658us/step - loss: 0.6311 - accuracy: 0.6510 - val_loss: 0.6411 - val_accuracy: 0.6510\n",
      "Epoch 80/1000\n",
      "36/36 [==============================] - 0s 623us/step - loss: 0.6307 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6510\n",
      "Epoch 81/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.6303 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6510\n",
      "Epoch 82/1000\n",
      "36/36 [==============================] - 0s 630us/step - loss: 0.6299 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6510\n",
      "Epoch 83/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.6296 - accuracy: 0.6510 - val_loss: 0.6400 - val_accuracy: 0.6510\n",
      "Epoch 84/1000\n",
      "36/36 [==============================] - 0s 632us/step - loss: 0.6292 - accuracy: 0.6510 - val_loss: 0.6398 - val_accuracy: 0.6510\n",
      "Epoch 85/1000\n",
      "36/36 [==============================] - 0s 619us/step - loss: 0.6288 - accuracy: 0.6510 - val_loss: 0.6395 - val_accuracy: 0.6510\n",
      "Epoch 86/1000\n",
      "36/36 [==============================] - 0s 639us/step - loss: 0.6284 - accuracy: 0.6510 - val_loss: 0.6392 - val_accuracy: 0.6510\n",
      "Epoch 87/1000\n",
      "36/36 [==============================] - 0s 629us/step - loss: 0.6280 - accuracy: 0.6510 - val_loss: 0.6390 - val_accuracy: 0.6510\n",
      "Epoch 88/1000\n",
      "36/36 [==============================] - 0s 646us/step - loss: 0.6277 - accuracy: 0.6510 - val_loss: 0.6387 - val_accuracy: 0.6510\n",
      "Epoch 89/1000\n",
      "36/36 [==============================] - 0s 633us/step - loss: 0.6273 - accuracy: 0.6510 - val_loss: 0.6385 - val_accuracy: 0.6510\n",
      "Epoch 90/1000\n",
      "36/36 [==============================] - 0s 624us/step - loss: 0.6269 - accuracy: 0.6510 - val_loss: 0.6382 - val_accuracy: 0.6510\n",
      "Epoch 91/1000\n",
      "36/36 [==============================] - 0s 644us/step - loss: 0.6265 - accuracy: 0.6510 - val_loss: 0.6380 - val_accuracy: 0.6510\n",
      "Epoch 92/1000\n",
      "36/36 [==============================] - 0s 628us/step - loss: 0.6261 - accuracy: 0.6510 - val_loss: 0.6377 - val_accuracy: 0.6510\n",
      "Epoch 93/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.6258 - accuracy: 0.6510 - val_loss: 0.6374 - val_accuracy: 0.6510\n",
      "Epoch 94/1000\n",
      "36/36 [==============================] - 0s 621us/step - loss: 0.6254 - accuracy: 0.6510 - val_loss: 0.6371 - val_accuracy: 0.6510\n",
      "Epoch 95/1000\n",
      "36/36 [==============================] - 0s 637us/step - loss: 0.6250 - accuracy: 0.6510 - val_loss: 0.6369 - val_accuracy: 0.6510\n",
      "Epoch 96/1000\n",
      "36/36 [==============================] - 0s 634us/step - loss: 0.6246 - accuracy: 0.6510 - val_loss: 0.6366 - val_accuracy: 0.6510\n",
      "Epoch 97/1000\n",
      "36/36 [==============================] - 0s 632us/step - loss: 0.6242 - accuracy: 0.6510 - val_loss: 0.6363 - val_accuracy: 0.6510\n",
      "Epoch 98/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.6238 - accuracy: 0.6510 - val_loss: 0.6360 - val_accuracy: 0.6510\n",
      "Epoch 99/1000\n",
      "36/36 [==============================] - 0s 627us/step - loss: 0.6234 - accuracy: 0.6510 - val_loss: 0.6357 - val_accuracy: 0.6510\n",
      "Epoch 100/1000\n",
      "36/36 [==============================] - 0s 639us/step - loss: 0.6231 - accuracy: 0.6510 - val_loss: 0.6355 - val_accuracy: 0.6510\n",
      "Epoch 101/1000\n",
      "36/36 [==============================] - 0s 623us/step - loss: 0.6227 - accuracy: 0.6510 - val_loss: 0.6352 - val_accuracy: 0.6510\n",
      "Epoch 102/1000\n",
      "36/36 [==============================] - 0s 667us/step - loss: 0.6223 - accuracy: 0.6510 - val_loss: 0.6349 - val_accuracy: 0.6510\n",
      "Epoch 103/1000\n",
      "36/36 [==============================] - 0s 713us/step - loss: 0.6219 - accuracy: 0.6510 - val_loss: 0.6346 - val_accuracy: 0.6510\n",
      "Epoch 104/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6215 - accuracy: 0.6510 - val_loss: 0.6343 - val_accuracy: 0.6510\n",
      "Epoch 105/1000\n",
      "36/36 [==============================] - 0s 844us/step - loss: 0.6211 - accuracy: 0.6510 - val_loss: 0.6340 - val_accuracy: 0.6510\n",
      "Epoch 106/1000\n",
      "36/36 [==============================] - 0s 626us/step - loss: 0.6208 - accuracy: 0.6510 - val_loss: 0.6337 - val_accuracy: 0.6510\n",
      "Epoch 107/1000\n",
      "36/36 [==============================] - 0s 607us/step - loss: 0.6203 - accuracy: 0.6510 - val_loss: 0.6334 - val_accuracy: 0.6510\n",
      "Epoch 108/1000\n",
      "36/36 [==============================] - 0s 605us/step - loss: 0.6200 - accuracy: 0.6510 - val_loss: 0.6331 - val_accuracy: 0.6510\n",
      "Epoch 109/1000\n",
      "36/36 [==============================] - 0s 631us/step - loss: 0.6196 - accuracy: 0.6510 - val_loss: 0.6328 - val_accuracy: 0.6510\n",
      "Epoch 110/1000\n",
      "36/36 [==============================] - 0s 616us/step - loss: 0.6192 - accuracy: 0.6510 - val_loss: 0.6325 - val_accuracy: 0.6510\n",
      "Epoch 111/1000\n",
      "36/36 [==============================] - 0s 614us/step - loss: 0.6188 - accuracy: 0.6510 - val_loss: 0.6322 - val_accuracy: 0.6510\n",
      "Epoch 112/1000\n",
      "36/36 [==============================] - 0s 609us/step - loss: 0.6184 - accuracy: 0.6510 - val_loss: 0.6319 - val_accuracy: 0.6510\n",
      "Epoch 113/1000\n",
      "36/36 [==============================] - 0s 602us/step - loss: 0.6180 - accuracy: 0.6510 - val_loss: 0.6316 - val_accuracy: 0.6510\n",
      "Epoch 114/1000\n",
      "36/36 [==============================] - 0s 609us/step - loss: 0.6176 - accuracy: 0.6510 - val_loss: 0.6313 - val_accuracy: 0.6510\n",
      "Epoch 115/1000\n",
      "36/36 [==============================] - 0s 605us/step - loss: 0.6172 - accuracy: 0.6510 - val_loss: 0.6310 - val_accuracy: 0.6510\n",
      "Epoch 116/1000\n",
      "36/36 [==============================] - 0s 601us/step - loss: 0.6168 - accuracy: 0.6510 - val_loss: 0.6306 - val_accuracy: 0.6510\n",
      "Epoch 117/1000\n",
      "36/36 [==============================] - 0s 608us/step - loss: 0.6164 - accuracy: 0.6510 - val_loss: 0.6303 - val_accuracy: 0.6510\n",
      "Epoch 118/1000\n",
      "36/36 [==============================] - 0s 606us/step - loss: 0.6160 - accuracy: 0.6510 - val_loss: 0.6300 - val_accuracy: 0.6510\n",
      "Epoch 119/1000\n",
      "36/36 [==============================] - 0s 609us/step - loss: 0.6156 - accuracy: 0.6510 - val_loss: 0.6297 - val_accuracy: 0.6510\n",
      "Epoch 120/1000\n",
      "36/36 [==============================] - 0s 612us/step - loss: 0.6152 - accuracy: 0.6510 - val_loss: 0.6294 - val_accuracy: 0.6510\n",
      "Epoch 121/1000\n",
      "36/36 [==============================] - 0s 604us/step - loss: 0.6148 - accuracy: 0.6510 - val_loss: 0.6290 - val_accuracy: 0.6510\n",
      "Epoch 122/1000\n",
      "36/36 [==============================] - 0s 604us/step - loss: 0.6144 - accuracy: 0.6510 - val_loss: 0.6287 - val_accuracy: 0.6510\n",
      "Epoch 123/1000\n",
      "36/36 [==============================] - 0s 656us/step - loss: 0.6140 - accuracy: 0.6510 - val_loss: 0.6284 - val_accuracy: 0.6510\n",
      "Epoch 124/1000\n",
      "36/36 [==============================] - 0s 639us/step - loss: 0.6136 - accuracy: 0.6510 - val_loss: 0.6281 - val_accuracy: 0.6510\n",
      "Epoch 125/1000\n",
      "36/36 [==============================] - 0s 703us/step - loss: 0.6132 - accuracy: 0.6510 - val_loss: 0.6278 - val_accuracy: 0.6510\n",
      "Epoch 126/1000\n",
      "36/36 [==============================] - 0s 668us/step - loss: 0.6129 - accuracy: 0.6510 - val_loss: 0.6275 - val_accuracy: 0.6510\n",
      "Epoch 127/1000\n",
      "36/36 [==============================] - 0s 913us/step - loss: 0.6125 - accuracy: 0.6510 - val_loss: 0.6271 - val_accuracy: 0.6510\n",
      "Epoch 128/1000\n",
      "36/36 [==============================] - 0s 736us/step - loss: 0.6121 - accuracy: 0.6510 - val_loss: 0.6268 - val_accuracy: 0.6510\n",
      "Epoch 129/1000\n",
      "36/36 [==============================] - 0s 698us/step - loss: 0.6117 - accuracy: 0.6510 - val_loss: 0.6265 - val_accuracy: 0.6510\n",
      "Epoch 130/1000\n",
      "36/36 [==============================] - 0s 700us/step - loss: 0.6112 - accuracy: 0.6510 - val_loss: 0.6262 - val_accuracy: 0.6510\n",
      "Epoch 131/1000\n",
      "36/36 [==============================] - 0s 711us/step - loss: 0.6108 - accuracy: 0.6510 - val_loss: 0.6258 - val_accuracy: 0.6510\n",
      "Epoch 132/1000\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.6104 - accuracy: 0.6510 - val_loss: 0.6255 - val_accuracy: 0.6510\n",
      "Epoch 133/1000\n",
      "36/36 [==============================] - 0s 705us/step - loss: 0.6100 - accuracy: 0.6510 - val_loss: 0.6252 - val_accuracy: 0.6510\n",
      "Epoch 134/1000\n",
      "36/36 [==============================] - 0s 649us/step - loss: 0.6096 - accuracy: 0.6510 - val_loss: 0.6248 - val_accuracy: 0.6510\n",
      "Epoch 135/1000\n",
      "36/36 [==============================] - 0s 691us/step - loss: 0.6092 - accuracy: 0.6510 - val_loss: 0.6245 - val_accuracy: 0.6510\n",
      "Epoch 136/1000\n",
      "36/36 [==============================] - 0s 693us/step - loss: 0.6088 - accuracy: 0.6510 - val_loss: 0.6242 - val_accuracy: 0.6510\n",
      "Epoch 137/1000\n",
      "36/36 [==============================] - 0s 667us/step - loss: 0.6083 - accuracy: 0.6510 - val_loss: 0.6238 - val_accuracy: 0.6510\n",
      "Epoch 138/1000\n",
      "36/36 [==============================] - 0s 662us/step - loss: 0.6079 - accuracy: 0.6510 - val_loss: 0.6235 - val_accuracy: 0.6510\n",
      "Epoch 139/1000\n",
      "36/36 [==============================] - 0s 660us/step - loss: 0.6075 - accuracy: 0.6510 - val_loss: 0.6231 - val_accuracy: 0.6510\n",
      "Epoch 140/1000\n",
      "36/36 [==============================] - 0s 639us/step - loss: 0.6070 - accuracy: 0.6510 - val_loss: 0.6228 - val_accuracy: 0.6510\n",
      "Epoch 141/1000\n",
      "36/36 [==============================] - 0s 625us/step - loss: 0.6066 - accuracy: 0.6510 - val_loss: 0.6224 - val_accuracy: 0.6510\n",
      "Epoch 142/1000\n",
      "36/36 [==============================] - 0s 631us/step - loss: 0.6062 - accuracy: 0.6510 - val_loss: 0.6221 - val_accuracy: 0.6510\n",
      "Epoch 143/1000\n",
      "36/36 [==============================] - 0s 666us/step - loss: 0.6057 - accuracy: 0.6510 - val_loss: 0.6217 - val_accuracy: 0.6510\n",
      "Epoch 144/1000\n",
      "36/36 [==============================] - 0s 635us/step - loss: 0.6053 - accuracy: 0.6510 - val_loss: 0.6214 - val_accuracy: 0.6510\n",
      "Epoch 145/1000\n",
      "36/36 [==============================] - 0s 648us/step - loss: 0.6048 - accuracy: 0.6510 - val_loss: 0.6210 - val_accuracy: 0.6510\n",
      "Epoch 146/1000\n",
      "36/36 [==============================] - 0s 632us/step - loss: 0.6044 - accuracy: 0.6510 - val_loss: 0.6207 - val_accuracy: 0.6510\n",
      "Epoch 147/1000\n",
      "36/36 [==============================] - 0s 651us/step - loss: 0.6039 - accuracy: 0.6510 - val_loss: 0.6203 - val_accuracy: 0.6510\n",
      "Epoch 148/1000\n",
      "36/36 [==============================] - 0s 637us/step - loss: 0.6035 - accuracy: 0.6528 - val_loss: 0.6200 - val_accuracy: 0.6510\n",
      "Epoch 149/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.6030 - accuracy: 0.6528 - val_loss: 0.6196 - val_accuracy: 0.6510\n",
      "Epoch 150/1000\n",
      "36/36 [==============================] - 0s 875us/step - loss: 0.6026 - accuracy: 0.6528 - val_loss: 0.6193 - val_accuracy: 0.6510\n",
      "Epoch 151/1000\n",
      "36/36 [==============================] - 0s 670us/step - loss: 0.6021 - accuracy: 0.6528 - val_loss: 0.6189 - val_accuracy: 0.6510\n",
      "Epoch 152/1000\n",
      "36/36 [==============================] - 0s 679us/step - loss: 0.6017 - accuracy: 0.6528 - val_loss: 0.6185 - val_accuracy: 0.6510\n",
      "Epoch 153/1000\n",
      "36/36 [==============================] - 0s 676us/step - loss: 0.6012 - accuracy: 0.6528 - val_loss: 0.6182 - val_accuracy: 0.6510\n",
      "Epoch 154/1000\n",
      "36/36 [==============================] - 0s 666us/step - loss: 0.6008 - accuracy: 0.6528 - val_loss: 0.6178 - val_accuracy: 0.6510\n",
      "Epoch 155/1000\n",
      "36/36 [==============================] - 0s 636us/step - loss: 0.6003 - accuracy: 0.6528 - val_loss: 0.6175 - val_accuracy: 0.6510\n",
      "Epoch 156/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.5999 - accuracy: 0.6528 - val_loss: 0.6171 - val_accuracy: 0.6510\n",
      "Epoch 157/1000\n",
      "36/36 [==============================] - 0s 628us/step - loss: 0.5994 - accuracy: 0.6528 - val_loss: 0.6167 - val_accuracy: 0.6510\n",
      "Epoch 158/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.5989 - accuracy: 0.6528 - val_loss: 0.6164 - val_accuracy: 0.6510\n",
      "Epoch 159/1000\n",
      "36/36 [==============================] - 0s 632us/step - loss: 0.5985 - accuracy: 0.6528 - val_loss: 0.6160 - val_accuracy: 0.6510\n",
      "Epoch 160/1000\n",
      "36/36 [==============================] - 0s 625us/step - loss: 0.5980 - accuracy: 0.6528 - val_loss: 0.6156 - val_accuracy: 0.6510\n",
      "Epoch 161/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.5976 - accuracy: 0.6528 - val_loss: 0.6152 - val_accuracy: 0.6510\n",
      "Epoch 162/1000\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.5971 - accuracy: 0.6528 - val_loss: 0.6148 - val_accuracy: 0.6510\n",
      "Epoch 163/1000\n",
      "36/36 [==============================] - 0s 651us/step - loss: 0.5966 - accuracy: 0.6528 - val_loss: 0.6144 - val_accuracy: 0.6510\n",
      "Epoch 164/1000\n",
      "36/36 [==============================] - 0s 632us/step - loss: 0.5961 - accuracy: 0.6528 - val_loss: 0.6141 - val_accuracy: 0.6510\n",
      "Epoch 165/1000\n",
      "36/36 [==============================] - 0s 649us/step - loss: 0.5957 - accuracy: 0.6528 - val_loss: 0.6137 - val_accuracy: 0.6510\n",
      "Epoch 166/1000\n",
      "36/36 [==============================] - 0s 663us/step - loss: 0.5952 - accuracy: 0.6528 - val_loss: 0.6133 - val_accuracy: 0.6510\n",
      "Epoch 167/1000\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.5947 - accuracy: 0.6528 - val_loss: 0.6129 - val_accuracy: 0.6510\n",
      "Epoch 168/1000\n",
      "36/36 [==============================] - 0s 639us/step - loss: 0.5942 - accuracy: 0.6528 - val_loss: 0.6125 - val_accuracy: 0.6510\n",
      "Epoch 169/1000\n",
      "36/36 [==============================] - 0s 646us/step - loss: 0.5937 - accuracy: 0.6528 - val_loss: 0.6121 - val_accuracy: 0.6510\n",
      "Epoch 170/1000\n",
      "36/36 [==============================] - 0s 688us/step - loss: 0.5933 - accuracy: 0.6528 - val_loss: 0.6117 - val_accuracy: 0.6510\n",
      "Epoch 171/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.5928 - accuracy: 0.6528 - val_loss: 0.6112 - val_accuracy: 0.6510\n",
      "Epoch 172/1000\n",
      "36/36 [==============================] - 0s 662us/step - loss: 0.5923 - accuracy: 0.6528 - val_loss: 0.6108 - val_accuracy: 0.6510\n",
      "Epoch 173/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5918 - accuracy: 0.6528 - val_loss: 0.6104 - val_accuracy: 0.6510\n",
      "Epoch 174/1000\n",
      "36/36 [==============================] - 0s 779us/step - loss: 0.5913 - accuracy: 0.6528 - val_loss: 0.6100 - val_accuracy: 0.6562\n",
      "Epoch 175/1000\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.5908 - accuracy: 0.6528 - val_loss: 0.6096 - val_accuracy: 0.6562\n",
      "Epoch 176/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.5903 - accuracy: 0.6528 - val_loss: 0.6092 - val_accuracy: 0.6562\n",
      "Epoch 177/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.5898 - accuracy: 0.6528 - val_loss: 0.6088 - val_accuracy: 0.6562\n",
      "Epoch 178/1000\n",
      "36/36 [==============================] - 0s 631us/step - loss: 0.5893 - accuracy: 0.6528 - val_loss: 0.6083 - val_accuracy: 0.6562\n",
      "Epoch 179/1000\n",
      "36/36 [==============================] - 0s 648us/step - loss: 0.5888 - accuracy: 0.6528 - val_loss: 0.6079 - val_accuracy: 0.6562\n",
      "Epoch 180/1000\n",
      "36/36 [==============================] - 0s 638us/step - loss: 0.5883 - accuracy: 0.6528 - val_loss: 0.6075 - val_accuracy: 0.6562\n",
      "Epoch 181/1000\n",
      "36/36 [==============================] - 0s 665us/step - loss: 0.5878 - accuracy: 0.6528 - val_loss: 0.6071 - val_accuracy: 0.6562\n",
      "Epoch 182/1000\n",
      "36/36 [==============================] - 0s 637us/step - loss: 0.5873 - accuracy: 0.6528 - val_loss: 0.6066 - val_accuracy: 0.6562\n",
      "Epoch 183/1000\n",
      "36/36 [==============================] - 0s 650us/step - loss: 0.5868 - accuracy: 0.6528 - val_loss: 0.6062 - val_accuracy: 0.6562\n",
      "Epoch 184/1000\n",
      "36/36 [==============================] - 0s 638us/step - loss: 0.5863 - accuracy: 0.6528 - val_loss: 0.6058 - val_accuracy: 0.6562\n",
      "Epoch 185/1000\n",
      "36/36 [==============================] - 0s 652us/step - loss: 0.5857 - accuracy: 0.6528 - val_loss: 0.6053 - val_accuracy: 0.6562\n",
      "Epoch 186/1000\n",
      "36/36 [==============================] - 0s 636us/step - loss: 0.5852 - accuracy: 0.6528 - val_loss: 0.6049 - val_accuracy: 0.6562\n",
      "Epoch 187/1000\n",
      "36/36 [==============================] - 0s 632us/step - loss: 0.5847 - accuracy: 0.6528 - val_loss: 0.6045 - val_accuracy: 0.6562\n",
      "Epoch 188/1000\n",
      "36/36 [==============================] - 0s 660us/step - loss: 0.5842 - accuracy: 0.6528 - val_loss: 0.6040 - val_accuracy: 0.6562\n",
      "Epoch 189/1000\n",
      "36/36 [==============================] - 0s 639us/step - loss: 0.5837 - accuracy: 0.6528 - val_loss: 0.6036 - val_accuracy: 0.6562\n",
      "Epoch 190/1000\n",
      "36/36 [==============================] - 0s 650us/step - loss: 0.5832 - accuracy: 0.6528 - val_loss: 0.6032 - val_accuracy: 0.6562\n",
      "Epoch 191/1000\n",
      "36/36 [==============================] - 0s 628us/step - loss: 0.5827 - accuracy: 0.6528 - val_loss: 0.6027 - val_accuracy: 0.6562\n",
      "Epoch 192/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.5822 - accuracy: 0.6528 - val_loss: 0.6023 - val_accuracy: 0.6562\n",
      "Epoch 193/1000\n",
      "36/36 [==============================] - 0s 645us/step - loss: 0.5816 - accuracy: 0.6528 - val_loss: 0.6018 - val_accuracy: 0.6562\n",
      "Epoch 194/1000\n",
      "36/36 [==============================] - 0s 657us/step - loss: 0.5811 - accuracy: 0.6528 - val_loss: 0.6014 - val_accuracy: 0.6562\n",
      "Epoch 195/1000\n",
      "36/36 [==============================] - 0s 626us/step - loss: 0.5806 - accuracy: 0.6528 - val_loss: 0.6010 - val_accuracy: 0.6562\n",
      "Epoch 196/1000\n",
      "36/36 [==============================] - 0s 657us/step - loss: 0.5801 - accuracy: 0.6528 - val_loss: 0.6005 - val_accuracy: 0.6562\n",
      "Epoch 197/1000\n",
      "36/36 [==============================] - 0s 646us/step - loss: 0.5796 - accuracy: 0.6545 - val_loss: 0.6001 - val_accuracy: 0.6615\n",
      "Epoch 198/1000\n",
      "36/36 [==============================] - 0s 632us/step - loss: 0.5790 - accuracy: 0.6545 - val_loss: 0.5996 - val_accuracy: 0.6615\n",
      "Epoch 199/1000\n",
      "36/36 [==============================] - 0s 652us/step - loss: 0.5785 - accuracy: 0.6545 - val_loss: 0.5992 - val_accuracy: 0.6615\n",
      "Epoch 200/1000\n",
      "36/36 [==============================] - 0s 636us/step - loss: 0.5780 - accuracy: 0.6545 - val_loss: 0.5987 - val_accuracy: 0.6615\n",
      "Epoch 201/1000\n",
      "36/36 [==============================] - 0s 652us/step - loss: 0.5775 - accuracy: 0.6545 - val_loss: 0.5983 - val_accuracy: 0.6615\n",
      "Epoch 202/1000\n",
      "36/36 [==============================] - 0s 619us/step - loss: 0.5770 - accuracy: 0.6545 - val_loss: 0.5978 - val_accuracy: 0.6615\n",
      "Epoch 203/1000\n",
      "36/36 [==============================] - 0s 671us/step - loss: 0.5765 - accuracy: 0.6545 - val_loss: 0.5974 - val_accuracy: 0.6615\n",
      "Epoch 204/1000\n",
      "36/36 [==============================] - 0s 628us/step - loss: 0.5760 - accuracy: 0.6545 - val_loss: 0.5970 - val_accuracy: 0.6615\n",
      "Epoch 205/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5755 - accuracy: 0.6545 - val_loss: 0.5965 - val_accuracy: 0.6615\n",
      "Epoch 206/1000\n",
      "36/36 [==============================] - 0s 866us/step - loss: 0.5750 - accuracy: 0.6545 - val_loss: 0.5961 - val_accuracy: 0.6615\n",
      "Epoch 207/1000\n",
      "36/36 [==============================] - 0s 622us/step - loss: 0.5744 - accuracy: 0.6562 - val_loss: 0.5956 - val_accuracy: 0.6615\n",
      "Epoch 208/1000\n",
      "36/36 [==============================] - 0s 641us/step - loss: 0.5739 - accuracy: 0.6562 - val_loss: 0.5952 - val_accuracy: 0.6615\n",
      "Epoch 209/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.5734 - accuracy: 0.6562 - val_loss: 0.5947 - val_accuracy: 0.6615\n",
      "Epoch 210/1000\n",
      "36/36 [==============================] - 0s 635us/step - loss: 0.5729 - accuracy: 0.6562 - val_loss: 0.5943 - val_accuracy: 0.6615\n",
      "Epoch 211/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.5724 - accuracy: 0.6562 - val_loss: 0.5938 - val_accuracy: 0.6615\n",
      "Epoch 212/1000\n",
      "36/36 [==============================] - 0s 634us/step - loss: 0.5719 - accuracy: 0.6580 - val_loss: 0.5934 - val_accuracy: 0.6615\n",
      "Epoch 213/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.5714 - accuracy: 0.6597 - val_loss: 0.5929 - val_accuracy: 0.6615\n",
      "Epoch 214/1000\n",
      "36/36 [==============================] - 0s 648us/step - loss: 0.5709 - accuracy: 0.6615 - val_loss: 0.5925 - val_accuracy: 0.6615\n",
      "Epoch 215/1000\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.5704 - accuracy: 0.6615 - val_loss: 0.5921 - val_accuracy: 0.6615\n",
      "Epoch 216/1000\n",
      "36/36 [==============================] - 0s 630us/step - loss: 0.5699 - accuracy: 0.6615 - val_loss: 0.5916 - val_accuracy: 0.6615\n",
      "Epoch 217/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.5694 - accuracy: 0.6615 - val_loss: 0.5912 - val_accuracy: 0.6615\n",
      "Epoch 218/1000\n",
      "36/36 [==============================] - 0s 657us/step - loss: 0.5689 - accuracy: 0.6597 - val_loss: 0.5908 - val_accuracy: 0.6667\n",
      "Epoch 219/1000\n",
      "36/36 [==============================] - 0s 635us/step - loss: 0.5684 - accuracy: 0.6597 - val_loss: 0.5903 - val_accuracy: 0.6667\n",
      "Epoch 220/1000\n",
      "36/36 [==============================] - 0s 644us/step - loss: 0.5679 - accuracy: 0.6597 - val_loss: 0.5899 - val_accuracy: 0.6667\n",
      "Epoch 221/1000\n",
      "36/36 [==============================] - 0s 633us/step - loss: 0.5674 - accuracy: 0.6615 - val_loss: 0.5894 - val_accuracy: 0.6667\n",
      "Epoch 222/1000\n",
      "36/36 [==============================] - 0s 869us/step - loss: 0.5669 - accuracy: 0.6615 - val_loss: 0.5890 - val_accuracy: 0.6667\n",
      "Epoch 223/1000\n",
      "36/36 [==============================] - 0s 766us/step - loss: 0.5664 - accuracy: 0.6615 - val_loss: 0.5885 - val_accuracy: 0.6667\n",
      "Epoch 224/1000\n",
      "36/36 [==============================] - 0s 628us/step - loss: 0.5659 - accuracy: 0.6615 - val_loss: 0.5881 - val_accuracy: 0.6667\n",
      "Epoch 225/1000\n",
      "36/36 [==============================] - 0s 645us/step - loss: 0.5654 - accuracy: 0.6615 - val_loss: 0.5877 - val_accuracy: 0.6667\n",
      "Epoch 226/1000\n",
      "36/36 [==============================] - 0s 628us/step - loss: 0.5649 - accuracy: 0.6615 - val_loss: 0.5872 - val_accuracy: 0.6667\n",
      "Epoch 227/1000\n",
      "36/36 [==============================] - 0s 662us/step - loss: 0.5644 - accuracy: 0.6615 - val_loss: 0.5868 - val_accuracy: 0.6667\n",
      "Epoch 228/1000\n",
      "36/36 [==============================] - 0s 628us/step - loss: 0.5639 - accuracy: 0.6615 - val_loss: 0.5863 - val_accuracy: 0.6667\n",
      "Epoch 229/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.5634 - accuracy: 0.6615 - val_loss: 0.5859 - val_accuracy: 0.6667\n",
      "Epoch 230/1000\n",
      "36/36 [==============================] - 0s 634us/step - loss: 0.5629 - accuracy: 0.6615 - val_loss: 0.5854 - val_accuracy: 0.6667\n",
      "Epoch 231/1000\n",
      "36/36 [==============================] - 0s 638us/step - loss: 0.5624 - accuracy: 0.6632 - val_loss: 0.5850 - val_accuracy: 0.6667\n",
      "Epoch 232/1000\n",
      "36/36 [==============================] - 0s 665us/step - loss: 0.5619 - accuracy: 0.6632 - val_loss: 0.5845 - val_accuracy: 0.6667\n",
      "Epoch 233/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.5614 - accuracy: 0.6632 - val_loss: 0.5841 - val_accuracy: 0.6667\n",
      "Epoch 234/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.5609 - accuracy: 0.6632 - val_loss: 0.5836 - val_accuracy: 0.6667\n",
      "Epoch 235/1000\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.5604 - accuracy: 0.6632 - val_loss: 0.5832 - val_accuracy: 0.6667\n",
      "Epoch 236/1000\n",
      "36/36 [==============================] - 0s 665us/step - loss: 0.5599 - accuracy: 0.6632 - val_loss: 0.5828 - val_accuracy: 0.6667\n",
      "Epoch 237/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.5594 - accuracy: 0.6632 - val_loss: 0.5824 - val_accuracy: 0.6667\n",
      "Epoch 238/1000\n",
      "36/36 [==============================] - 0s 646us/step - loss: 0.5589 - accuracy: 0.6615 - val_loss: 0.5820 - val_accuracy: 0.6667\n",
      "Epoch 239/1000\n",
      "36/36 [==============================] - 0s 655us/step - loss: 0.5584 - accuracy: 0.6615 - val_loss: 0.5815 - val_accuracy: 0.6667\n",
      "Epoch 240/1000\n",
      "36/36 [==============================] - 0s 636us/step - loss: 0.5580 - accuracy: 0.6615 - val_loss: 0.5811 - val_accuracy: 0.6667\n",
      "Epoch 241/1000\n",
      "36/36 [==============================] - 0s 658us/step - loss: 0.5575 - accuracy: 0.6615 - val_loss: 0.5807 - val_accuracy: 0.6667\n",
      "Epoch 242/1000\n",
      "36/36 [==============================] - 0s 657us/step - loss: 0.5570 - accuracy: 0.6615 - val_loss: 0.5803 - val_accuracy: 0.6667\n",
      "Epoch 243/1000\n",
      "36/36 [==============================] - 0s 656us/step - loss: 0.5565 - accuracy: 0.6615 - val_loss: 0.5799 - val_accuracy: 0.6667\n",
      "Epoch 244/1000\n",
      "36/36 [==============================] - 0s 646us/step - loss: 0.5560 - accuracy: 0.6615 - val_loss: 0.5795 - val_accuracy: 0.6667\n",
      "Epoch 245/1000\n",
      "36/36 [==============================] - 0s 659us/step - loss: 0.5555 - accuracy: 0.6615 - val_loss: 0.5791 - val_accuracy: 0.6667\n",
      "Epoch 246/1000\n",
      "36/36 [==============================] - 0s 624us/step - loss: 0.5551 - accuracy: 0.6615 - val_loss: 0.5787 - val_accuracy: 0.6667\n",
      "Epoch 247/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.5546 - accuracy: 0.6615 - val_loss: 0.5783 - val_accuracy: 0.6667\n",
      "Epoch 248/1000\n",
      "36/36 [==============================] - 0s 632us/step - loss: 0.5541 - accuracy: 0.6615 - val_loss: 0.5779 - val_accuracy: 0.6719\n",
      "Epoch 249/1000\n",
      "36/36 [==============================] - 0s 651us/step - loss: 0.5536 - accuracy: 0.6615 - val_loss: 0.5775 - val_accuracy: 0.6719\n",
      "Epoch 250/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5532 - accuracy: 0.6649 - val_loss: 0.5771 - val_accuracy: 0.6719\n",
      "Epoch 251/1000\n",
      "36/36 [==============================] - 0s 858us/step - loss: 0.5527 - accuracy: 0.6667 - val_loss: 0.5767 - val_accuracy: 0.6719\n",
      "Epoch 252/1000\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.5522 - accuracy: 0.6667 - val_loss: 0.5763 - val_accuracy: 0.6719\n",
      "Epoch 253/1000\n",
      "36/36 [==============================] - 0s 626us/step - loss: 0.5517 - accuracy: 0.6667 - val_loss: 0.5759 - val_accuracy: 0.6719\n",
      "Epoch 254/1000\n",
      "36/36 [==============================] - 0s 651us/step - loss: 0.5513 - accuracy: 0.6667 - val_loss: 0.5755 - val_accuracy: 0.6719\n",
      "Epoch 255/1000\n",
      "36/36 [==============================] - 0s 623us/step - loss: 0.5508 - accuracy: 0.6667 - val_loss: 0.5751 - val_accuracy: 0.6719\n",
      "Epoch 256/1000\n",
      "36/36 [==============================] - 0s 660us/step - loss: 0.5503 - accuracy: 0.6667 - val_loss: 0.5747 - val_accuracy: 0.6719\n",
      "Epoch 257/1000\n",
      "36/36 [==============================] - 0s 624us/step - loss: 0.5499 - accuracy: 0.6667 - val_loss: 0.5744 - val_accuracy: 0.6719\n",
      "Epoch 258/1000\n",
      "36/36 [==============================] - 0s 649us/step - loss: 0.5494 - accuracy: 0.6667 - val_loss: 0.5740 - val_accuracy: 0.6719\n",
      "Epoch 259/1000\n",
      "36/36 [==============================] - 0s 655us/step - loss: 0.5490 - accuracy: 0.6667 - val_loss: 0.5736 - val_accuracy: 0.6719\n",
      "Epoch 260/1000\n",
      "36/36 [==============================] - 0s 639us/step - loss: 0.5485 - accuracy: 0.6667 - val_loss: 0.5733 - val_accuracy: 0.6771\n",
      "Epoch 261/1000\n",
      "36/36 [==============================] - 0s 646us/step - loss: 0.5481 - accuracy: 0.6667 - val_loss: 0.5729 - val_accuracy: 0.6771\n",
      "Epoch 262/1000\n",
      "36/36 [==============================] - 0s 631us/step - loss: 0.5476 - accuracy: 0.6667 - val_loss: 0.5725 - val_accuracy: 0.6771\n",
      "Epoch 263/1000\n",
      "36/36 [==============================] - 0s 646us/step - loss: 0.5471 - accuracy: 0.6667 - val_loss: 0.5722 - val_accuracy: 0.6771\n",
      "Epoch 264/1000\n",
      "36/36 [==============================] - 0s 626us/step - loss: 0.5467 - accuracy: 0.6667 - val_loss: 0.5718 - val_accuracy: 0.6771\n",
      "Epoch 265/1000\n",
      "36/36 [==============================] - 0s 664us/step - loss: 0.5462 - accuracy: 0.6667 - val_loss: 0.5715 - val_accuracy: 0.6771\n",
      "Epoch 266/1000\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.5458 - accuracy: 0.6667 - val_loss: 0.5711 - val_accuracy: 0.6771\n",
      "Epoch 267/1000\n",
      "36/36 [==============================] - 0s 655us/step - loss: 0.5453 - accuracy: 0.6667 - val_loss: 0.5707 - val_accuracy: 0.6771\n",
      "Epoch 268/1000\n",
      "36/36 [==============================] - 0s 926us/step - loss: 0.5449 - accuracy: 0.6667 - val_loss: 0.5704 - val_accuracy: 0.6771\n",
      "Epoch 269/1000\n",
      "36/36 [==============================] - 0s 757us/step - loss: 0.5444 - accuracy: 0.6667 - val_loss: 0.5700 - val_accuracy: 0.6771\n",
      "Epoch 270/1000\n",
      "36/36 [==============================] - 0s 664us/step - loss: 0.5439 - accuracy: 0.6684 - val_loss: 0.5696 - val_accuracy: 0.6771\n",
      "Epoch 271/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.5434 - accuracy: 0.6684 - val_loss: 0.5692 - val_accuracy: 0.6771\n",
      "Epoch 272/1000\n",
      "36/36 [==============================] - 0s 675us/step - loss: 0.5430 - accuracy: 0.6684 - val_loss: 0.5689 - val_accuracy: 0.6771\n",
      "Epoch 273/1000\n",
      "36/36 [==============================] - 0s 648us/step - loss: 0.5425 - accuracy: 0.6684 - val_loss: 0.5685 - val_accuracy: 0.6771\n",
      "Epoch 274/1000\n",
      "36/36 [==============================] - 0s 663us/step - loss: 0.5421 - accuracy: 0.6684 - val_loss: 0.5681 - val_accuracy: 0.6771\n",
      "Epoch 275/1000\n",
      "36/36 [==============================] - 0s 638us/step - loss: 0.5416 - accuracy: 0.6701 - val_loss: 0.5677 - val_accuracy: 0.6771\n",
      "Epoch 276/1000\n",
      "36/36 [==============================] - 0s 644us/step - loss: 0.5411 - accuracy: 0.6701 - val_loss: 0.5674 - val_accuracy: 0.6771\n",
      "Epoch 277/1000\n",
      "36/36 [==============================] - 0s 641us/step - loss: 0.5406 - accuracy: 0.6701 - val_loss: 0.5670 - val_accuracy: 0.6771\n",
      "Epoch 278/1000\n",
      "36/36 [==============================] - 0s 639us/step - loss: 0.5402 - accuracy: 0.6684 - val_loss: 0.5666 - val_accuracy: 0.6771\n",
      "Epoch 279/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.5397 - accuracy: 0.6684 - val_loss: 0.5662 - val_accuracy: 0.6771\n",
      "Epoch 280/1000\n",
      "36/36 [==============================] - 0s 639us/step - loss: 0.5393 - accuracy: 0.6684 - val_loss: 0.5659 - val_accuracy: 0.6771\n",
      "Epoch 281/1000\n",
      "36/36 [==============================] - 0s 645us/step - loss: 0.5388 - accuracy: 0.6684 - val_loss: 0.5655 - val_accuracy: 0.6771\n",
      "Epoch 282/1000\n",
      "36/36 [==============================] - 0s 629us/step - loss: 0.5383 - accuracy: 0.6684 - val_loss: 0.5651 - val_accuracy: 0.6771\n",
      "Epoch 283/1000\n",
      "36/36 [==============================] - 0s 656us/step - loss: 0.5379 - accuracy: 0.6684 - val_loss: 0.5648 - val_accuracy: 0.6771\n",
      "Epoch 284/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.5374 - accuracy: 0.6684 - val_loss: 0.5644 - val_accuracy: 0.6771\n",
      "Epoch 285/1000\n",
      "36/36 [==============================] - 0s 649us/step - loss: 0.5370 - accuracy: 0.6684 - val_loss: 0.5641 - val_accuracy: 0.6771\n",
      "Epoch 286/1000\n",
      "36/36 [==============================] - 0s 620us/step - loss: 0.5365 - accuracy: 0.6684 - val_loss: 0.5637 - val_accuracy: 0.6771\n",
      "Epoch 287/1000\n",
      "36/36 [==============================] - 0s 650us/step - loss: 0.5360 - accuracy: 0.6701 - val_loss: 0.5633 - val_accuracy: 0.6771\n",
      "Epoch 288/1000\n",
      "36/36 [==============================] - 0s 651us/step - loss: 0.5356 - accuracy: 0.6719 - val_loss: 0.5630 - val_accuracy: 0.6771\n",
      "Epoch 289/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5351 - accuracy: 0.6719 - val_loss: 0.5626 - val_accuracy: 0.6823\n",
      "Epoch 290/1000\n",
      "36/36 [==============================] - 0s 852us/step - loss: 0.5347 - accuracy: 0.6719 - val_loss: 0.5623 - val_accuracy: 0.6823\n",
      "Epoch 291/1000\n",
      "36/36 [==============================] - 0s 638us/step - loss: 0.5343 - accuracy: 0.6719 - val_loss: 0.5620 - val_accuracy: 0.6823\n",
      "Epoch 292/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.5338 - accuracy: 0.6719 - val_loss: 0.5616 - val_accuracy: 0.6823\n",
      "Epoch 293/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.5334 - accuracy: 0.6719 - val_loss: 0.5613 - val_accuracy: 0.6823\n",
      "Epoch 294/1000\n",
      "36/36 [==============================] - 0s 641us/step - loss: 0.5330 - accuracy: 0.6736 - val_loss: 0.5610 - val_accuracy: 0.6823\n",
      "Epoch 295/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.5325 - accuracy: 0.6753 - val_loss: 0.5607 - val_accuracy: 0.6823\n",
      "Epoch 296/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.5321 - accuracy: 0.6753 - val_loss: 0.5604 - val_accuracy: 0.6823\n",
      "Epoch 297/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.5317 - accuracy: 0.6753 - val_loss: 0.5601 - val_accuracy: 0.6823\n",
      "Epoch 298/1000\n",
      "36/36 [==============================] - 0s 637us/step - loss: 0.5313 - accuracy: 0.6736 - val_loss: 0.5598 - val_accuracy: 0.6823\n",
      "Epoch 299/1000\n",
      "36/36 [==============================] - 0s 664us/step - loss: 0.5309 - accuracy: 0.6736 - val_loss: 0.5595 - val_accuracy: 0.6823\n",
      "Epoch 300/1000\n",
      "36/36 [==============================] - 0s 618us/step - loss: 0.5305 - accuracy: 0.6736 - val_loss: 0.5592 - val_accuracy: 0.6823\n",
      "Epoch 301/1000\n",
      "36/36 [==============================] - 0s 639us/step - loss: 0.5301 - accuracy: 0.6736 - val_loss: 0.5588 - val_accuracy: 0.6823\n",
      "Epoch 302/1000\n",
      "36/36 [==============================] - 0s 641us/step - loss: 0.5297 - accuracy: 0.6736 - val_loss: 0.5585 - val_accuracy: 0.6823\n",
      "Epoch 303/1000\n",
      "36/36 [==============================] - 0s 657us/step - loss: 0.5293 - accuracy: 0.6736 - val_loss: 0.5583 - val_accuracy: 0.6823\n",
      "Epoch 304/1000\n",
      "36/36 [==============================] - 0s 645us/step - loss: 0.5289 - accuracy: 0.6736 - val_loss: 0.5580 - val_accuracy: 0.6823\n",
      "Epoch 305/1000\n",
      "36/36 [==============================] - 0s 635us/step - loss: 0.5285 - accuracy: 0.6736 - val_loss: 0.5577 - val_accuracy: 0.6823\n",
      "Epoch 306/1000\n",
      "36/36 [==============================] - 0s 667us/step - loss: 0.5281 - accuracy: 0.6736 - val_loss: 0.5574 - val_accuracy: 0.6823\n",
      "Epoch 307/1000\n",
      "36/36 [==============================] - 0s 936us/step - loss: 0.5277 - accuracy: 0.6736 - val_loss: 0.5571 - val_accuracy: 0.6823\n",
      "Epoch 308/1000\n",
      "36/36 [==============================] - 0s 757us/step - loss: 0.5273 - accuracy: 0.6736 - val_loss: 0.5569 - val_accuracy: 0.6823\n",
      "Epoch 309/1000\n",
      "36/36 [==============================] - 0s 649us/step - loss: 0.5269 - accuracy: 0.6736 - val_loss: 0.5566 - val_accuracy: 0.6823\n",
      "Epoch 310/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.5265 - accuracy: 0.6736 - val_loss: 0.5563 - val_accuracy: 0.6823\n",
      "Epoch 311/1000\n",
      "36/36 [==============================] - 0s 651us/step - loss: 0.5262 - accuracy: 0.6736 - val_loss: 0.5561 - val_accuracy: 0.6823\n",
      "Epoch 312/1000\n",
      "36/36 [==============================] - 0s 622us/step - loss: 0.5258 - accuracy: 0.6736 - val_loss: 0.5558 - val_accuracy: 0.6823\n",
      "Epoch 313/1000\n",
      "36/36 [==============================] - 0s 641us/step - loss: 0.5254 - accuracy: 0.6736 - val_loss: 0.5555 - val_accuracy: 0.6875\n",
      "Epoch 314/1000\n",
      "36/36 [==============================] - 0s 629us/step - loss: 0.5251 - accuracy: 0.6736 - val_loss: 0.5553 - val_accuracy: 0.6875\n",
      "Epoch 315/1000\n",
      "36/36 [==============================] - 0s 651us/step - loss: 0.5247 - accuracy: 0.6736 - val_loss: 0.5550 - val_accuracy: 0.6875\n",
      "Epoch 316/1000\n",
      "36/36 [==============================] - 0s 621us/step - loss: 0.5243 - accuracy: 0.6736 - val_loss: 0.5547 - val_accuracy: 0.6875\n",
      "Epoch 317/1000\n",
      "36/36 [==============================] - 0s 636us/step - loss: 0.5240 - accuracy: 0.6736 - val_loss: 0.5545 - val_accuracy: 0.6875\n",
      "Epoch 318/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.5236 - accuracy: 0.6736 - val_loss: 0.5542 - val_accuracy: 0.6875\n",
      "Epoch 319/1000\n",
      "36/36 [==============================] - 0s 629us/step - loss: 0.5233 - accuracy: 0.6753 - val_loss: 0.5540 - val_accuracy: 0.6875\n",
      "Epoch 320/1000\n",
      "36/36 [==============================] - 0s 662us/step - loss: 0.5229 - accuracy: 0.6753 - val_loss: 0.5537 - val_accuracy: 0.6875\n",
      "Epoch 321/1000\n",
      "36/36 [==============================] - 0s 638us/step - loss: 0.5226 - accuracy: 0.6753 - val_loss: 0.5534 - val_accuracy: 0.6927\n",
      "Epoch 322/1000\n",
      "36/36 [==============================] - 0s 646us/step - loss: 0.5222 - accuracy: 0.6753 - val_loss: 0.5532 - val_accuracy: 0.6927\n",
      "Epoch 323/1000\n",
      "36/36 [==============================] - 0s 636us/step - loss: 0.5219 - accuracy: 0.6788 - val_loss: 0.5529 - val_accuracy: 0.6927\n",
      "Epoch 324/1000\n",
      "36/36 [==============================] - 0s 667us/step - loss: 0.5215 - accuracy: 0.6840 - val_loss: 0.5526 - val_accuracy: 0.6927\n",
      "Epoch 325/1000\n",
      "36/36 [==============================] - 0s 633us/step - loss: 0.5212 - accuracy: 0.6858 - val_loss: 0.5523 - val_accuracy: 0.6927\n",
      "Epoch 326/1000\n",
      "36/36 [==============================] - 0s 667us/step - loss: 0.5208 - accuracy: 0.6858 - val_loss: 0.5521 - val_accuracy: 0.6979\n",
      "Epoch 327/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.5204 - accuracy: 0.6840 - val_loss: 0.5518 - val_accuracy: 0.6979\n",
      "Epoch 328/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.5201 - accuracy: 0.6840 - val_loss: 0.5516 - val_accuracy: 0.6979\n",
      "Epoch 329/1000\n",
      "36/36 [==============================] - 0s 870us/step - loss: 0.5197 - accuracy: 0.6858 - val_loss: 0.5513 - val_accuracy: 0.6927\n",
      "Epoch 330/1000\n",
      "36/36 [==============================] - 0s 639us/step - loss: 0.5194 - accuracy: 0.6875 - val_loss: 0.5510 - val_accuracy: 0.6979\n",
      "Epoch 331/1000\n",
      "36/36 [==============================] - 0s 686us/step - loss: 0.5190 - accuracy: 0.6910 - val_loss: 0.5508 - val_accuracy: 0.6979\n",
      "Epoch 332/1000\n",
      "36/36 [==============================] - 0s 659us/step - loss: 0.5187 - accuracy: 0.6944 - val_loss: 0.5505 - val_accuracy: 0.7031\n",
      "Epoch 333/1000\n",
      "36/36 [==============================] - 0s 670us/step - loss: 0.5183 - accuracy: 0.6944 - val_loss: 0.5502 - val_accuracy: 0.7135\n",
      "Epoch 334/1000\n",
      "36/36 [==============================] - 0s 637us/step - loss: 0.5179 - accuracy: 0.6962 - val_loss: 0.5499 - val_accuracy: 0.7135\n",
      "Epoch 335/1000\n",
      "36/36 [==============================] - 0s 649us/step - loss: 0.5176 - accuracy: 0.6927 - val_loss: 0.5497 - val_accuracy: 0.7188\n",
      "Epoch 336/1000\n",
      "36/36 [==============================] - 0s 627us/step - loss: 0.5172 - accuracy: 0.6997 - val_loss: 0.5494 - val_accuracy: 0.7188\n",
      "Epoch 337/1000\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.5169 - accuracy: 0.6962 - val_loss: 0.5492 - val_accuracy: 0.7240\n",
      "Epoch 338/1000\n",
      "36/36 [==============================] - 0s 628us/step - loss: 0.5165 - accuracy: 0.7049 - val_loss: 0.5489 - val_accuracy: 0.7240\n",
      "Epoch 339/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.5162 - accuracy: 0.7135 - val_loss: 0.5487 - val_accuracy: 0.7292\n",
      "Epoch 340/1000\n",
      "36/36 [==============================] - 0s 632us/step - loss: 0.5159 - accuracy: 0.7257 - val_loss: 0.5484 - val_accuracy: 0.7344\n",
      "Epoch 341/1000\n",
      "36/36 [==============================] - 0s 633us/step - loss: 0.5155 - accuracy: 0.7257 - val_loss: 0.5481 - val_accuracy: 0.7344\n",
      "Epoch 342/1000\n",
      "36/36 [==============================] - 0s 912us/step - loss: 0.5152 - accuracy: 0.7222 - val_loss: 0.5479 - val_accuracy: 0.7344\n",
      "Epoch 343/1000\n",
      "36/36 [==============================] - 0s 757us/step - loss: 0.5149 - accuracy: 0.7257 - val_loss: 0.5476 - val_accuracy: 0.7396\n",
      "Epoch 344/1000\n",
      "36/36 [==============================] - 0s 658us/step - loss: 0.5145 - accuracy: 0.7257 - val_loss: 0.5474 - val_accuracy: 0.7448\n",
      "Epoch 345/1000\n",
      "36/36 [==============================] - 0s 641us/step - loss: 0.5142 - accuracy: 0.7240 - val_loss: 0.5472 - val_accuracy: 0.7396\n",
      "Epoch 346/1000\n",
      "36/36 [==============================] - 0s 639us/step - loss: 0.5139 - accuracy: 0.7222 - val_loss: 0.5469 - val_accuracy: 0.7396\n",
      "Epoch 347/1000\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.5135 - accuracy: 0.7274 - val_loss: 0.5467 - val_accuracy: 0.7344\n",
      "Epoch 348/1000\n",
      "36/36 [==============================] - 0s 629us/step - loss: 0.5132 - accuracy: 0.7257 - val_loss: 0.5464 - val_accuracy: 0.7344\n",
      "Epoch 349/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.5129 - accuracy: 0.7240 - val_loss: 0.5461 - val_accuracy: 0.7344\n",
      "Epoch 350/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.5126 - accuracy: 0.7274 - val_loss: 0.5459 - val_accuracy: 0.7396\n",
      "Epoch 351/1000\n",
      "36/36 [==============================] - 0s 664us/step - loss: 0.5122 - accuracy: 0.7274 - val_loss: 0.5456 - val_accuracy: 0.7396\n",
      "Epoch 352/1000\n",
      "36/36 [==============================] - 0s 635us/step - loss: 0.5119 - accuracy: 0.7274 - val_loss: 0.5454 - val_accuracy: 0.7344\n",
      "Epoch 353/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.5116 - accuracy: 0.7309 - val_loss: 0.5452 - val_accuracy: 0.7344\n",
      "Epoch 354/1000\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.5113 - accuracy: 0.7309 - val_loss: 0.5449 - val_accuracy: 0.7344\n",
      "Epoch 355/1000\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.5110 - accuracy: 0.7326 - val_loss: 0.5447 - val_accuracy: 0.7344\n",
      "Epoch 356/1000\n",
      "36/36 [==============================] - 0s 662us/step - loss: 0.5106 - accuracy: 0.7326 - val_loss: 0.5444 - val_accuracy: 0.7344\n",
      "Epoch 357/1000\n",
      "36/36 [==============================] - 0s 651us/step - loss: 0.5103 - accuracy: 0.7326 - val_loss: 0.5442 - val_accuracy: 0.7344\n",
      "Epoch 358/1000\n",
      "36/36 [==============================] - 0s 695us/step - loss: 0.5100 - accuracy: 0.7344 - val_loss: 0.5439 - val_accuracy: 0.7344\n",
      "Epoch 359/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7344 - val_loss: 0.5437 - val_accuracy: 0.7396\n",
      "Epoch 360/1000\n",
      "36/36 [==============================] - 0s 673us/step - loss: 0.5094 - accuracy: 0.7378 - val_loss: 0.5434 - val_accuracy: 0.7344\n",
      "Epoch 361/1000\n",
      "36/36 [==============================] - 0s 699us/step - loss: 0.5091 - accuracy: 0.7344 - val_loss: 0.5432 - val_accuracy: 0.7344\n",
      "Epoch 362/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.5088 - accuracy: 0.7344 - val_loss: 0.5429 - val_accuracy: 0.7344\n",
      "Epoch 363/1000\n",
      "36/36 [==============================] - 0s 649us/step - loss: 0.5085 - accuracy: 0.7326 - val_loss: 0.5427 - val_accuracy: 0.7344\n",
      "Epoch 364/1000\n",
      "36/36 [==============================] - 0s 629us/step - loss: 0.5082 - accuracy: 0.7309 - val_loss: 0.5425 - val_accuracy: 0.7344\n",
      "Epoch 365/1000\n",
      "36/36 [==============================] - 0s 656us/step - loss: 0.5079 - accuracy: 0.7274 - val_loss: 0.5422 - val_accuracy: 0.7344\n",
      "Epoch 366/1000\n",
      "36/36 [==============================] - 0s 639us/step - loss: 0.5076 - accuracy: 0.7274 - val_loss: 0.5420 - val_accuracy: 0.7344\n",
      "Epoch 367/1000\n",
      "36/36 [==============================] - 0s 655us/step - loss: 0.5073 - accuracy: 0.7292 - val_loss: 0.5418 - val_accuracy: 0.7344\n",
      "Epoch 368/1000\n",
      "36/36 [==============================] - 0s 649us/step - loss: 0.5070 - accuracy: 0.7274 - val_loss: 0.5415 - val_accuracy: 0.7396\n",
      "Epoch 369/1000\n",
      "36/36 [==============================] - 0s 649us/step - loss: 0.5067 - accuracy: 0.7309 - val_loss: 0.5413 - val_accuracy: 0.7396\n",
      "Epoch 370/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.5065 - accuracy: 0.7274 - val_loss: 0.5411 - val_accuracy: 0.7396\n",
      "Epoch 371/1000\n",
      "36/36 [==============================] - 0s 644us/step - loss: 0.5062 - accuracy: 0.7257 - val_loss: 0.5408 - val_accuracy: 0.7448\n",
      "Epoch 372/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.5059 - accuracy: 0.7274 - val_loss: 0.5406 - val_accuracy: 0.7448\n",
      "Epoch 373/1000\n",
      "36/36 [==============================] - 0s 638us/step - loss: 0.5056 - accuracy: 0.7257 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
      "Epoch 374/1000\n",
      "36/36 [==============================] - 0s 674us/step - loss: 0.5053 - accuracy: 0.7274 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
      "Epoch 375/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.5050 - accuracy: 0.7292 - val_loss: 0.5399 - val_accuracy: 0.7552\n",
      "Epoch 376/1000\n",
      "36/36 [==============================] - 0s 763us/step - loss: 0.5048 - accuracy: 0.7292 - val_loss: 0.5397 - val_accuracy: 0.7604\n",
      "Epoch 377/1000\n",
      "36/36 [==============================] - 0s 660us/step - loss: 0.5045 - accuracy: 0.7309 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
      "Epoch 378/1000\n",
      "36/36 [==============================] - 0s 655us/step - loss: 0.5042 - accuracy: 0.7292 - val_loss: 0.5392 - val_accuracy: 0.7500\n",
      "Epoch 379/1000\n",
      "36/36 [==============================] - 0s 651us/step - loss: 0.5039 - accuracy: 0.7326 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
      "Epoch 380/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.5036 - accuracy: 0.7344 - val_loss: 0.5388 - val_accuracy: 0.7448\n",
      "Epoch 381/1000\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.5034 - accuracy: 0.7344 - val_loss: 0.5385 - val_accuracy: 0.7448\n",
      "Epoch 382/1000\n",
      "36/36 [==============================] - 0s 639us/step - loss: 0.5031 - accuracy: 0.7396 - val_loss: 0.5383 - val_accuracy: 0.7448\n",
      "Epoch 383/1000\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.5028 - accuracy: 0.7396 - val_loss: 0.5381 - val_accuracy: 0.7448\n",
      "Epoch 384/1000\n",
      "36/36 [==============================] - 0s 631us/step - loss: 0.5026 - accuracy: 0.7413 - val_loss: 0.5379 - val_accuracy: 0.7448\n",
      "Epoch 385/1000\n",
      "36/36 [==============================] - 0s 663us/step - loss: 0.5023 - accuracy: 0.7431 - val_loss: 0.5376 - val_accuracy: 0.7500\n",
      "Epoch 386/1000\n",
      "36/36 [==============================] - 0s 639us/step - loss: 0.5020 - accuracy: 0.7413 - val_loss: 0.5374 - val_accuracy: 0.7500\n",
      "Epoch 387/1000\n",
      "36/36 [==============================] - 0s 658us/step - loss: 0.5018 - accuracy: 0.7413 - val_loss: 0.5372 - val_accuracy: 0.7500\n",
      "Epoch 388/1000\n",
      "36/36 [==============================] - 0s 630us/step - loss: 0.5015 - accuracy: 0.7396 - val_loss: 0.5370 - val_accuracy: 0.7552\n",
      "Epoch 389/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.7396 - val_loss: 0.5368 - val_accuracy: 0.7552\n",
      "Epoch 390/1000\n",
      "36/36 [==============================] - 0s 667us/step - loss: 0.5010 - accuracy: 0.7396 - val_loss: 0.5366 - val_accuracy: 0.7552\n",
      "Epoch 391/1000\n",
      "36/36 [==============================] - 0s 697us/step - loss: 0.5007 - accuracy: 0.7396 - val_loss: 0.5364 - val_accuracy: 0.7552\n",
      "Epoch 392/1000\n",
      "36/36 [==============================] - 0s 665us/step - loss: 0.5005 - accuracy: 0.7396 - val_loss: 0.5362 - val_accuracy: 0.7552\n",
      "Epoch 393/1000\n",
      "36/36 [==============================] - 0s 668us/step - loss: 0.5002 - accuracy: 0.7396 - val_loss: 0.5360 - val_accuracy: 0.7552\n",
      "Epoch 394/1000\n",
      "36/36 [==============================] - 0s 656us/step - loss: 0.5000 - accuracy: 0.7396 - val_loss: 0.5358 - val_accuracy: 0.7552\n",
      "Epoch 395/1000\n",
      "36/36 [==============================] - 0s 644us/step - loss: 0.4997 - accuracy: 0.7396 - val_loss: 0.5356 - val_accuracy: 0.7552\n",
      "Epoch 396/1000\n",
      "36/36 [==============================] - 0s 667us/step - loss: 0.4995 - accuracy: 0.7448 - val_loss: 0.5354 - val_accuracy: 0.7448\n",
      "Epoch 397/1000\n",
      "36/36 [==============================] - 0s 655us/step - loss: 0.4992 - accuracy: 0.7552 - val_loss: 0.5352 - val_accuracy: 0.7448\n",
      "Epoch 398/1000\n",
      "36/36 [==============================] - 0s 627us/step - loss: 0.4990 - accuracy: 0.7500 - val_loss: 0.5351 - val_accuracy: 0.7448\n",
      "Epoch 399/1000\n",
      "36/36 [==============================] - 0s 633us/step - loss: 0.4988 - accuracy: 0.7517 - val_loss: 0.5349 - val_accuracy: 0.7448\n",
      "Epoch 400/1000\n",
      "36/36 [==============================] - 0s 650us/step - loss: 0.4986 - accuracy: 0.7517 - val_loss: 0.5347 - val_accuracy: 0.7448\n",
      "Epoch 401/1000\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.4983 - accuracy: 0.7552 - val_loss: 0.5345 - val_accuracy: 0.7448\n",
      "Epoch 402/1000\n",
      "36/36 [==============================] - 0s 670us/step - loss: 0.4981 - accuracy: 0.7552 - val_loss: 0.5343 - val_accuracy: 0.7396\n",
      "Epoch 403/1000\n",
      "36/36 [==============================] - 0s 632us/step - loss: 0.4978 - accuracy: 0.7569 - val_loss: 0.5342 - val_accuracy: 0.7396\n",
      "Epoch 404/1000\n",
      "36/36 [==============================] - 0s 906us/step - loss: 0.4976 - accuracy: 0.7569 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 405/1000\n",
      "36/36 [==============================] - 0s 787us/step - loss: 0.4974 - accuracy: 0.7552 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 406/1000\n",
      "36/36 [==============================] - 0s 638us/step - loss: 0.4972 - accuracy: 0.7569 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 407/1000\n",
      "36/36 [==============================] - 0s 677us/step - loss: 0.4969 - accuracy: 0.7552 - val_loss: 0.5334 - val_accuracy: 0.7396\n",
      "Epoch 408/1000\n",
      "36/36 [==============================] - 0s 656us/step - loss: 0.4967 - accuracy: 0.7500 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
      "Epoch 409/1000\n",
      "36/36 [==============================] - 0s 656us/step - loss: 0.4965 - accuracy: 0.7500 - val_loss: 0.5331 - val_accuracy: 0.7448\n",
      "Epoch 410/1000\n",
      "36/36 [==============================] - 0s 634us/step - loss: 0.4963 - accuracy: 0.7448 - val_loss: 0.5329 - val_accuracy: 0.7448\n",
      "Epoch 411/1000\n",
      "36/36 [==============================] - 0s 703us/step - loss: 0.4961 - accuracy: 0.7465 - val_loss: 0.5328 - val_accuracy: 0.7500\n",
      "Epoch 412/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.4959 - accuracy: 0.7448 - val_loss: 0.5326 - val_accuracy: 0.7500\n",
      "Epoch 413/1000\n",
      "36/36 [==============================] - 0s 686us/step - loss: 0.4957 - accuracy: 0.7448 - val_loss: 0.5324 - val_accuracy: 0.7500\n",
      "Epoch 414/1000\n",
      "36/36 [==============================] - 0s 658us/step - loss: 0.4955 - accuracy: 0.7448 - val_loss: 0.5322 - val_accuracy: 0.7500\n",
      "Epoch 415/1000\n",
      "36/36 [==============================] - 0s 697us/step - loss: 0.4953 - accuracy: 0.7431 - val_loss: 0.5320 - val_accuracy: 0.7500\n",
      "Epoch 416/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4951 - accuracy: 0.7431 - val_loss: 0.5318 - val_accuracy: 0.7500\n",
      "Epoch 417/1000\n",
      "36/36 [==============================] - 0s 932us/step - loss: 0.4949 - accuracy: 0.7431 - val_loss: 0.5317 - val_accuracy: 0.7500\n",
      "Epoch 418/1000\n",
      "36/36 [==============================] - 0s 665us/step - loss: 0.4946 - accuracy: 0.7431 - val_loss: 0.5315 - val_accuracy: 0.7500\n",
      "Epoch 419/1000\n",
      "36/36 [==============================] - 0s 677us/step - loss: 0.4945 - accuracy: 0.7378 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
      "Epoch 420/1000\n",
      "36/36 [==============================] - 0s 684us/step - loss: 0.4942 - accuracy: 0.7396 - val_loss: 0.5311 - val_accuracy: 0.7500\n",
      "Epoch 421/1000\n",
      "36/36 [==============================] - 0s 637us/step - loss: 0.4940 - accuracy: 0.7378 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
      "Epoch 422/1000\n",
      "36/36 [==============================] - 0s 659us/step - loss: 0.4938 - accuracy: 0.7396 - val_loss: 0.5307 - val_accuracy: 0.7448\n",
      "Epoch 423/1000\n",
      "36/36 [==============================] - 0s 646us/step - loss: 0.4936 - accuracy: 0.7378 - val_loss: 0.5306 - val_accuracy: 0.7448\n",
      "Epoch 424/1000\n",
      "36/36 [==============================] - 0s 644us/step - loss: 0.4934 - accuracy: 0.7396 - val_loss: 0.5304 - val_accuracy: 0.7448\n",
      "Epoch 425/1000\n",
      "36/36 [==============================] - 0s 633us/step - loss: 0.4931 - accuracy: 0.7413 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
      "Epoch 426/1000\n",
      "36/36 [==============================] - 0s 664us/step - loss: 0.4929 - accuracy: 0.7413 - val_loss: 0.5300 - val_accuracy: 0.7448\n",
      "Epoch 427/1000\n",
      "36/36 [==============================] - 0s 676us/step - loss: 0.4927 - accuracy: 0.7413 - val_loss: 0.5298 - val_accuracy: 0.7448\n",
      "Epoch 428/1000\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.4925 - accuracy: 0.7413 - val_loss: 0.5296 - val_accuracy: 0.7448\n",
      "Epoch 429/1000\n",
      "36/36 [==============================] - 0s 662us/step - loss: 0.4923 - accuracy: 0.7413 - val_loss: 0.5294 - val_accuracy: 0.7500\n",
      "Epoch 430/1000\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.4921 - accuracy: 0.7413 - val_loss: 0.5292 - val_accuracy: 0.7500\n",
      "Epoch 431/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.7413 - val_loss: 0.5290 - val_accuracy: 0.7500\n",
      "Epoch 432/1000\n",
      "36/36 [==============================] - 0s 696us/step - loss: 0.4917 - accuracy: 0.7413 - val_loss: 0.5288 - val_accuracy: 0.7500\n",
      "Epoch 433/1000\n",
      "36/36 [==============================] - 0s 645us/step - loss: 0.4914 - accuracy: 0.7396 - val_loss: 0.5286 - val_accuracy: 0.7552\n",
      "Epoch 434/1000\n",
      "36/36 [==============================] - 0s 649us/step - loss: 0.4912 - accuracy: 0.7413 - val_loss: 0.5284 - val_accuracy: 0.7552\n",
      "Epoch 435/1000\n",
      "36/36 [==============================] - 0s 691us/step - loss: 0.4910 - accuracy: 0.7413 - val_loss: 0.5282 - val_accuracy: 0.7552\n",
      "Epoch 436/1000\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.4908 - accuracy: 0.7431 - val_loss: 0.5280 - val_accuracy: 0.7552\n",
      "Epoch 437/1000\n",
      "36/36 [==============================] - 0s 682us/step - loss: 0.4906 - accuracy: 0.7448 - val_loss: 0.5278 - val_accuracy: 0.7604\n",
      "Epoch 438/1000\n",
      "36/36 [==============================] - 0s 638us/step - loss: 0.4904 - accuracy: 0.7431 - val_loss: 0.5276 - val_accuracy: 0.7604\n",
      "Epoch 439/1000\n",
      "36/36 [==============================] - 0s 658us/step - loss: 0.4902 - accuracy: 0.7465 - val_loss: 0.5275 - val_accuracy: 0.7604\n",
      "Epoch 440/1000\n",
      "36/36 [==============================] - 0s 626us/step - loss: 0.4900 - accuracy: 0.7465 - val_loss: 0.5273 - val_accuracy: 0.7604\n",
      "Epoch 441/1000\n",
      "36/36 [==============================] - 0s 846us/step - loss: 0.4898 - accuracy: 0.7465 - val_loss: 0.5271 - val_accuracy: 0.7604\n",
      "Epoch 442/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4896 - accuracy: 0.7465 - val_loss: 0.5269 - val_accuracy: 0.7604\n",
      "Epoch 443/1000\n",
      "36/36 [==============================] - 0s 623us/step - loss: 0.4894 - accuracy: 0.7483 - val_loss: 0.5268 - val_accuracy: 0.7604\n",
      "Epoch 444/1000\n",
      "36/36 [==============================] - 0s 646us/step - loss: 0.4892 - accuracy: 0.7483 - val_loss: 0.5266 - val_accuracy: 0.7604\n",
      "Epoch 445/1000\n",
      "36/36 [==============================] - 0s 624us/step - loss: 0.4890 - accuracy: 0.7517 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 446/1000\n",
      "36/36 [==============================] - 0s 661us/step - loss: 0.4888 - accuracy: 0.7500 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
      "Epoch 447/1000\n",
      "36/36 [==============================] - 0s 629us/step - loss: 0.4886 - accuracy: 0.7517 - val_loss: 0.5261 - val_accuracy: 0.7604\n",
      "Epoch 448/1000\n",
      "36/36 [==============================] - 0s 649us/step - loss: 0.4884 - accuracy: 0.7517 - val_loss: 0.5260 - val_accuracy: 0.7552\n",
      "Epoch 449/1000\n",
      "36/36 [==============================] - 0s 639us/step - loss: 0.4882 - accuracy: 0.7500 - val_loss: 0.5258 - val_accuracy: 0.7552\n",
      "Epoch 450/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.4881 - accuracy: 0.7500 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
      "Epoch 451/1000\n",
      "36/36 [==============================] - 0s 632us/step - loss: 0.4879 - accuracy: 0.7535 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
      "Epoch 452/1000\n",
      "36/36 [==============================] - 0s 638us/step - loss: 0.4877 - accuracy: 0.7535 - val_loss: 0.5254 - val_accuracy: 0.7552\n",
      "Epoch 453/1000\n",
      "36/36 [==============================] - 0s 657us/step - loss: 0.4875 - accuracy: 0.7535 - val_loss: 0.5252 - val_accuracy: 0.7552\n",
      "Epoch 454/1000\n",
      "36/36 [==============================] - 0s 641us/step - loss: 0.4873 - accuracy: 0.7535 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
      "Epoch 455/1000\n",
      "36/36 [==============================] - 0s 662us/step - loss: 0.4871 - accuracy: 0.7535 - val_loss: 0.5249 - val_accuracy: 0.7604\n",
      "Epoch 456/1000\n",
      "36/36 [==============================] - 0s 634us/step - loss: 0.4869 - accuracy: 0.7517 - val_loss: 0.5248 - val_accuracy: 0.7604\n",
      "Epoch 457/1000\n",
      "36/36 [==============================] - 0s 891us/step - loss: 0.4867 - accuracy: 0.7517 - val_loss: 0.5246 - val_accuracy: 0.7604\n",
      "Epoch 458/1000\n",
      "36/36 [==============================] - 0s 757us/step - loss: 0.4865 - accuracy: 0.7517 - val_loss: 0.5245 - val_accuracy: 0.7604\n",
      "Epoch 459/1000\n",
      "36/36 [==============================] - 0s 636us/step - loss: 0.4864 - accuracy: 0.7535 - val_loss: 0.5243 - val_accuracy: 0.7604\n",
      "Epoch 460/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.4862 - accuracy: 0.7535 - val_loss: 0.5242 - val_accuracy: 0.7604\n",
      "Epoch 461/1000\n",
      "36/36 [==============================] - 0s 625us/step - loss: 0.4860 - accuracy: 0.7535 - val_loss: 0.5240 - val_accuracy: 0.7604\n",
      "Epoch 462/1000\n",
      "36/36 [==============================] - 0s 648us/step - loss: 0.4858 - accuracy: 0.7517 - val_loss: 0.5239 - val_accuracy: 0.7604\n",
      "Epoch 463/1000\n",
      "36/36 [==============================] - 0s 637us/step - loss: 0.4857 - accuracy: 0.7535 - val_loss: 0.5238 - val_accuracy: 0.7604\n",
      "Epoch 464/1000\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.4855 - accuracy: 0.7535 - val_loss: 0.5236 - val_accuracy: 0.7604\n",
      "Epoch 465/1000\n",
      "36/36 [==============================] - 0s 631us/step - loss: 0.4853 - accuracy: 0.7552 - val_loss: 0.5235 - val_accuracy: 0.7604\n",
      "Epoch 466/1000\n",
      "36/36 [==============================] - 0s 630us/step - loss: 0.4851 - accuracy: 0.7552 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
      "Epoch 467/1000\n",
      "36/36 [==============================] - 0s 661us/step - loss: 0.4850 - accuracy: 0.7569 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
      "Epoch 468/1000\n",
      "36/36 [==============================] - 0s 631us/step - loss: 0.4848 - accuracy: 0.7569 - val_loss: 0.5231 - val_accuracy: 0.7604\n",
      "Epoch 469/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.4846 - accuracy: 0.7587 - val_loss: 0.5230 - val_accuracy: 0.7604\n",
      "Epoch 470/1000\n",
      "36/36 [==============================] - 0s 627us/step - loss: 0.4845 - accuracy: 0.7587 - val_loss: 0.5229 - val_accuracy: 0.7604\n",
      "Epoch 471/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.7587 - val_loss: 0.5227 - val_accuracy: 0.7604\n",
      "Epoch 472/1000\n",
      "36/36 [==============================] - 0s 866us/step - loss: 0.4841 - accuracy: 0.7587 - val_loss: 0.5226 - val_accuracy: 0.7656\n",
      "Epoch 473/1000\n",
      "36/36 [==============================] - 0s 624us/step - loss: 0.4840 - accuracy: 0.7587 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
      "Epoch 474/1000\n",
      "36/36 [==============================] - 0s 648us/step - loss: 0.4838 - accuracy: 0.7587 - val_loss: 0.5224 - val_accuracy: 0.7656\n",
      "Epoch 475/1000\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.4837 - accuracy: 0.7587 - val_loss: 0.5223 - val_accuracy: 0.7656\n",
      "Epoch 476/1000\n",
      "36/36 [==============================] - 0s 646us/step - loss: 0.4835 - accuracy: 0.7587 - val_loss: 0.5221 - val_accuracy: 0.7656\n",
      "Epoch 477/1000\n",
      "36/36 [==============================] - 0s 625us/step - loss: 0.4834 - accuracy: 0.7587 - val_loss: 0.5220 - val_accuracy: 0.7656\n",
      "Epoch 478/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.4832 - accuracy: 0.7587 - val_loss: 0.5219 - val_accuracy: 0.7656\n",
      "Epoch 479/1000\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.4831 - accuracy: 0.7587 - val_loss: 0.5218 - val_accuracy: 0.7656\n",
      "Epoch 480/1000\n",
      "36/36 [==============================] - 0s 634us/step - loss: 0.4829 - accuracy: 0.7604 - val_loss: 0.5217 - val_accuracy: 0.7656\n",
      "Epoch 481/1000\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.4828 - accuracy: 0.7587 - val_loss: 0.5215 - val_accuracy: 0.7656\n",
      "Epoch 482/1000\n",
      "36/36 [==============================] - 0s 886us/step - loss: 0.4826 - accuracy: 0.7587 - val_loss: 0.5214 - val_accuracy: 0.7656\n",
      "Epoch 483/1000\n",
      "36/36 [==============================] - 0s 750us/step - loss: 0.4824 - accuracy: 0.7587 - val_loss: 0.5213 - val_accuracy: 0.7656\n",
      "Epoch 484/1000\n",
      "36/36 [==============================] - 0s 645us/step - loss: 0.4823 - accuracy: 0.7587 - val_loss: 0.5212 - val_accuracy: 0.7656\n",
      "Epoch 485/1000\n",
      "36/36 [==============================] - 0s 645us/step - loss: 0.4822 - accuracy: 0.7604 - val_loss: 0.5211 - val_accuracy: 0.7656\n",
      "Epoch 486/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.4820 - accuracy: 0.7604 - val_loss: 0.5209 - val_accuracy: 0.7656\n",
      "Epoch 487/1000\n",
      "36/36 [==============================] - 0s 641us/step - loss: 0.4819 - accuracy: 0.7587 - val_loss: 0.5208 - val_accuracy: 0.7656\n",
      "Epoch 488/1000\n",
      "36/36 [==============================] - 0s 652us/step - loss: 0.4817 - accuracy: 0.7604 - val_loss: 0.5207 - val_accuracy: 0.7656\n",
      "Epoch 489/1000\n",
      "36/36 [==============================] - 0s 634us/step - loss: 0.4816 - accuracy: 0.7622 - val_loss: 0.5206 - val_accuracy: 0.7656\n",
      "Epoch 490/1000\n",
      "36/36 [==============================] - 0s 670us/step - loss: 0.4814 - accuracy: 0.7622 - val_loss: 0.5205 - val_accuracy: 0.7656\n",
      "Epoch 491/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.4813 - accuracy: 0.7622 - val_loss: 0.5204 - val_accuracy: 0.7656\n",
      "Epoch 492/1000\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.4812 - accuracy: 0.7622 - val_loss: 0.5202 - val_accuracy: 0.7656\n",
      "Epoch 493/1000\n",
      "36/36 [==============================] - 0s 644us/step - loss: 0.4811 - accuracy: 0.7622 - val_loss: 0.5201 - val_accuracy: 0.7656\n",
      "Epoch 494/1000\n",
      "36/36 [==============================] - 0s 634us/step - loss: 0.4809 - accuracy: 0.7622 - val_loss: 0.5200 - val_accuracy: 0.7656\n",
      "Epoch 495/1000\n",
      "36/36 [==============================] - 0s 646us/step - loss: 0.4807 - accuracy: 0.7604 - val_loss: 0.5199 - val_accuracy: 0.7656\n",
      "Epoch 496/1000\n",
      "36/36 [==============================] - 0s 644us/step - loss: 0.4806 - accuracy: 0.7604 - val_loss: 0.5198 - val_accuracy: 0.7656\n",
      "Epoch 497/1000\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.4805 - accuracy: 0.7604 - val_loss: 0.5196 - val_accuracy: 0.7656\n",
      "Epoch 498/1000\n",
      "36/36 [==============================] - 0s 652us/step - loss: 0.4804 - accuracy: 0.7604 - val_loss: 0.5195 - val_accuracy: 0.7656\n",
      "Epoch 499/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7604 - val_loss: 0.5194 - val_accuracy: 0.7656\n",
      "Epoch 500/1000\n",
      "36/36 [==============================] - 0s 871us/step - loss: 0.4801 - accuracy: 0.7604 - val_loss: 0.5193 - val_accuracy: 0.7656\n",
      "Epoch 501/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.4800 - accuracy: 0.7604 - val_loss: 0.5191 - val_accuracy: 0.7656\n",
      "Epoch 502/1000\n",
      "36/36 [==============================] - 0s 659us/step - loss: 0.4798 - accuracy: 0.7622 - val_loss: 0.5190 - val_accuracy: 0.7656\n",
      "Epoch 503/1000\n",
      "36/36 [==============================] - 0s 628us/step - loss: 0.4797 - accuracy: 0.7622 - val_loss: 0.5189 - val_accuracy: 0.7656\n",
      "Epoch 504/1000\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.4796 - accuracy: 0.7622 - val_loss: 0.5188 - val_accuracy: 0.7656\n",
      "Epoch 505/1000\n",
      "36/36 [==============================] - 0s 919us/step - loss: 0.4794 - accuracy: 0.7622 - val_loss: 0.5186 - val_accuracy: 0.7656\n",
      "Epoch 506/1000\n",
      "36/36 [==============================] - 0s 756us/step - loss: 0.4793 - accuracy: 0.7587 - val_loss: 0.5185 - val_accuracy: 0.7656\n",
      "Epoch 507/1000\n",
      "36/36 [==============================] - 0s 656us/step - loss: 0.4792 - accuracy: 0.7622 - val_loss: 0.5184 - val_accuracy: 0.7656\n",
      "Epoch 508/1000\n",
      "36/36 [==============================] - 0s 634us/step - loss: 0.4791 - accuracy: 0.7587 - val_loss: 0.5183 - val_accuracy: 0.7656\n",
      "Epoch 509/1000\n",
      "36/36 [==============================] - 0s 648us/step - loss: 0.4789 - accuracy: 0.7569 - val_loss: 0.5181 - val_accuracy: 0.7656\n",
      "Epoch 510/1000\n",
      "36/36 [==============================] - 0s 625us/step - loss: 0.4788 - accuracy: 0.7569 - val_loss: 0.5180 - val_accuracy: 0.7656\n",
      "Epoch 511/1000\n",
      "36/36 [==============================] - 0s 644us/step - loss: 0.4787 - accuracy: 0.7587 - val_loss: 0.5179 - val_accuracy: 0.7656\n",
      "Epoch 512/1000\n",
      "36/36 [==============================] - 0s 637us/step - loss: 0.4786 - accuracy: 0.7604 - val_loss: 0.5178 - val_accuracy: 0.7656\n",
      "Epoch 513/1000\n",
      "36/36 [==============================] - 0s 646us/step - loss: 0.4784 - accuracy: 0.7587 - val_loss: 0.5177 - val_accuracy: 0.7656\n",
      "Epoch 514/1000\n",
      "36/36 [==============================] - 0s 638us/step - loss: 0.4783 - accuracy: 0.7587 - val_loss: 0.5176 - val_accuracy: 0.7656\n",
      "Epoch 515/1000\n",
      "36/36 [==============================] - 0s 634us/step - loss: 0.4782 - accuracy: 0.7604 - val_loss: 0.5175 - val_accuracy: 0.7656\n",
      "Epoch 516/1000\n",
      "36/36 [==============================] - 0s 637us/step - loss: 0.4781 - accuracy: 0.7587 - val_loss: 0.5174 - val_accuracy: 0.7656\n",
      "Epoch 517/1000\n",
      "36/36 [==============================] - 0s 638us/step - loss: 0.4780 - accuracy: 0.7587 - val_loss: 0.5173 - val_accuracy: 0.7656\n",
      "Epoch 518/1000\n",
      "36/36 [==============================] - 0s 658us/step - loss: 0.4779 - accuracy: 0.7587 - val_loss: 0.5172 - val_accuracy: 0.7656\n",
      "Epoch 519/1000\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.4777 - accuracy: 0.7587 - val_loss: 0.5171 - val_accuracy: 0.7656\n",
      "Epoch 520/1000\n",
      "36/36 [==============================] - 0s 656us/step - loss: 0.4776 - accuracy: 0.7587 - val_loss: 0.5170 - val_accuracy: 0.7656\n",
      "Epoch 521/1000\n",
      "36/36 [==============================] - 0s 635us/step - loss: 0.4775 - accuracy: 0.7587 - val_loss: 0.5169 - val_accuracy: 0.7656\n",
      "Epoch 522/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4774 - accuracy: 0.7587 - val_loss: 0.5169 - val_accuracy: 0.7656\n",
      "Epoch 523/1000\n",
      "36/36 [==============================] - 0s 753us/step - loss: 0.4773 - accuracy: 0.7587 - val_loss: 0.5168 - val_accuracy: 0.7656\n",
      "Epoch 524/1000\n",
      "36/36 [==============================] - 0s 634us/step - loss: 0.4771 - accuracy: 0.7587 - val_loss: 0.5167 - val_accuracy: 0.7656\n",
      "Epoch 525/1000\n",
      "36/36 [==============================] - 0s 657us/step - loss: 0.4770 - accuracy: 0.7587 - val_loss: 0.5166 - val_accuracy: 0.7656\n",
      "Epoch 526/1000\n",
      "36/36 [==============================] - 0s 628us/step - loss: 0.4769 - accuracy: 0.7587 - val_loss: 0.5165 - val_accuracy: 0.7656\n",
      "Epoch 527/1000\n",
      "36/36 [==============================] - 0s 645us/step - loss: 0.4768 - accuracy: 0.7604 - val_loss: 0.5164 - val_accuracy: 0.7656\n",
      "Epoch 528/1000\n",
      "36/36 [==============================] - 0s 950us/step - loss: 0.4767 - accuracy: 0.7587 - val_loss: 0.5163 - val_accuracy: 0.7656\n",
      "Epoch 529/1000\n",
      "36/36 [==============================] - 0s 762us/step - loss: 0.4766 - accuracy: 0.7587 - val_loss: 0.5162 - val_accuracy: 0.7708\n",
      "Epoch 530/1000\n",
      "36/36 [==============================] - 0s 662us/step - loss: 0.4765 - accuracy: 0.7622 - val_loss: 0.5161 - val_accuracy: 0.7708\n",
      "Epoch 531/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.4763 - accuracy: 0.7622 - val_loss: 0.5160 - val_accuracy: 0.7708\n",
      "Epoch 532/1000\n",
      "36/36 [==============================] - 0s 656us/step - loss: 0.4763 - accuracy: 0.7639 - val_loss: 0.5159 - val_accuracy: 0.7708\n",
      "Epoch 533/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.4761 - accuracy: 0.7622 - val_loss: 0.5158 - val_accuracy: 0.7708\n",
      "Epoch 534/1000\n",
      "36/36 [==============================] - 0s 658us/step - loss: 0.4760 - accuracy: 0.7639 - val_loss: 0.5157 - val_accuracy: 0.7708\n",
      "Epoch 535/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.4759 - accuracy: 0.7639 - val_loss: 0.5157 - val_accuracy: 0.7656\n",
      "Epoch 536/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.4758 - accuracy: 0.7639 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
      "Epoch 537/1000\n",
      "36/36 [==============================] - 0s 671us/step - loss: 0.4757 - accuracy: 0.7639 - val_loss: 0.5155 - val_accuracy: 0.7656\n",
      "Epoch 538/1000\n",
      "36/36 [==============================] - 0s 629us/step - loss: 0.4756 - accuracy: 0.7622 - val_loss: 0.5154 - val_accuracy: 0.7656\n",
      "Epoch 539/1000\n",
      "36/36 [==============================] - 0s 657us/step - loss: 0.4755 - accuracy: 0.7639 - val_loss: 0.5153 - val_accuracy: 0.7656\n",
      "Epoch 540/1000\n",
      "36/36 [==============================] - 0s 636us/step - loss: 0.4754 - accuracy: 0.7639 - val_loss: 0.5152 - val_accuracy: 0.7656\n",
      "Epoch 541/1000\n",
      "36/36 [==============================] - 0s 655us/step - loss: 0.4753 - accuracy: 0.7622 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
      "Epoch 542/1000\n",
      "36/36 [==============================] - 0s 634us/step - loss: 0.4752 - accuracy: 0.7639 - val_loss: 0.5150 - val_accuracy: 0.7656\n",
      "Epoch 543/1000\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.4751 - accuracy: 0.7639 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
      "Epoch 544/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.4750 - accuracy: 0.7639 - val_loss: 0.5148 - val_accuracy: 0.7656\n",
      "Epoch 545/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4749 - accuracy: 0.7656 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
      "Epoch 546/1000\n",
      "36/36 [==============================] - 0s 855us/step - loss: 0.4748 - accuracy: 0.7656 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
      "Epoch 547/1000\n",
      "36/36 [==============================] - 0s 633us/step - loss: 0.4747 - accuracy: 0.7656 - val_loss: 0.5146 - val_accuracy: 0.7656\n",
      "Epoch 548/1000\n",
      "36/36 [==============================] - 0s 652us/step - loss: 0.4746 - accuracy: 0.7639 - val_loss: 0.5145 - val_accuracy: 0.7656\n",
      "Epoch 549/1000\n",
      "36/36 [==============================] - 0s 636us/step - loss: 0.4745 - accuracy: 0.7674 - val_loss: 0.5144 - val_accuracy: 0.7656\n",
      "Epoch 550/1000\n",
      "36/36 [==============================] - 0s 657us/step - loss: 0.4744 - accuracy: 0.7656 - val_loss: 0.5143 - val_accuracy: 0.7656\n",
      "Epoch 551/1000\n",
      "36/36 [==============================] - 0s 899us/step - loss: 0.4743 - accuracy: 0.7674 - val_loss: 0.5142 - val_accuracy: 0.7656\n",
      "Epoch 552/1000\n",
      "36/36 [==============================] - 0s 755us/step - loss: 0.4742 - accuracy: 0.7674 - val_loss: 0.5141 - val_accuracy: 0.7656\n",
      "Epoch 553/1000\n",
      "36/36 [==============================] - 0s 655us/step - loss: 0.4741 - accuracy: 0.7674 - val_loss: 0.5141 - val_accuracy: 0.7656\n",
      "Epoch 554/1000\n",
      "36/36 [==============================] - 0s 628us/step - loss: 0.4740 - accuracy: 0.7656 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
      "Epoch 555/1000\n",
      "36/36 [==============================] - 0s 657us/step - loss: 0.4739 - accuracy: 0.7674 - val_loss: 0.5139 - val_accuracy: 0.7656\n",
      "Epoch 556/1000\n",
      "36/36 [==============================] - 0s 641us/step - loss: 0.4738 - accuracy: 0.7656 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 557/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.4737 - accuracy: 0.7656 - val_loss: 0.5137 - val_accuracy: 0.7656\n",
      "Epoch 558/1000\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.4736 - accuracy: 0.7656 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
      "Epoch 559/1000\n",
      "36/36 [==============================] - 0s 659us/step - loss: 0.4735 - accuracy: 0.7639 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 560/1000\n",
      "36/36 [==============================] - 0s 667us/step - loss: 0.4734 - accuracy: 0.7656 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 561/1000\n",
      "36/36 [==============================] - 0s 646us/step - loss: 0.4733 - accuracy: 0.7656 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 562/1000\n",
      "36/36 [==============================] - 0s 644us/step - loss: 0.4732 - accuracy: 0.7656 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 563/1000\n",
      "36/36 [==============================] - 0s 637us/step - loss: 0.4731 - accuracy: 0.7656 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 564/1000\n",
      "36/36 [==============================] - 0s 649us/step - loss: 0.4730 - accuracy: 0.7656 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 565/1000\n",
      "36/36 [==============================] - 0s 639us/step - loss: 0.4729 - accuracy: 0.7656 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 566/1000\n",
      "36/36 [==============================] - 0s 656us/step - loss: 0.4728 - accuracy: 0.7656 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 567/1000\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.4728 - accuracy: 0.7674 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 568/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.4726 - accuracy: 0.7656 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
      "Epoch 569/1000\n",
      "36/36 [==============================] - 0s 635us/step - loss: 0.4725 - accuracy: 0.7674 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 570/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.4724 - accuracy: 0.7656 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 571/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7674 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
      "Epoch 572/1000\n",
      "36/36 [==============================] - 0s 832us/step - loss: 0.4722 - accuracy: 0.7674 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
      "Epoch 573/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.4722 - accuracy: 0.7674 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
      "Epoch 574/1000\n",
      "36/36 [==============================] - 0s 624us/step - loss: 0.4720 - accuracy: 0.7656 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
      "Epoch 575/1000\n",
      "36/36 [==============================] - 0s 652us/step - loss: 0.4720 - accuracy: 0.7674 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
      "Epoch 576/1000\n",
      "36/36 [==============================] - 0s 648us/step - loss: 0.4719 - accuracy: 0.7656 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
      "Epoch 577/1000\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.4718 - accuracy: 0.7674 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
      "Epoch 578/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.4717 - accuracy: 0.7674 - val_loss: 0.5119 - val_accuracy: 0.7656\n",
      "Epoch 579/1000\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.4716 - accuracy: 0.7674 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
      "Epoch 580/1000\n",
      "36/36 [==============================] - 0s 645us/step - loss: 0.4715 - accuracy: 0.7656 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
      "Epoch 581/1000\n",
      "36/36 [==============================] - 0s 635us/step - loss: 0.4714 - accuracy: 0.7674 - val_loss: 0.5117 - val_accuracy: 0.7656\n",
      "Epoch 582/1000\n",
      "36/36 [==============================] - 0s 652us/step - loss: 0.4713 - accuracy: 0.7656 - val_loss: 0.5116 - val_accuracy: 0.7656\n",
      "Epoch 583/1000\n",
      "36/36 [==============================] - 0s 655us/step - loss: 0.4713 - accuracy: 0.7656 - val_loss: 0.5115 - val_accuracy: 0.7656\n",
      "Epoch 584/1000\n",
      "36/36 [==============================] - 0s 668us/step - loss: 0.4712 - accuracy: 0.7674 - val_loss: 0.5114 - val_accuracy: 0.7656\n",
      "Epoch 585/1000\n",
      "36/36 [==============================] - 0s 639us/step - loss: 0.4711 - accuracy: 0.7674 - val_loss: 0.5113 - val_accuracy: 0.7656\n",
      "Epoch 586/1000\n",
      "36/36 [==============================] - 0s 648us/step - loss: 0.4710 - accuracy: 0.7674 - val_loss: 0.5112 - val_accuracy: 0.7656\n",
      "Epoch 587/1000\n",
      "36/36 [==============================] - 0s 633us/step - loss: 0.4709 - accuracy: 0.7656 - val_loss: 0.5112 - val_accuracy: 0.7656\n",
      "Epoch 588/1000\n",
      "36/36 [==============================] - 0s 661us/step - loss: 0.4708 - accuracy: 0.7656 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
      "Epoch 589/1000\n",
      "36/36 [==============================] - 0s 637us/step - loss: 0.4707 - accuracy: 0.7674 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 590/1000\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.4707 - accuracy: 0.7674 - val_loss: 0.5109 - val_accuracy: 0.7708\n",
      "Epoch 591/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.4706 - accuracy: 0.7674 - val_loss: 0.5108 - val_accuracy: 0.7708\n",
      "Epoch 592/1000\n",
      "36/36 [==============================] - 0s 868us/step - loss: 0.4705 - accuracy: 0.7674 - val_loss: 0.5107 - val_accuracy: 0.7708\n",
      "Epoch 593/1000\n",
      "36/36 [==============================] - 0s 759us/step - loss: 0.4704 - accuracy: 0.7656 - val_loss: 0.5106 - val_accuracy: 0.7708\n",
      "Epoch 594/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4703 - accuracy: 0.7674 - val_loss: 0.5105 - val_accuracy: 0.7708\n",
      "Epoch 595/1000\n",
      "36/36 [==============================] - 0s 873us/step - loss: 0.4702 - accuracy: 0.7674 - val_loss: 0.5104 - val_accuracy: 0.7708\n",
      "Epoch 596/1000\n",
      "36/36 [==============================] - 0s 650us/step - loss: 0.4701 - accuracy: 0.7674 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 597/1000\n",
      "36/36 [==============================] - 0s 631us/step - loss: 0.4701 - accuracy: 0.7639 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 598/1000\n",
      "36/36 [==============================] - 0s 650us/step - loss: 0.4700 - accuracy: 0.7656 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 599/1000\n",
      "36/36 [==============================] - 0s 631us/step - loss: 0.4699 - accuracy: 0.7656 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 600/1000\n",
      "36/36 [==============================] - 0s 649us/step - loss: 0.4698 - accuracy: 0.7656 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 601/1000\n",
      "36/36 [==============================] - 0s 660us/step - loss: 0.4697 - accuracy: 0.7691 - val_loss: 0.5099 - val_accuracy: 0.7760\n",
      "Epoch 602/1000\n",
      "36/36 [==============================] - 0s 641us/step - loss: 0.4696 - accuracy: 0.7656 - val_loss: 0.5098 - val_accuracy: 0.7760\n",
      "Epoch 603/1000\n",
      "36/36 [==============================] - 0s 636us/step - loss: 0.4695 - accuracy: 0.7674 - val_loss: 0.5097 - val_accuracy: 0.7760\n",
      "Epoch 604/1000\n",
      "36/36 [==============================] - 0s 635us/step - loss: 0.4695 - accuracy: 0.7639 - val_loss: 0.5096 - val_accuracy: 0.7760\n",
      "Epoch 605/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.4693 - accuracy: 0.7656 - val_loss: 0.5095 - val_accuracy: 0.7760\n",
      "Epoch 606/1000\n",
      "36/36 [==============================] - 0s 634us/step - loss: 0.4693 - accuracy: 0.7656 - val_loss: 0.5094 - val_accuracy: 0.7760\n",
      "Epoch 607/1000\n",
      "36/36 [==============================] - 0s 670us/step - loss: 0.4692 - accuracy: 0.7656 - val_loss: 0.5093 - val_accuracy: 0.7760\n",
      "Epoch 608/1000\n",
      "36/36 [==============================] - 0s 626us/step - loss: 0.4691 - accuracy: 0.7656 - val_loss: 0.5092 - val_accuracy: 0.7760\n",
      "Epoch 609/1000\n",
      "36/36 [==============================] - 0s 660us/step - loss: 0.4690 - accuracy: 0.7656 - val_loss: 0.5091 - val_accuracy: 0.7760\n",
      "Epoch 610/1000\n",
      "36/36 [==============================] - 0s 635us/step - loss: 0.4689 - accuracy: 0.7656 - val_loss: 0.5090 - val_accuracy: 0.7760\n",
      "Epoch 611/1000\n",
      "36/36 [==============================] - 0s 646us/step - loss: 0.4688 - accuracy: 0.7674 - val_loss: 0.5089 - val_accuracy: 0.7760\n",
      "Epoch 612/1000\n",
      "36/36 [==============================] - 0s 842us/step - loss: 0.4687 - accuracy: 0.7656 - val_loss: 0.5088 - val_accuracy: 0.7760\n",
      "Epoch 613/1000\n",
      "36/36 [==============================] - 0s 782us/step - loss: 0.4687 - accuracy: 0.7656 - val_loss: 0.5087 - val_accuracy: 0.7760\n",
      "Epoch 614/1000\n",
      "36/36 [==============================] - 0s 666us/step - loss: 0.4685 - accuracy: 0.7674 - val_loss: 0.5086 - val_accuracy: 0.7760\n",
      "Epoch 615/1000\n",
      "36/36 [==============================] - 0s 635us/step - loss: 0.4685 - accuracy: 0.7656 - val_loss: 0.5085 - val_accuracy: 0.7760\n",
      "Epoch 616/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.7674 - val_loss: 0.5085 - val_accuracy: 0.7760\n",
      "Epoch 617/1000\n",
      "36/36 [==============================] - 0s 870us/step - loss: 0.4683 - accuracy: 0.7674 - val_loss: 0.5084 - val_accuracy: 0.7760\n",
      "Epoch 618/1000\n",
      "36/36 [==============================] - 0s 658us/step - loss: 0.4682 - accuracy: 0.7674 - val_loss: 0.5083 - val_accuracy: 0.7760\n",
      "Epoch 619/1000\n",
      "36/36 [==============================] - 0s 686us/step - loss: 0.4681 - accuracy: 0.7674 - val_loss: 0.5082 - val_accuracy: 0.7760\n",
      "Epoch 620/1000\n",
      "36/36 [==============================] - 0s 677us/step - loss: 0.4680 - accuracy: 0.7674 - val_loss: 0.5081 - val_accuracy: 0.7760\n",
      "Epoch 621/1000\n",
      "36/36 [==============================] - 0s 679us/step - loss: 0.4679 - accuracy: 0.7674 - val_loss: 0.5080 - val_accuracy: 0.7760\n",
      "Epoch 622/1000\n",
      "36/36 [==============================] - 0s 692us/step - loss: 0.4678 - accuracy: 0.7674 - val_loss: 0.5079 - val_accuracy: 0.7760\n",
      "Epoch 623/1000\n",
      "36/36 [==============================] - 0s 677us/step - loss: 0.4678 - accuracy: 0.7674 - val_loss: 0.5078 - val_accuracy: 0.7760\n",
      "Epoch 624/1000\n",
      "36/36 [==============================] - 0s 676us/step - loss: 0.4677 - accuracy: 0.7674 - val_loss: 0.5078 - val_accuracy: 0.7760\n",
      "Epoch 625/1000\n",
      "36/36 [==============================] - 0s 668us/step - loss: 0.4676 - accuracy: 0.7674 - val_loss: 0.5077 - val_accuracy: 0.7760\n",
      "Epoch 626/1000\n",
      "36/36 [==============================] - 0s 689us/step - loss: 0.4675 - accuracy: 0.7674 - val_loss: 0.5076 - val_accuracy: 0.7760\n",
      "Epoch 627/1000\n",
      "36/36 [==============================] - 0s 677us/step - loss: 0.4674 - accuracy: 0.7674 - val_loss: 0.5075 - val_accuracy: 0.7760\n",
      "Epoch 628/1000\n",
      "36/36 [==============================] - 0s 695us/step - loss: 0.4673 - accuracy: 0.7656 - val_loss: 0.5075 - val_accuracy: 0.7760\n",
      "Epoch 629/1000\n",
      "36/36 [==============================] - 0s 662us/step - loss: 0.4672 - accuracy: 0.7674 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
      "Epoch 630/1000\n",
      "36/36 [==============================] - 0s 709us/step - loss: 0.4671 - accuracy: 0.7674 - val_loss: 0.5073 - val_accuracy: 0.7760\n",
      "Epoch 631/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.4671 - accuracy: 0.7674 - val_loss: 0.5072 - val_accuracy: 0.7760\n",
      "Epoch 632/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4670 - accuracy: 0.7656 - val_loss: 0.5071 - val_accuracy: 0.7760\n",
      "Epoch 633/1000\n",
      "36/36 [==============================] - 0s 645us/step - loss: 0.4669 - accuracy: 0.7674 - val_loss: 0.5070 - val_accuracy: 0.7760\n",
      "Epoch 634/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.4668 - accuracy: 0.7674 - val_loss: 0.5070 - val_accuracy: 0.7760\n",
      "Epoch 635/1000\n",
      "36/36 [==============================] - 0s 864us/step - loss: 0.4667 - accuracy: 0.7674 - val_loss: 0.5069 - val_accuracy: 0.7760\n",
      "Epoch 636/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4667 - accuracy: 0.7656 - val_loss: 0.5068 - val_accuracy: 0.7760\n",
      "Epoch 637/1000\n",
      "36/36 [==============================] - 0s 634us/step - loss: 0.4666 - accuracy: 0.7656 - val_loss: 0.5068 - val_accuracy: 0.7760\n",
      "Epoch 638/1000\n",
      "36/36 [==============================] - 0s 666us/step - loss: 0.4665 - accuracy: 0.7656 - val_loss: 0.5067 - val_accuracy: 0.7760\n",
      "Epoch 639/1000\n",
      "36/36 [==============================] - 0s 645us/step - loss: 0.4664 - accuracy: 0.7656 - val_loss: 0.5066 - val_accuracy: 0.7760\n",
      "Epoch 640/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.4664 - accuracy: 0.7656 - val_loss: 0.5065 - val_accuracy: 0.7760\n",
      "Epoch 641/1000\n",
      "36/36 [==============================] - 0s 641us/step - loss: 0.4663 - accuracy: 0.7674 - val_loss: 0.5065 - val_accuracy: 0.7760\n",
      "Epoch 642/1000\n",
      "36/36 [==============================] - 0s 659us/step - loss: 0.4662 - accuracy: 0.7674 - val_loss: 0.5064 - val_accuracy: 0.7760\n",
      "Epoch 643/1000\n",
      "36/36 [==============================] - 0s 644us/step - loss: 0.4661 - accuracy: 0.7691 - val_loss: 0.5064 - val_accuracy: 0.7760\n",
      "Epoch 644/1000\n",
      "36/36 [==============================] - 0s 645us/step - loss: 0.4661 - accuracy: 0.7691 - val_loss: 0.5063 - val_accuracy: 0.7760\n",
      "Epoch 645/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.4660 - accuracy: 0.7691 - val_loss: 0.5062 - val_accuracy: 0.7760\n",
      "Epoch 646/1000\n",
      "36/36 [==============================] - 0s 625us/step - loss: 0.4659 - accuracy: 0.7656 - val_loss: 0.5062 - val_accuracy: 0.7760\n",
      "Epoch 647/1000\n",
      "36/36 [==============================] - 0s 664us/step - loss: 0.4659 - accuracy: 0.7674 - val_loss: 0.5061 - val_accuracy: 0.7760\n",
      "Epoch 648/1000\n",
      "36/36 [==============================] - 0s 646us/step - loss: 0.4658 - accuracy: 0.7674 - val_loss: 0.5061 - val_accuracy: 0.7760\n",
      "Epoch 649/1000\n",
      "36/36 [==============================] - 0s 639us/step - loss: 0.4657 - accuracy: 0.7691 - val_loss: 0.5060 - val_accuracy: 0.7760\n",
      "Epoch 650/1000\n",
      "36/36 [==============================] - 0s 635us/step - loss: 0.4656 - accuracy: 0.7656 - val_loss: 0.5060 - val_accuracy: 0.7760\n",
      "Epoch 651/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.4656 - accuracy: 0.7674 - val_loss: 0.5059 - val_accuracy: 0.7760\n",
      "Epoch 652/1000\n",
      "36/36 [==============================] - 0s 877us/step - loss: 0.4655 - accuracy: 0.7656 - val_loss: 0.5058 - val_accuracy: 0.7760\n",
      "Epoch 653/1000\n",
      "36/36 [==============================] - 0s 773us/step - loss: 0.4654 - accuracy: 0.7656 - val_loss: 0.5058 - val_accuracy: 0.7760\n",
      "Epoch 654/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.7674 - val_loss: 0.5057 - val_accuracy: 0.7760\n",
      "Epoch 655/1000\n",
      "36/36 [==============================] - 0s 852us/step - loss: 0.4653 - accuracy: 0.7656 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
      "Epoch 656/1000\n",
      "36/36 [==============================] - 0s 649us/step - loss: 0.4652 - accuracy: 0.7656 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
      "Epoch 657/1000\n",
      "36/36 [==============================] - 0s 638us/step - loss: 0.4651 - accuracy: 0.7656 - val_loss: 0.5055 - val_accuracy: 0.7760\n",
      "Epoch 658/1000\n",
      "36/36 [==============================] - 0s 665us/step - loss: 0.4650 - accuracy: 0.7656 - val_loss: 0.5055 - val_accuracy: 0.7760\n",
      "Epoch 659/1000\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.4650 - accuracy: 0.7656 - val_loss: 0.5054 - val_accuracy: 0.7760\n",
      "Epoch 660/1000\n",
      "36/36 [==============================] - 0s 661us/step - loss: 0.4649 - accuracy: 0.7656 - val_loss: 0.5053 - val_accuracy: 0.7760\n",
      "Epoch 661/1000\n",
      "36/36 [==============================] - 0s 650us/step - loss: 0.4648 - accuracy: 0.7656 - val_loss: 0.5053 - val_accuracy: 0.7760\n",
      "Epoch 662/1000\n",
      "36/36 [==============================] - 0s 648us/step - loss: 0.4648 - accuracy: 0.7674 - val_loss: 0.5052 - val_accuracy: 0.7760\n",
      "Epoch 663/1000\n",
      "36/36 [==============================] - 0s 675us/step - loss: 0.4647 - accuracy: 0.7674 - val_loss: 0.5052 - val_accuracy: 0.7760\n",
      "Epoch 664/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.4646 - accuracy: 0.7656 - val_loss: 0.5051 - val_accuracy: 0.7760\n",
      "Epoch 665/1000\n",
      "36/36 [==============================] - 0s 686us/step - loss: 0.4646 - accuracy: 0.7656 - val_loss: 0.5051 - val_accuracy: 0.7760\n",
      "Epoch 666/1000\n",
      "36/36 [==============================] - 0s 648us/step - loss: 0.4644 - accuracy: 0.7656 - val_loss: 0.5050 - val_accuracy: 0.7760\n",
      "Epoch 667/1000\n",
      "36/36 [==============================] - 0s 675us/step - loss: 0.4644 - accuracy: 0.7691 - val_loss: 0.5050 - val_accuracy: 0.7760\n",
      "Epoch 668/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.4643 - accuracy: 0.7674 - val_loss: 0.5049 - val_accuracy: 0.7760\n",
      "Epoch 669/1000\n",
      "36/36 [==============================] - 0s 661us/step - loss: 0.4642 - accuracy: 0.7674 - val_loss: 0.5049 - val_accuracy: 0.7760\n",
      "Epoch 670/1000\n",
      "36/36 [==============================] - 0s 910us/step - loss: 0.4642 - accuracy: 0.7656 - val_loss: 0.5048 - val_accuracy: 0.7760\n",
      "Epoch 671/1000\n",
      "36/36 [==============================] - 0s 763us/step - loss: 0.4641 - accuracy: 0.7691 - val_loss: 0.5047 - val_accuracy: 0.7760\n",
      "Epoch 672/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 0.7674 - val_loss: 0.5047 - val_accuracy: 0.7760\n",
      "Epoch 673/1000\n",
      "36/36 [==============================] - 0s 970us/step - loss: 0.4639 - accuracy: 0.7691 - val_loss: 0.5046 - val_accuracy: 0.7760\n",
      "Epoch 674/1000\n",
      "36/36 [==============================] - 0s 650us/step - loss: 0.4639 - accuracy: 0.7674 - val_loss: 0.5045 - val_accuracy: 0.7760\n",
      "Epoch 675/1000\n",
      "36/36 [==============================] - 0s 637us/step - loss: 0.4638 - accuracy: 0.7691 - val_loss: 0.5045 - val_accuracy: 0.7760\n",
      "Epoch 676/1000\n",
      "36/36 [==============================] - 0s 655us/step - loss: 0.4637 - accuracy: 0.7674 - val_loss: 0.5044 - val_accuracy: 0.7760\n",
      "Epoch 677/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.4636 - accuracy: 0.7691 - val_loss: 0.5043 - val_accuracy: 0.7760\n",
      "Epoch 678/1000\n",
      "36/36 [==============================] - 0s 649us/step - loss: 0.4635 - accuracy: 0.7691 - val_loss: 0.5043 - val_accuracy: 0.7760\n",
      "Epoch 679/1000\n",
      "36/36 [==============================] - 0s 638us/step - loss: 0.4634 - accuracy: 0.7674 - val_loss: 0.5042 - val_accuracy: 0.7760\n",
      "Epoch 680/1000\n",
      "36/36 [==============================] - 0s 631us/step - loss: 0.4633 - accuracy: 0.7674 - val_loss: 0.5042 - val_accuracy: 0.7760\n",
      "Epoch 681/1000\n",
      "36/36 [==============================] - 0s 650us/step - loss: 0.4633 - accuracy: 0.7674 - val_loss: 0.5041 - val_accuracy: 0.7760\n",
      "Epoch 682/1000\n",
      "36/36 [==============================] - 0s 644us/step - loss: 0.4632 - accuracy: 0.7691 - val_loss: 0.5041 - val_accuracy: 0.7760\n",
      "Epoch 683/1000\n",
      "36/36 [==============================] - 0s 644us/step - loss: 0.4631 - accuracy: 0.7708 - val_loss: 0.5040 - val_accuracy: 0.7760\n",
      "Epoch 684/1000\n",
      "36/36 [==============================] - 0s 633us/step - loss: 0.4631 - accuracy: 0.7691 - val_loss: 0.5040 - val_accuracy: 0.7760\n",
      "Epoch 685/1000\n",
      "36/36 [==============================] - 0s 646us/step - loss: 0.4630 - accuracy: 0.7691 - val_loss: 0.5039 - val_accuracy: 0.7760\n",
      "Epoch 686/1000\n",
      "36/36 [==============================] - 0s 648us/step - loss: 0.4629 - accuracy: 0.7691 - val_loss: 0.5039 - val_accuracy: 0.7760\n",
      "Epoch 687/1000\n",
      "36/36 [==============================] - 0s 878us/step - loss: 0.4628 - accuracy: 0.7691 - val_loss: 0.5038 - val_accuracy: 0.7760\n",
      "Epoch 688/1000\n",
      "36/36 [==============================] - 0s 761us/step - loss: 0.4628 - accuracy: 0.7691 - val_loss: 0.5038 - val_accuracy: 0.7760\n",
      "Epoch 689/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.4627 - accuracy: 0.7708 - val_loss: 0.5037 - val_accuracy: 0.7760\n",
      "Epoch 690/1000\n",
      "36/36 [==============================] - 0s 660us/step - loss: 0.4626 - accuracy: 0.7674 - val_loss: 0.5037 - val_accuracy: 0.7760\n",
      "Epoch 691/1000\n",
      "36/36 [==============================] - 0s 637us/step - loss: 0.4625 - accuracy: 0.7674 - val_loss: 0.5036 - val_accuracy: 0.7760\n",
      "Epoch 692/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7691 - val_loss: 0.5036 - val_accuracy: 0.7760\n",
      "Epoch 693/1000\n",
      "36/36 [==============================] - 0s 891us/step - loss: 0.4624 - accuracy: 0.7691 - val_loss: 0.5035 - val_accuracy: 0.7760\n",
      "Epoch 694/1000\n",
      "36/36 [==============================] - 0s 641us/step - loss: 0.4623 - accuracy: 0.7691 - val_loss: 0.5035 - val_accuracy: 0.7760\n",
      "Epoch 695/1000\n",
      "36/36 [==============================] - 0s 678us/step - loss: 0.4623 - accuracy: 0.7691 - val_loss: 0.5035 - val_accuracy: 0.7760\n",
      "Epoch 696/1000\n",
      "36/36 [==============================] - 0s 651us/step - loss: 0.4622 - accuracy: 0.7691 - val_loss: 0.5034 - val_accuracy: 0.7760\n",
      "Epoch 697/1000\n",
      "36/36 [==============================] - 0s 661us/step - loss: 0.4622 - accuracy: 0.7691 - val_loss: 0.5034 - val_accuracy: 0.7760\n",
      "Epoch 698/1000\n",
      "36/36 [==============================] - 0s 648us/step - loss: 0.4621 - accuracy: 0.7691 - val_loss: 0.5033 - val_accuracy: 0.7760\n",
      "Epoch 699/1000\n",
      "36/36 [==============================] - 0s 670us/step - loss: 0.4620 - accuracy: 0.7691 - val_loss: 0.5033 - val_accuracy: 0.7760\n",
      "Epoch 700/1000\n",
      "36/36 [==============================] - 0s 641us/step - loss: 0.4619 - accuracy: 0.7691 - val_loss: 0.5032 - val_accuracy: 0.7760\n",
      "Epoch 701/1000\n",
      "36/36 [==============================] - 0s 670us/step - loss: 0.4619 - accuracy: 0.7691 - val_loss: 0.5032 - val_accuracy: 0.7760\n",
      "Epoch 702/1000\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.4618 - accuracy: 0.7691 - val_loss: 0.5032 - val_accuracy: 0.7760\n",
      "Epoch 703/1000\n",
      "36/36 [==============================] - 0s 657us/step - loss: 0.4617 - accuracy: 0.7691 - val_loss: 0.5031 - val_accuracy: 0.7760\n",
      "Epoch 704/1000\n",
      "36/36 [==============================] - 0s 966us/step - loss: 0.4616 - accuracy: 0.7691 - val_loss: 0.5031 - val_accuracy: 0.7760\n",
      "Epoch 705/1000\n",
      "36/36 [==============================] - 0s 742us/step - loss: 0.4616 - accuracy: 0.7674 - val_loss: 0.5030 - val_accuracy: 0.7760\n",
      "Epoch 706/1000\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.4615 - accuracy: 0.7674 - val_loss: 0.5030 - val_accuracy: 0.7760\n",
      "Epoch 707/1000\n",
      "36/36 [==============================] - 0s 631us/step - loss: 0.4614 - accuracy: 0.7674 - val_loss: 0.5030 - val_accuracy: 0.7760\n",
      "Epoch 708/1000\n",
      "36/36 [==============================] - 0s 659us/step - loss: 0.4613 - accuracy: 0.7674 - val_loss: 0.5029 - val_accuracy: 0.7760\n",
      "Epoch 709/1000\n",
      "36/36 [==============================] - 0s 648us/step - loss: 0.4613 - accuracy: 0.7674 - val_loss: 0.5029 - val_accuracy: 0.7760\n",
      "Epoch 710/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.4612 - accuracy: 0.7674 - val_loss: 0.5029 - val_accuracy: 0.7760\n",
      "Epoch 711/1000\n",
      "36/36 [==============================] - 0s 636us/step - loss: 0.4612 - accuracy: 0.7674 - val_loss: 0.5028 - val_accuracy: 0.7760\n",
      "Epoch 712/1000\n",
      "36/36 [==============================] - 0s 660us/step - loss: 0.4611 - accuracy: 0.7674 - val_loss: 0.5028 - val_accuracy: 0.7760\n",
      "Epoch 713/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7674 - val_loss: 0.5028 - val_accuracy: 0.7760\n",
      "Epoch 714/1000\n",
      "36/36 [==============================] - 0s 865us/step - loss: 0.4609 - accuracy: 0.7674 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
      "Epoch 715/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.4609 - accuracy: 0.7674 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
      "Epoch 716/1000\n",
      "36/36 [==============================] - 0s 629us/step - loss: 0.4608 - accuracy: 0.7674 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
      "Epoch 717/1000\n",
      "36/36 [==============================] - 0s 629us/step - loss: 0.4607 - accuracy: 0.7674 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 718/1000\n",
      "36/36 [==============================] - 0s 648us/step - loss: 0.4607 - accuracy: 0.7674 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 719/1000\n",
      "36/36 [==============================] - 0s 635us/step - loss: 0.4606 - accuracy: 0.7674 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 720/1000\n",
      "36/36 [==============================] - 0s 652us/step - loss: 0.4605 - accuracy: 0.7674 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 721/1000\n",
      "36/36 [==============================] - 0s 880us/step - loss: 0.4604 - accuracy: 0.7674 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 722/1000\n",
      "36/36 [==============================] - 0s 766us/step - loss: 0.4604 - accuracy: 0.7674 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 723/1000\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.4603 - accuracy: 0.7674 - val_loss: 0.5024 - val_accuracy: 0.7708\n",
      "Epoch 724/1000\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.4603 - accuracy: 0.7674 - val_loss: 0.5024 - val_accuracy: 0.7708\n",
      "Epoch 725/1000\n",
      "36/36 [==============================] - 0s 632us/step - loss: 0.4602 - accuracy: 0.7674 - val_loss: 0.5024 - val_accuracy: 0.7708\n",
      "Epoch 726/1000\n",
      "36/36 [==============================] - 0s 644us/step - loss: 0.4601 - accuracy: 0.7674 - val_loss: 0.5024 - val_accuracy: 0.7708\n",
      "Epoch 727/1000\n",
      "36/36 [==============================] - 0s 659us/step - loss: 0.4601 - accuracy: 0.7656 - val_loss: 0.5023 - val_accuracy: 0.7708\n",
      "Epoch 728/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.4600 - accuracy: 0.7674 - val_loss: 0.5023 - val_accuracy: 0.7708\n",
      "Epoch 729/1000\n",
      "36/36 [==============================] - 0s 660us/step - loss: 0.4599 - accuracy: 0.7656 - val_loss: 0.5023 - val_accuracy: 0.7708\n",
      "Epoch 730/1000\n",
      "36/36 [==============================] - 0s 645us/step - loss: 0.4599 - accuracy: 0.7656 - val_loss: 0.5023 - val_accuracy: 0.7708\n",
      "Epoch 731/1000\n",
      "36/36 [==============================] - 0s 660us/step - loss: 0.4598 - accuracy: 0.7674 - val_loss: 0.5022 - val_accuracy: 0.7708\n",
      "Epoch 732/1000\n",
      "36/36 [==============================] - 0s 644us/step - loss: 0.4597 - accuracy: 0.7674 - val_loss: 0.5022 - val_accuracy: 0.7708\n",
      "Epoch 733/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.7639 - val_loss: 0.5022 - val_accuracy: 0.7708\n",
      "Epoch 734/1000\n",
      "36/36 [==============================] - 0s 869us/step - loss: 0.4596 - accuracy: 0.7656 - val_loss: 0.5022 - val_accuracy: 0.7708\n",
      "Epoch 735/1000\n",
      "36/36 [==============================] - 0s 668us/step - loss: 0.4595 - accuracy: 0.7656 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
      "Epoch 736/1000\n",
      "36/36 [==============================] - 0s 655us/step - loss: 0.4595 - accuracy: 0.7656 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
      "Epoch 737/1000\n",
      "36/36 [==============================] - 0s 867us/step - loss: 0.4594 - accuracy: 0.7639 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
      "Epoch 738/1000\n",
      "36/36 [==============================] - 0s 873us/step - loss: 0.4593 - accuracy: 0.7639 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
      "Epoch 739/1000\n",
      "36/36 [==============================] - 0s 677us/step - loss: 0.4593 - accuracy: 0.7656 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
      "Epoch 740/1000\n",
      "36/36 [==============================] - 0s 637us/step - loss: 0.4593 - accuracy: 0.7639 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
      "Epoch 741/1000\n",
      "36/36 [==============================] - 0s 661us/step - loss: 0.4591 - accuracy: 0.7656 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
      "Epoch 742/1000\n",
      "36/36 [==============================] - 0s 656us/step - loss: 0.4591 - accuracy: 0.7639 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
      "Epoch 743/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.4590 - accuracy: 0.7639 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
      "Epoch 744/1000\n",
      "36/36 [==============================] - 0s 660us/step - loss: 0.4590 - accuracy: 0.7674 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
      "Epoch 745/1000\n",
      "36/36 [==============================] - 0s 649us/step - loss: 0.4589 - accuracy: 0.7656 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
      "Epoch 746/1000\n",
      "36/36 [==============================] - 0s 638us/step - loss: 0.4588 - accuracy: 0.7656 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
      "Epoch 747/1000\n",
      "36/36 [==============================] - 0s 637us/step - loss: 0.4588 - accuracy: 0.7639 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
      "Epoch 748/1000\n",
      "36/36 [==============================] - 0s 651us/step - loss: 0.4587 - accuracy: 0.7656 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
      "Epoch 749/1000\n",
      "36/36 [==============================] - 0s 634us/step - loss: 0.4587 - accuracy: 0.7656 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
      "Epoch 750/1000\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.4586 - accuracy: 0.7656 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
      "Epoch 751/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.7656 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
      "Epoch 752/1000\n",
      "36/36 [==============================] - 0s 922us/step - loss: 0.4585 - accuracy: 0.7656 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
      "Epoch 753/1000\n",
      "36/36 [==============================] - 0s 644us/step - loss: 0.4584 - accuracy: 0.7639 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
      "Epoch 754/1000\n",
      "36/36 [==============================] - 0s 875us/step - loss: 0.4584 - accuracy: 0.7656 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
      "Epoch 755/1000\n",
      "36/36 [==============================] - 0s 773us/step - loss: 0.4584 - accuracy: 0.7656 - val_loss: 0.5016 - val_accuracy: 0.7708\n",
      "Epoch 756/1000\n",
      "36/36 [==============================] - 0s 627us/step - loss: 0.4583 - accuracy: 0.7674 - val_loss: 0.5016 - val_accuracy: 0.7708\n",
      "Epoch 757/1000\n",
      "36/36 [==============================] - 0s 644us/step - loss: 0.4582 - accuracy: 0.7639 - val_loss: 0.5016 - val_accuracy: 0.7708\n",
      "Epoch 758/1000\n",
      "36/36 [==============================] - 0s 626us/step - loss: 0.4581 - accuracy: 0.7656 - val_loss: 0.5016 - val_accuracy: 0.7708\n",
      "Epoch 759/1000\n",
      "36/36 [==============================] - 0s 629us/step - loss: 0.4581 - accuracy: 0.7656 - val_loss: 0.5016 - val_accuracy: 0.7708\n",
      "Epoch 760/1000\n",
      "36/36 [==============================] - 0s 650us/step - loss: 0.4581 - accuracy: 0.7656 - val_loss: 0.5016 - val_accuracy: 0.7708\n",
      "Epoch 761/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.4580 - accuracy: 0.7656 - val_loss: 0.5016 - val_accuracy: 0.7708\n",
      "Epoch 762/1000\n",
      "36/36 [==============================] - 0s 648us/step - loss: 0.4580 - accuracy: 0.7656 - val_loss: 0.5015 - val_accuracy: 0.7708\n",
      "Epoch 763/1000\n",
      "36/36 [==============================] - 0s 632us/step - loss: 0.4579 - accuracy: 0.7656 - val_loss: 0.5015 - val_accuracy: 0.7708\n",
      "Epoch 764/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.4578 - accuracy: 0.7656 - val_loss: 0.5015 - val_accuracy: 0.7708\n",
      "Epoch 765/1000\n",
      "36/36 [==============================] - 0s 648us/step - loss: 0.4578 - accuracy: 0.7656 - val_loss: 0.5015 - val_accuracy: 0.7708\n",
      "Epoch 766/1000\n",
      "36/36 [==============================] - 0s 639us/step - loss: 0.4577 - accuracy: 0.7656 - val_loss: 0.5015 - val_accuracy: 0.7656\n",
      "Epoch 767/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4577 - accuracy: 0.7656 - val_loss: 0.5015 - val_accuracy: 0.7656\n",
      "Epoch 768/1000\n",
      "36/36 [==============================] - 0s 907us/step - loss: 0.4576 - accuracy: 0.7656 - val_loss: 0.5015 - val_accuracy: 0.7656\n",
      "Epoch 769/1000\n",
      "36/36 [==============================] - 0s 648us/step - loss: 0.4575 - accuracy: 0.7656 - val_loss: 0.5015 - val_accuracy: 0.7656\n",
      "Epoch 770/1000\n",
      "36/36 [==============================] - 0s 645us/step - loss: 0.4575 - accuracy: 0.7656 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 771/1000\n",
      "36/36 [==============================] - 0s 941us/step - loss: 0.4574 - accuracy: 0.7656 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 772/1000\n",
      "36/36 [==============================] - 0s 769us/step - loss: 0.4573 - accuracy: 0.7674 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 773/1000\n",
      "36/36 [==============================] - 0s 628us/step - loss: 0.4573 - accuracy: 0.7691 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 774/1000\n",
      "36/36 [==============================] - 0s 660us/step - loss: 0.4572 - accuracy: 0.7691 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 775/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.4572 - accuracy: 0.7674 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 776/1000\n",
      "36/36 [==============================] - 0s 680us/step - loss: 0.4571 - accuracy: 0.7691 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 777/1000\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.4571 - accuracy: 0.7691 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 778/1000\n",
      "36/36 [==============================] - 0s 668us/step - loss: 0.4570 - accuracy: 0.7691 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 779/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.4569 - accuracy: 0.7691 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 780/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.4568 - accuracy: 0.7691 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 781/1000\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.4568 - accuracy: 0.7691 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 782/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4568 - accuracy: 0.7691 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 783/1000\n",
      "36/36 [==============================] - 0s 886us/step - loss: 0.4567 - accuracy: 0.7691 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 784/1000\n",
      "36/36 [==============================] - 0s 655us/step - loss: 0.4566 - accuracy: 0.7691 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 785/1000\n",
      "36/36 [==============================] - 0s 634us/step - loss: 0.4566 - accuracy: 0.7691 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 786/1000\n",
      "36/36 [==============================] - 0s 644us/step - loss: 0.4565 - accuracy: 0.7691 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 787/1000\n",
      "36/36 [==============================] - 0s 950us/step - loss: 0.4565 - accuracy: 0.7691 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 788/1000\n",
      "36/36 [==============================] - 0s 766us/step - loss: 0.4564 - accuracy: 0.7691 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 789/1000\n",
      "36/36 [==============================] - 0s 652us/step - loss: 0.4564 - accuracy: 0.7691 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 790/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.4563 - accuracy: 0.7691 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 791/1000\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.4562 - accuracy: 0.7691 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 792/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.4562 - accuracy: 0.7691 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 793/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.4561 - accuracy: 0.7691 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 794/1000\n",
      "36/36 [==============================] - 0s 645us/step - loss: 0.4560 - accuracy: 0.7708 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 795/1000\n",
      "36/36 [==============================] - 0s 636us/step - loss: 0.4560 - accuracy: 0.7708 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 796/1000\n",
      "36/36 [==============================] - 0s 652us/step - loss: 0.4559 - accuracy: 0.7691 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 797/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.7691 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 798/1000\n",
      "36/36 [==============================] - 0s 880us/step - loss: 0.4558 - accuracy: 0.7708 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 799/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.4557 - accuracy: 0.7708 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 800/1000\n",
      "36/36 [==============================] - 0s 655us/step - loss: 0.4557 - accuracy: 0.7708 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 801/1000\n",
      "36/36 [==============================] - 0s 629us/step - loss: 0.4556 - accuracy: 0.7708 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 802/1000\n",
      "36/36 [==============================] - 0s 984us/step - loss: 0.4555 - accuracy: 0.7708 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 803/1000\n",
      "36/36 [==============================] - 0s 768us/step - loss: 0.4554 - accuracy: 0.7708 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 804/1000\n",
      "36/36 [==============================] - 0s 635us/step - loss: 0.4554 - accuracy: 0.7708 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 805/1000\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.4553 - accuracy: 0.7726 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 806/1000\n",
      "36/36 [==============================] - 0s 641us/step - loss: 0.4553 - accuracy: 0.7708 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 807/1000\n",
      "36/36 [==============================] - 0s 637us/step - loss: 0.4552 - accuracy: 0.7708 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 808/1000\n",
      "36/36 [==============================] - 0s 644us/step - loss: 0.4551 - accuracy: 0.7708 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 809/1000\n",
      "36/36 [==============================] - 0s 672us/step - loss: 0.4551 - accuracy: 0.7708 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 810/1000\n",
      "36/36 [==============================] - 0s 646us/step - loss: 0.4550 - accuracy: 0.7708 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 811/1000\n",
      "36/36 [==============================] - 0s 662us/step - loss: 0.4550 - accuracy: 0.7691 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
      "Epoch 812/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.4549 - accuracy: 0.7708 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
      "Epoch 813/1000\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.4548 - accuracy: 0.7708 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
      "Epoch 814/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4548 - accuracy: 0.7708 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
      "Epoch 815/1000\n",
      "36/36 [==============================] - 0s 648us/step - loss: 0.4547 - accuracy: 0.7708 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
      "Epoch 816/1000\n",
      "36/36 [==============================] - 0s 663us/step - loss: 0.4546 - accuracy: 0.7674 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
      "Epoch 817/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4546 - accuracy: 0.7691 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
      "Epoch 818/1000\n",
      "36/36 [==============================] - 0s 676us/step - loss: 0.4545 - accuracy: 0.7691 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
      "Epoch 819/1000\n",
      "36/36 [==============================] - 0s 634us/step - loss: 0.4545 - accuracy: 0.7674 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
      "Epoch 820/1000\n",
      "36/36 [==============================] - 0s 641us/step - loss: 0.4544 - accuracy: 0.7708 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
      "Epoch 821/1000\n",
      "36/36 [==============================] - 0s 644us/step - loss: 0.4544 - accuracy: 0.7708 - val_loss: 0.5007 - val_accuracy: 0.7656\n",
      "Epoch 822/1000\n",
      "36/36 [==============================] - 0s 652us/step - loss: 0.4543 - accuracy: 0.7691 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 823/1000\n",
      "36/36 [==============================] - 0s 634us/step - loss: 0.4542 - accuracy: 0.7691 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 824/1000\n",
      "36/36 [==============================] - 0s 667us/step - loss: 0.4542 - accuracy: 0.7691 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 825/1000\n",
      "36/36 [==============================] - 0s 645us/step - loss: 0.4541 - accuracy: 0.7708 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 826/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.4540 - accuracy: 0.7691 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 827/1000\n",
      "36/36 [==============================] - 0s 638us/step - loss: 0.4540 - accuracy: 0.7708 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 828/1000\n",
      "36/36 [==============================] - 0s 656us/step - loss: 0.4539 - accuracy: 0.7708 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 829/1000\n",
      "36/36 [==============================] - 0s 645us/step - loss: 0.4539 - accuracy: 0.7708 - val_loss: 0.5006 - val_accuracy: 0.7708\n",
      "Epoch 830/1000\n",
      "36/36 [==============================] - 0s 641us/step - loss: 0.4538 - accuracy: 0.7708 - val_loss: 0.5006 - val_accuracy: 0.7708\n",
      "Epoch 831/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.7708 - val_loss: 0.5006 - val_accuracy: 0.7708\n",
      "Epoch 832/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4537 - accuracy: 0.7726 - val_loss: 0.5006 - val_accuracy: 0.7708\n",
      "Epoch 833/1000\n",
      "36/36 [==============================] - 0s 668us/step - loss: 0.4536 - accuracy: 0.7708 - val_loss: 0.5006 - val_accuracy: 0.7708\n",
      "Epoch 834/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.4536 - accuracy: 0.7708 - val_loss: 0.5006 - val_accuracy: 0.7708\n",
      "Epoch 835/1000\n",
      "36/36 [==============================] - 0s 644us/step - loss: 0.4535 - accuracy: 0.7708 - val_loss: 0.5006 - val_accuracy: 0.7708\n",
      "Epoch 836/1000\n",
      "36/36 [==============================] - 0s 652us/step - loss: 0.4535 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 837/1000\n",
      "36/36 [==============================] - 0s 645us/step - loss: 0.4534 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 838/1000\n",
      "36/36 [==============================] - 0s 645us/step - loss: 0.4533 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 839/1000\n",
      "36/36 [==============================] - 0s 660us/step - loss: 0.4533 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 840/1000\n",
      "36/36 [==============================] - 0s 634us/step - loss: 0.4532 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 841/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.4532 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 842/1000\n",
      "36/36 [==============================] - 0s 637us/step - loss: 0.4531 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 843/1000\n",
      "36/36 [==============================] - 0s 649us/step - loss: 0.4531 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 844/1000\n",
      "36/36 [==============================] - 0s 625us/step - loss: 0.4530 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 845/1000\n",
      "36/36 [==============================] - 0s 661us/step - loss: 0.4529 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 846/1000\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.4529 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 847/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 848/1000\n",
      "36/36 [==============================] - 0s 671us/step - loss: 0.4528 - accuracy: 0.7708 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 849/1000\n",
      "36/36 [==============================] - 0s 692us/step - loss: 0.4528 - accuracy: 0.7708 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 850/1000\n",
      "36/36 [==============================] - 0s 675us/step - loss: 0.4527 - accuracy: 0.7708 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 851/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.4526 - accuracy: 0.7708 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 852/1000\n",
      "36/36 [==============================] - 0s 649us/step - loss: 0.4526 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 853/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.4525 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 854/1000\n",
      "36/36 [==============================] - 0s 658us/step - loss: 0.4525 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 855/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.4524 - accuracy: 0.7691 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 856/1000\n",
      "36/36 [==============================] - 0s 651us/step - loss: 0.4524 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 857/1000\n",
      "36/36 [==============================] - 0s 629us/step - loss: 0.4524 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 858/1000\n",
      "36/36 [==============================] - 0s 657us/step - loss: 0.4524 - accuracy: 0.7691 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 859/1000\n",
      "36/36 [==============================] - 0s 648us/step - loss: 0.4523 - accuracy: 0.7691 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 860/1000\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.4522 - accuracy: 0.7691 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 861/1000\n",
      "36/36 [==============================] - 0s 628us/step - loss: 0.4522 - accuracy: 0.7691 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 862/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7691 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 863/1000\n",
      "36/36 [==============================] - 0s 663us/step - loss: 0.4521 - accuracy: 0.7708 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 864/1000\n",
      "36/36 [==============================] - 0s 642us/step - loss: 0.4521 - accuracy: 0.7691 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 865/1000\n",
      "36/36 [==============================] - 0s 641us/step - loss: 0.4520 - accuracy: 0.7708 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 866/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.4520 - accuracy: 0.7691 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 867/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.4519 - accuracy: 0.7691 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 868/1000\n",
      "36/36 [==============================] - 0s 667us/step - loss: 0.4519 - accuracy: 0.7691 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 869/1000\n",
      "36/36 [==============================] - 0s 639us/step - loss: 0.4518 - accuracy: 0.7691 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 870/1000\n",
      "36/36 [==============================] - 0s 655us/step - loss: 0.4518 - accuracy: 0.7691 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 871/1000\n",
      "36/36 [==============================] - 0s 641us/step - loss: 0.4517 - accuracy: 0.7691 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 872/1000\n",
      "36/36 [==============================] - 0s 663us/step - loss: 0.4517 - accuracy: 0.7691 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 873/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.4517 - accuracy: 0.7691 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 874/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.4517 - accuracy: 0.7691 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 875/1000\n",
      "36/36 [==============================] - 0s 955us/step - loss: 0.4516 - accuracy: 0.7691 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 876/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.7691 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 877/1000\n",
      "36/36 [==============================] - 0s 870us/step - loss: 0.4515 - accuracy: 0.7691 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 878/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.4514 - accuracy: 0.7691 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 879/1000\n",
      "36/36 [==============================] - 0s 659us/step - loss: 0.4514 - accuracy: 0.7691 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 880/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.4513 - accuracy: 0.7691 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 881/1000\n",
      "36/36 [==============================] - 0s 648us/step - loss: 0.4513 - accuracy: 0.7691 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 882/1000\n",
      "36/36 [==============================] - 0s 649us/step - loss: 0.4512 - accuracy: 0.7708 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 883/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.4512 - accuracy: 0.7691 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 884/1000\n",
      "36/36 [==============================] - 0s 657us/step - loss: 0.4512 - accuracy: 0.7708 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 885/1000\n",
      "36/36 [==============================] - 0s 633us/step - loss: 0.4511 - accuracy: 0.7691 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 886/1000\n",
      "36/36 [==============================] - 0s 662us/step - loss: 0.4511 - accuracy: 0.7691 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 887/1000\n",
      "36/36 [==============================] - 0s 655us/step - loss: 0.4510 - accuracy: 0.7708 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 888/1000\n",
      "36/36 [==============================] - 0s 672us/step - loss: 0.4510 - accuracy: 0.7708 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 889/1000\n",
      "36/36 [==============================] - 0s 854us/step - loss: 0.4509 - accuracy: 0.7691 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 890/1000\n",
      "36/36 [==============================] - 0s 753us/step - loss: 0.4509 - accuracy: 0.7691 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 891/1000\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.4508 - accuracy: 0.7708 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 892/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.7708 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 893/1000\n",
      "36/36 [==============================] - 0s 882us/step - loss: 0.4507 - accuracy: 0.7726 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 894/1000\n",
      "36/36 [==============================] - 0s 656us/step - loss: 0.4507 - accuracy: 0.7708 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 895/1000\n",
      "36/36 [==============================] - 0s 660us/step - loss: 0.4507 - accuracy: 0.7726 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 896/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.4506 - accuracy: 0.7708 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 897/1000\n",
      "36/36 [==============================] - 0s 672us/step - loss: 0.4506 - accuracy: 0.7708 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 898/1000\n",
      "36/36 [==============================] - 0s 627us/step - loss: 0.4505 - accuracy: 0.7708 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 899/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.4505 - accuracy: 0.7743 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 900/1000\n",
      "36/36 [==============================] - 0s 638us/step - loss: 0.4504 - accuracy: 0.7726 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 901/1000\n",
      "36/36 [==============================] - 0s 635us/step - loss: 0.4504 - accuracy: 0.7743 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 902/1000\n",
      "36/36 [==============================] - 0s 663us/step - loss: 0.4503 - accuracy: 0.7708 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 903/1000\n",
      "36/36 [==============================] - 0s 925us/step - loss: 0.4503 - accuracy: 0.7726 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 904/1000\n",
      "36/36 [==============================] - 0s 773us/step - loss: 0.4503 - accuracy: 0.7743 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 905/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.4502 - accuracy: 0.7726 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 906/1000\n",
      "36/36 [==============================] - 0s 662us/step - loss: 0.4502 - accuracy: 0.7743 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 907/1000\n",
      "36/36 [==============================] - 0s 645us/step - loss: 0.4502 - accuracy: 0.7760 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 908/1000\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.4501 - accuracy: 0.7743 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 909/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.7726 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 910/1000\n",
      "36/36 [==============================] - 0s 880us/step - loss: 0.4500 - accuracy: 0.7743 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 911/1000\n",
      "36/36 [==============================] - 0s 648us/step - loss: 0.4499 - accuracy: 0.7760 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 912/1000\n",
      "36/36 [==============================] - 0s 630us/step - loss: 0.4499 - accuracy: 0.7760 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 913/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.4499 - accuracy: 0.7760 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 914/1000\n",
      "36/36 [==============================] - 0s 634us/step - loss: 0.4498 - accuracy: 0.7743 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 915/1000\n",
      "36/36 [==============================] - 0s 653us/step - loss: 0.4498 - accuracy: 0.7760 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 916/1000\n",
      "36/36 [==============================] - 0s 644us/step - loss: 0.4497 - accuracy: 0.7760 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 917/1000\n",
      "36/36 [==============================] - 0s 905us/step - loss: 0.4497 - accuracy: 0.7778 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 918/1000\n",
      "36/36 [==============================] - 0s 773us/step - loss: 0.4497 - accuracy: 0.7778 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 919/1000\n",
      "36/36 [==============================] - 0s 635us/step - loss: 0.4496 - accuracy: 0.7743 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 920/1000\n",
      "36/36 [==============================] - 0s 649us/step - loss: 0.4496 - accuracy: 0.7778 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 921/1000\n",
      "36/36 [==============================] - 0s 641us/step - loss: 0.4496 - accuracy: 0.7778 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 922/1000\n",
      "36/36 [==============================] - 0s 652us/step - loss: 0.4495 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 923/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.4495 - accuracy: 0.7760 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 924/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 925/1000\n",
      "36/36 [==============================] - 0s 641us/step - loss: 0.4494 - accuracy: 0.7760 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 926/1000\n",
      "36/36 [==============================] - 0s 644us/step - loss: 0.4494 - accuracy: 0.7760 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 927/1000\n",
      "36/36 [==============================] - 0s 635us/step - loss: 0.4493 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 928/1000\n",
      "36/36 [==============================] - 0s 631us/step - loss: 0.4493 - accuracy: 0.7743 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 929/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.4492 - accuracy: 0.7760 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 930/1000\n",
      "36/36 [==============================] - 0s 631us/step - loss: 0.4492 - accuracy: 0.7760 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 931/1000\n",
      "36/36 [==============================] - 0s 657us/step - loss: 0.4492 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 932/1000\n",
      "36/36 [==============================] - 0s 903us/step - loss: 0.4491 - accuracy: 0.7760 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 933/1000\n",
      "36/36 [==============================] - 0s 769us/step - loss: 0.4491 - accuracy: 0.7760 - val_loss: 0.5000 - val_accuracy: 0.7708\n",
      "Epoch 934/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.4491 - accuracy: 0.7760 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 935/1000\n",
      "36/36 [==============================] - 0s 657us/step - loss: 0.4490 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 936/1000\n",
      "36/36 [==============================] - 0s 646us/step - loss: 0.4490 - accuracy: 0.7778 - val_loss: 0.5000 - val_accuracy: 0.7708\n",
      "Epoch 937/1000\n",
      "36/36 [==============================] - 0s 650us/step - loss: 0.4490 - accuracy: 0.7778 - val_loss: 0.5000 - val_accuracy: 0.7708\n",
      "Epoch 938/1000\n",
      "36/36 [==============================] - 0s 649us/step - loss: 0.4489 - accuracy: 0.7778 - val_loss: 0.5000 - val_accuracy: 0.7708\n",
      "Epoch 939/1000\n",
      "36/36 [==============================] - 0s 661us/step - loss: 0.4489 - accuracy: 0.7778 - val_loss: 0.5000 - val_accuracy: 0.7708\n",
      "Epoch 940/1000\n",
      "36/36 [==============================] - 0s 655us/step - loss: 0.4489 - accuracy: 0.7778 - val_loss: 0.5000 - val_accuracy: 0.7708\n",
      "Epoch 941/1000\n",
      "36/36 [==============================] - 0s 633us/step - loss: 0.4488 - accuracy: 0.7778 - val_loss: 0.5000 - val_accuracy: 0.7708\n",
      "Epoch 942/1000\n",
      "36/36 [==============================] - 0s 640us/step - loss: 0.4488 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 943/1000\n",
      "36/36 [==============================] - 0s 641us/step - loss: 0.4488 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 944/1000\n",
      "36/36 [==============================] - 0s 654us/step - loss: 0.4487 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 945/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 946/1000\n",
      "36/36 [==============================] - 0s 885us/step - loss: 0.4486 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 947/1000\n",
      "36/36 [==============================] - 0s 921us/step - loss: 0.4486 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 948/1000\n",
      "36/36 [==============================] - 0s 751us/step - loss: 0.4486 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 949/1000\n",
      "36/36 [==============================] - 0s 675us/step - loss: 0.4485 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 950/1000\n",
      "36/36 [==============================] - 0s 655us/step - loss: 0.4485 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 951/1000\n",
      "36/36 [==============================] - 0s 668us/step - loss: 0.4484 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 952/1000\n",
      "36/36 [==============================] - 0s 644us/step - loss: 0.4484 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 953/1000\n",
      "36/36 [==============================] - 0s 655us/step - loss: 0.4484 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 954/1000\n",
      "36/36 [==============================] - 0s 662us/step - loss: 0.4483 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 955/1000\n",
      "36/36 [==============================] - 0s 672us/step - loss: 0.4483 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 956/1000\n",
      "36/36 [==============================] - 0s 655us/step - loss: 0.4482 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 957/1000\n",
      "36/36 [==============================] - 0s 667us/step - loss: 0.4482 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 958/1000\n",
      "36/36 [==============================] - 0s 661us/step - loss: 0.4482 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 959/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 960/1000\n",
      "36/36 [==============================] - 0s 683us/step - loss: 0.4481 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7760\n",
      "Epoch 961/1000\n",
      "36/36 [==============================] - 0s 718us/step - loss: 0.4481 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7760\n",
      "Epoch 962/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7760\n",
      "Epoch 963/1000\n",
      "36/36 [==============================] - 0s 784us/step - loss: 0.4480 - accuracy: 0.7778 - val_loss: 0.5001 - val_accuracy: 0.7760\n",
      "Epoch 964/1000\n",
      "36/36 [==============================] - 0s 658us/step - loss: 0.4480 - accuracy: 0.7778 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 965/1000\n",
      "36/36 [==============================] - 0s 667us/step - loss: 0.4479 - accuracy: 0.7778 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 966/1000\n",
      "36/36 [==============================] - 0s 649us/step - loss: 0.4479 - accuracy: 0.7778 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 967/1000\n",
      "36/36 [==============================] - 0s 670us/step - loss: 0.4479 - accuracy: 0.7760 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 968/1000\n",
      "36/36 [==============================] - 0s 664us/step - loss: 0.4478 - accuracy: 0.7778 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 969/1000\n",
      "36/36 [==============================] - 0s 661us/step - loss: 0.4478 - accuracy: 0.7778 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 970/1000\n",
      "36/36 [==============================] - 0s 649us/step - loss: 0.4477 - accuracy: 0.7778 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 971/1000\n",
      "36/36 [==============================] - 0s 671us/step - loss: 0.4477 - accuracy: 0.7795 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 972/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.7795 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 973/1000\n",
      "36/36 [==============================] - 0s 857us/step - loss: 0.4477 - accuracy: 0.7778 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 974/1000\n",
      "36/36 [==============================] - 0s 649us/step - loss: 0.4476 - accuracy: 0.7795 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 975/1000\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.7795 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 976/1000\n",
      "36/36 [==============================] - 0s 744us/step - loss: 0.4475 - accuracy: 0.7795 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 977/1000\n",
      "36/36 [==============================] - 0s 645us/step - loss: 0.4475 - accuracy: 0.7795 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 978/1000\n",
      "36/36 [==============================] - 0s 635us/step - loss: 0.4475 - accuracy: 0.7795 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 979/1000\n",
      "36/36 [==============================] - 0s 647us/step - loss: 0.4474 - accuracy: 0.7795 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 980/1000\n",
      "36/36 [==============================] - 0s 661us/step - loss: 0.4474 - accuracy: 0.7795 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 981/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.4474 - accuracy: 0.7795 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 982/1000\n",
      "36/36 [==============================] - 0s 663us/step - loss: 0.4474 - accuracy: 0.7812 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 983/1000\n",
      "36/36 [==============================] - 0s 656us/step - loss: 0.4473 - accuracy: 0.7778 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 984/1000\n",
      "36/36 [==============================] - 0s 658us/step - loss: 0.4472 - accuracy: 0.7795 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 985/1000\n",
      "36/36 [==============================] - 0s 643us/step - loss: 0.4472 - accuracy: 0.7812 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 986/1000\n",
      "36/36 [==============================] - 0s 801us/step - loss: 0.4472 - accuracy: 0.7812 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 987/1000\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 988/1000\n",
      "36/36 [==============================] - 0s 663us/step - loss: 0.4471 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 989/1000\n",
      "36/36 [==============================] - 0s 674us/step - loss: 0.4471 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 990/1000\n",
      "36/36 [==============================] - 0s 673us/step - loss: 0.4471 - accuracy: 0.7812 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 991/1000\n",
      "36/36 [==============================] - 0s 658us/step - loss: 0.4470 - accuracy: 0.7830 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
      "Epoch 992/1000\n",
      "36/36 [==============================] - 0s 639us/step - loss: 0.4470 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7760\n",
      "Epoch 993/1000\n",
      "36/36 [==============================] - 0s 688us/step - loss: 0.4470 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7760\n",
      "Epoch 994/1000\n",
      "36/36 [==============================] - 0s 659us/step - loss: 0.4469 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7760\n",
      "Epoch 995/1000\n",
      "36/36 [==============================] - 0s 651us/step - loss: 0.4469 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7760\n",
      "Epoch 996/1000\n",
      "36/36 [==============================] - 0s 662us/step - loss: 0.4469 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7760\n",
      "Epoch 997/1000\n",
      "36/36 [==============================] - 0s 680us/step - loss: 0.4468 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7760\n",
      "Epoch 998/1000\n",
      "36/36 [==============================] - 0s 670us/step - loss: 0.4468 - accuracy: 0.7830 - val_loss: 0.5003 - val_accuracy: 0.7760\n",
      "Epoch 999/1000\n",
      "36/36 [==============================] - 0s 697us/step - loss: 0.4467 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7760\n",
      "Epoch 1000/1000\n",
      "36/36 [==============================] - 0s 932us/step - loss: 0.4467 - accuracy: 0.7830 - val_loss: 0.5004 - val_accuracy: 0.7760\n",
      "6/6 [==============================] - 0s 599us/step\n",
      "Final Training Loss: 0.4467\n",
      "Final Validation Loss: 0.5004\n",
      "Final Training Accuracy: 0.7830\n",
      "Final Validation Accuracy: 0.7760\n"
     ]
    }
   ],
   "source": [
    "model_3 = Sequential([\n",
    "    Dense(6, input_shape=(num_features,), activation=\"relu\"),\n",
    "    Dense(6, activation=\"relu\"),\n",
    "    Dense(6, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# learning rate fix to 0.003\n",
    "# 1500 epochs (iterations)\n",
    "\n",
    "model_3.compile(\n",
    "    optimizer=SGD(learning_rate=0.001),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "run_hist_3 = model_3.fit(\n",
    "    X_train_norm,\n",
    "    y_train,\n",
    "    validation_data=(X_test_norm, y_test),\n",
    "    epochs=1000,\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "y_pred_prob_nn_3 = model_3.predict(X_test_norm)\n",
    "y_pred_class_nn_3 = (y_pred_prob_nn_3 >= 0.5).astype('int32')\n",
    "\n",
    "final_train_loss = run_hist_3.history[\"loss\"][-1]\n",
    "final_val_loss = run_hist_3.history[\"val_loss\"][-1]\n",
    "final_train_accuracy = run_hist_3.history[\"accuracy\"][-1]\n",
    "final_val_accuracy = run_hist_3.history[\"val_accuracy\"][-1]\n",
    "\n",
    "print(f\"Final Training Loss: {final_train_loss:.4f}\")\n",
    "print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
    "print(f\"Final Training Accuracy: {final_train_accuracy:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {final_val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss\n",
    "fig3, (cx1, cx2) = plt.subplots(nrows=2, ncols=1, figsize=(16, 12))\n",
    "cx1.plot(run_hist_3.history[\"loss\"], 'teal', linestyle='-', label=\"Train Loss\")\n",
    "cx1.plot(run_hist_3.history[\"val_loss\"], 'orange', linestyle='-', linewidth=3, label=\"Validation Loss\")\n",
    "cx1.legend()\n",
    "cx1.set_xlabel(\"Epoch\")\n",
    "cx1.set_ylabel(\"Loss\")\n",
    "cx1.set_title(\"Training and Validation Loss\")\n",
    "\n",
    "# Plot accuracy\n",
    "cx2.plot(run_hist_3.history[\"accuracy\"], 'teal', linestyle='-', label=\"Train Accuracy\")\n",
    "cx2.plot(run_hist_3.history[\"val_accuracy\"], 'orange', linestyle='-', linewidth=3, label=\"Validation Accuracy\")\n",
    "cx2.legend()\n",
    "cx2.set_xlabel(\"Epoch\")\n",
    "cx2.set_ylabel(\"Accuracy\")\n",
    "cx2.set_title(\"Training and Validation Accuracy\")\n",
    "\n",
    "# Adjust layout to prevent clipping\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "อธิบายให้เห็นว่าผลลัพธ์ที่ได้จากโมเดลใหม่นั้นดีขึ้นจากโมเดลเดิม"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    จากการลองปรับค่า Hyperparameter ต่างๆ นิสิตสามารถทำให้โมเดลใหม่นั้นดีขึ้นได้แค่ \n",
    "    \n",
    "    ''' \n",
    "        การเพิ่มค่า accuracy ของ validation_accuracy ให้ลู่ใกล้เคียงกับ train_accuracy ใน scale ที่รับได้ คือ \n",
    "        Final Training Accuracy: 0.7830\n",
    "        Final Validation Accuracy: 0.7760\n",
    "    '''\n",
    "\n",
    "    โดยนิสิตคิดว่าจาก behavior ของ dataset, sequence model และ SGD optimizer นั้น model จะเริ่มเรียนรู้ได้น้อยลง ( พิจารณาจาก Loss Graph ) ในช่วง epoch ที่ 1000+ โดยมี learning rate = 0.001 และ batch_size = 16 ซึ่งถ้ากำหนดให้ค่าเหล่านี้ไม่ไปในทิศทางเดียวกัน model อาจจะ overfitted ได้\n",
    "\n",
    "    การปรับ complexity และจำนวนของ layer ของ model, hidden layer = 1 - 3 ให้ผลที่ไม่แตกต่างและมีนัยยะมากนัก\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning Records\n",
    "\n",
    "### Round 1\n",
    "\n",
    "- **Configuration:**\n",
    "  - 3 hidden layers\n",
    "  - Learning rate: 0.005\n",
    "  - Epoch: 1000\n",
    "  - Batch size: 32\n",
    "\n",
    "- **Results:**\n",
    "  - Final Training Loss: 0.3969\n",
    "  - Final Validation Loss: 0.5624\n",
    "  - Final Training Accuracy: 0.8212\n",
    "  - Final Validation Accuracy: 0.7292\n",
    "\n",
    "### Round 2\n",
    "\n",
    "- **Configuration:**\n",
    "  - 3 hidden layers\n",
    "  - Learning rate: 0.002\n",
    "  - Epoch: 2000\n",
    "  - Batch size: 32\n",
    "\n",
    "- **Results:**\n",
    "  - Final Training Loss: 0.4025\n",
    "  - Final Validation Loss: 0.5439\n",
    "  - Final Training Accuracy: 0.8125\n",
    "  - Final Validation Accuracy: 0.7188\n",
    "\n",
    "### Round 3\n",
    "\n",
    "- **Configuration:**\n",
    "  - 2 hidden layers\n",
    "  - Learning rate: 0.001\n",
    "  - Epoch: 2500\n",
    "  - Batch size: 16\n",
    "\n",
    "- **Results:**\n",
    "  - Final Training Loss: 0.4381\n",
    "  - Final Validation Loss: 0.5285\n",
    "  - Final Training Accuracy: 0.7899\n",
    "  - Final Validation Accuracy: 0.7500\n",
    "\n",
    "### Round 4\n",
    "\n",
    "- **Configuration:**\n",
    "  - 2 hidden layers\n",
    "  - Learning rate: 0.001\n",
    "  - Epoch: 2500\n",
    "  - Batch size: 16\n",
    "\n",
    "- **Results:**\n",
    "  - Final Training Loss: 0.3871\n",
    "  - Final Validation Loss: 0.5369\n",
    "  - Final Training Accuracy: 0.8056\n",
    "  - Final Validation Accuracy: 0.7604\n",
    "\n",
    "### Round 5\n",
    "\n",
    "- **Configuration:**\n",
    "  - 2 hidden layers\n",
    "  - Learning rate: 0.002\n",
    "  - Epoch: 2500\n",
    "  - Batch size: 32\n",
    "\n",
    "- **Results:**\n",
    "  - Final Training Loss: 0.4233\n",
    "  - Final Validation Loss: 0.5160\n",
    "  - Final Training Accuracy: 0.7830\n",
    "  - Final Validation Accuracy: 0.7448\n",
    "\n",
    "### Round 6\n",
    "\n",
    "- **Configuration:**\n",
    "  - 2 hidden layers\n",
    "  - Learning rate: 0.002\n",
    "  - Epoch: 2500\n",
    "  - Batch size: 8\n",
    "\n",
    "- **Results:**\n",
    "  - Final Training Loss: 0.3564\n",
    "  - Final Validation Loss: 0.6900\n",
    "  - Final Training Accuracy: 0.8299\n",
    "  - Final Validation Accuracy: 0.7135\n",
    "\n",
    "### Round 7\n",
    "\n",
    "- **Configuration:**\n",
    "  - 2 hidden layers\n",
    "  - Learning rate: 0.002\n",
    "  - Epoch: 3000\n",
    "  - Batch size: 16\n",
    "\n",
    "- **Results:**\n",
    "  - Final Training Loss: 0.4078\n",
    "  - Final Validation Loss: 0.5495\n",
    "  - Final Training Accuracy: 0.7969\n",
    "  - Final Validation Accuracy: 0.7344\n",
    "\n",
    "### Round 8\n",
    "\n",
    "- **Configuration:**\n",
    "  - 2 hidden layers\n",
    "  - Learning rate: 0.001\n",
    "  - Epoch: 2500\n",
    "  - Batch size: 16\n",
    "\n",
    "- **Results:**\n",
    "  - Final Training Loss: 0.4205\n",
    "  - Final Validation Loss: 0.5048\n",
    "  - Final Training Accuracy: 0.8021\n",
    "  - Final Validation Accuracy: 0.7396\n",
    "\n",
    "### Round 9\n",
    "\n",
    "- **Configuration:**\n",
    "  - 3 hidden layers\n",
    "  - Learning rate: 0.001\n",
    "  - Epoch: 2500\n",
    "  - Batch size: 16\n",
    "\n",
    "- **Results:**\n",
    "  - Final Training Loss: 0.4164\n",
    "  - Final Validation Loss: 0.5273\n",
    "  - Final Training Accuracy: 0.8212\n",
    "  - Final Validation Accuracy: 0.7448\n",
    "\n",
    "### Round 10\n",
    "\n",
    "- **Configuration:**\n",
    "  - 3 hidden layers\n",
    "  - Learning rate: 0.001\n",
    "  - Epoch: 3000\n",
    "  - Batch size: 16\n",
    "\n",
    "- **Results:**\n",
    "  - Final Training Loss: 0.3975\n",
    "  - Final Validation Loss: 0.5183\n",
    "  - Final Training Accuracy: 0.8108\n",
    "  - Final Validation Accuracy: 0.7708\n",
    "\n",
    "### Round 11\n",
    "\n",
    "- **Configuration:**\n",
    "  - 3 hidden layers\n",
    "  - Learning rate: 0.001\n",
    "  - Epoch: 4000\n",
    "  - Batch size: 16\n",
    "\n",
    "- **Results:**\n",
    "  - Final Training Loss: 0.3738\n",
    "  - Final Validation Loss: 0.5447\n",
    "  - Final Training Accuracy: 0.7951\n",
    "  - Final Validation Accuracy: 0.7500\n",
    "\n",
    "### Round 12\n",
    "\n",
    "- **Configuration:**\n",
    "  - 3 hidden layers\n",
    "  - Learning rate: 0.001\n",
    "  - Epoch: 3000\n",
    "  - Batch size: 16\n",
    "  - Architecture:\n",
    "    - Dense(8, input_shape=(num_features,), activation=\"relu\")\n",
    "    - Dense(8, activation=\"relu\")\n",
    "    - Dense(8, activation=\"relu\")\n",
    "    - Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "- **Results:**\n",
    "  - Final Training Loss: 0.3921\n",
    "  - Final Validation Loss: 0.5350\n",
    "  - Final Training Accuracy: 0.8125\n",
    "  - Final Validation Accuracy: 0.7344\n",
    "\n",
    "### Round 13\n",
    "\n",
    "- **Configuration:**\n",
    "  - 2 hidden layers\n",
    "  - Learning rate: 0.001\n",
    "  - Epoch: 3000\n",
    "  - Batch size: 16\n",
    "  - Architecture:\n",
    "    - Dense(8, input_shape=(num_features,), activation=\"relu\")\n",
    "    - Dense(8, activation=\"relu\")\n",
    "    - Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "- **Results:**\n",
    "  - Final Training Loss: 0.4107\n",
    "  - Final Validation Loss: 0.5171\n",
    "  - Final Training Accuracy: 0.7969\n",
    "  - Final Validation Accuracy: 0.7604\n",
    "\n",
    "\n",
    "### Round 14\n",
    "\n",
    "- **Configuration:**\n",
    "  - 2 hidden layers\n",
    "  - Learning rate: 0.002\n",
    "  - Epoch: 1000\n",
    "  - Batch size: 16\n",
    "\n",
    "- **Results:**\n",
    "  - Final Training Loss: 0.4137\n",
    "  - Final Validation Loss: 0.5277\n",
    "  - Final Training Accuracy: 0.8038\n",
    "  - Final Validation Accuracy: 0.7240\n",
    "\n",
    "### Round 15\n",
    "\n",
    "- **Configuration:**\n",
    "  - 3 hidden layers\n",
    "  - Learning rate: 0.001\n",
    "  - Epoch: 1000\n",
    "  - Batch size: 16\n",
    "\n",
    "- **Results:**\n",
    "  - Final Training Loss: 0.4467\n",
    "  - Final Validation Loss: 0.5004\n",
    "  - Final Training Accuracy: 0.7830\n",
    "  - Final Validation Accuracy: 0.7760"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
